# ==----------------------------------------------------------------------------mysql==





https://zhuanlan.zhihu.com/p/138065975   

>一些常见的命令查询  学生表 和 成绩表 和教师表

https://blog.csdn.net/ThinkWon/article/details/103522351   mysql和redis相关总结

16.数据库char和varchar的区别
17.int1 和 int10 怎么选择
18.int1中存放超过一位数的数也可以，为什么
19.char之间大小比较于varchar之间大小比较的区别   

# ==mysql基础架构==

## 数据库与普通文本对比

其实就是这个稍微有点闪亮呗 就是这个样子呢 看着是不是还是难受啊 这样子看呢是吧 看着就是还是难受呗

>使用普通文件的遇到的问题： 必须的必  所以就是这个样子吗  所以就是这个样子吗 妈妈说啊 这键盘就是没有那个键盘那么舒服啊 键盘还是不舒服呗
>
>1. 当文件变大时，使用普通文件将会变得非常慢，访问速度制约了应用性能
>2. 在一个普通文件中查找特定的一个或一组记录将非常困难。
>3. 处理并发访问可能遇到问题。虽然可以使用锁定文件来操作文件，但是多个脚本访问文件时可能导致竞争条件的发生，它可能导致应用出现性能的瓶颈。
>4. 普通文件在顺序访问时具有优势，但是在随机访问数据时可能非常困难。除非你将整个文件读入到内存中，在内存中修改它，然后将整个文件写回去
>5. 除了使用文件访问权限作为限制外，还没有一个简单高效的方法区分不同级别的数据访问权限机制。
>
>关系数据库关系系统如何解决文件存储晕倒的问题：
>
>1. 提供了比普通文件更快的访问速度。
>2. 可以很容易查找并检索满足特定条件的数据集合
>3. 具有内置的处理并发访问机制。作为一个编程人员，不需要处理这些内容。
>4. 可以随机访问数据
>5. 具有内置的权限系统，有灵活的角色和权限管理功能。





## **关系型数据库和非关系数据库的比较**

>**关系型数据库和非关系数据库的比较**
>
>1. 使用场景不同：关系型数据库适用于关系特别复杂的数据库查询场景，非关系则反之
>
>2. “事务”特性的支持：关系型数据库对事务支持的非常完善，二非关系型数据库则不支持
>
>3. 成本：Nosql数据库简单易部署，基本都是开源软件，不需要像使用Oracle那样花费大量成本购买使用，相比关系型数据库价格便宜。
>
>4. 查询速度：Nosql数据库将数据存储于缓存之中，而且不需要经过SQL层的解析，关系型数据库将数据存储在硬盘中，自然查询速度远不及Nosql数据库。
>
>5. 存储数据的格式：Nosql的存储格式是key,value形式、文档形式、图片形式等等，所以可以存储基础类型以及对象或者是集合等各种格式，而数据库则只支持基础类型。
>
>6. 扩展性：关系型数据库有类似join这样的多表查询机制的限制导致扩展很艰难。Nosql基于键值对，数据之间没有耦合性，所以非常容易水平扩展。
>
>7. 持久存储：Nosql不使用于持久存储，海量数据的持久存储，还是需要关系型数据库
>
>8. 数据一致性：非关系型数据库一般强调的是数据最终一致性，不像关系型数据库一样强调数据的强一致性，从非关系型数据库中读到的有可能还是处于一个中间态的数据



## 介绍以下Mysql 分层 

>`Server` 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖` MySQL` 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。
>
>#### 连接器
>
>第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。
>
>#### 查询缓存
>
>连接建立完成后，你就可以执行` select `语句了。执行逻辑就会来到第二步：查询缓存。
>
>`MySQL` 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以` key-value `对的形式，被直接缓存在内存中。`key `是查询的语句，`value `是查询的结果。如果你的查询能够直接在这个缓存中找到` key`，那么这个 `value` 就会被直接返回给客户端。
>
>如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。你可以看到，如果查询命中缓存 `MySQL `不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。
>
>但是大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。
>
>查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。
>
>好在 MySQL 也提供了这种“按需使用”的方式。你可以将参数` query_cache_type` 设置成` DEMAND`，这样对于默认的 `SQL` 语句都不使用查询缓存
>
>#### 分析器
>
>如果没有命中查询缓存，就要开始真正执行语句了。首先，`MySQL `需要知道你要做什么，因此需要对` SQL `语句做解析。
>
>#### 优化器
>
>经过了分析器，`MySQL` 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。
>
>优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联`（join`）的时候，决定各个表的连接顺序
>
>#### 执行器
>
>`MySQL` 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。
>
>-------------
>
>##### 分层设计的好处
>
>1. **分层的设计可以简化系统设计，让不同的人专注做某一层次的事情。**而有了分层的设计，你只需要专注设计应用层的程序就可以了，其他都可以交给下面几层来完成。
>
>2. **再有，分层之后可以做到很高的复用。**比如，我们在设计系统A的时候，发现某一层具有一定的通用性，那么我们可以把它抽取独立出来，在设计系统B的时候使用起来，这样可以减少研发周期，提升研发的效率。
>3. **最后一点，分层架构可以让我们更容易做横向扩展。**如果系统没有分层，当流量增加时我们需要针对整体系统来做扩展。但是，如果我们按照上面提到的三层架构将系统分层后，就可以针对具体的问题来做细致的扩展。





## 数据库设计三大范式

>- 第一**范式**(确保每列保持原子性)                    所有字段值都是不可分解的原子值
>- 第二**范式**(确保表中的每列都和主键相关)。 第二范式需要确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）。也就是说在一个数据库表中，一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。
>- 第**三范式**(确保每列都和主键列直接相关,而不是间接相关)
>
>----
>
>https://www.cnblogs.com/linjiqin/archive/2012/04/01/2428695.html   在第二大范式当中 简单例子 可以看一下





##  ==red log&& binlog==

>`redo log`（重做日志）和 `binlog`（归档日志）。
>
>当有一条记录需要更新的时候，`InnoDB` 引擎就会先把记录写到` redo log`（粉板）里面，并更新内存，这个时候更新就算完成了。同时，`InnoDB` 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事。
>
>与此类似，`InnoDB 的 redo log `是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 `1GB`，那么这块“粉板”总共就可以记录 `4GB `的操作。从头开始写，写到末尾就又回到开头循环写，粉板 `redo log` 是 `InnoDB` 引擎特有的日志
>
>-------------
>
>**而 `Server` 层也有自己的日志，称为 `binlog`（归档日志）。**
>
>1. `redo log` 是` InnoDB` 引擎特有的；`binlog `是 `MySQL` 的` Server` 层实现的，所有引擎都可以使用。
>2. `redo log` 是物理日志，记录的是“在某个数据页上做了什么修改；`binlog `是逻辑日志，记录的是这个语句的原始逻辑
>3. `redo log` 是循环写的，空间固定会用完；`binlog` 是可以追加写入的。是指 `binlog `文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。
>
>--------------------
>
>执行器和 `InnoDB `引擎在执行这个简单的 `update` 语句时的内部流程。配合`red log`日志
>
>`mysql> update T set c=c+1 where ID=2;`  
>
>我们再来看执行器和` InnoDB `引擎在执行这个简单的` update `语句时的内部流程。
>
>1. 执行器先找引擎取` ID=2 `这一行。`ID `是主键，引擎直接用树搜索找到这一行。如果` ID=2` 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。
>2. 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。
>3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到` redo log `里面，此时` redo log` 处于` prepare` 状态。然后告知执行器执行完成了，随时可以提交事务。
>4. 执行器生成这个操作的 `binlog`，并把` binlog` 写入磁盘。
>5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的` redo log` 改成提交（`commit`）状态，更新完成。
>
>这里我给出这个` update` 语句的执行流程图，图中浅色框表示是在` InnoDB` 内部执行的，深色框表示是在执行器中执行的。
>
>- 两阶段提交
>
>由于 `redo log` 和 `binlog` 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完` redo log` 再写` binlog`，或者采用反过来的顺序。我们看看这两种方式会有什么问题。
>
>仍然用前面的 `update `语句来做例子。假设当前` ID=2 `的行，字段` c `的值是 0，再假设执行 `update `语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了` crash`，会出现什么情况呢？
>
>1. **先写 redo log 后写 binlog**。假设在` redo log` 写完，`binlog` 还没有写完的时候，`MySQL` 进程异常重启。由于我们前面说过的，`redo log `写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。
>    但是由于` binlog` 没写完就` crash `了，这时候` binlog` 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的` binlog `里面就没有这条语句。
>    然后你会发现，如果需要用这个 `binlog` 来恢复临时库的话，由于这个语句的` binlog `丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。
> 
> 2. **先写 binlog 后写 redo log**。如果在` binlog `写完之后` crash`，由于` redo log` 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 `binlog `里面已经记录了“把` c 从 0 改成 1`这个日志。所以，在之后用 `binlog` 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。
>
>3. 两阶段提交 
>
> 如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。
> 简单说，`redo log` 和 `binlog` 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。
> 
> -------------------------------------
>
>问题总结
>
>- 我可以认为`redo log `记录的是这个行在这个页更新之后的状态，`binlog` 记录的是`sql`吗？
>
>`Redo log`不是记录数据页“更新之后的状态”，而是记录这个页 “做了什么改动”。`Binlog`有两种模式，`statement `格式的话是记`sql`语句，` row`格式会记录行的内容，记两条，更新前和更新后都有。
>
>---------------------------
>
>`redo`是物理的，`binlog`是逻辑的；现在由于`redo`是属于`InnoDB`引擎，所以必须要有`binlo`g，因为你可以使用别的引擎
>保证数据库的一致性，必须要保证2份日志一致，使用的2阶段式提交；其实感觉像事务，不是成功就是失败，不能让中间环节出现，也就是一个成功，一个失败

## Mysql怎么保证一致性的   ACID？

>从[数据库](https://cloud.tencent.com/solution/database?from=10680)层面，数据库通过原子性、隔离性、持久性来保证一致性。也就是说ACID四大特性之中，C(一致性)是目的，A(原子性)、I(隔离性)、D(持久性)是手段，是为了保证一致性，数据库提供的手段。数据库必须要实现AID三大特性，才有可能实现一致性。例如，原子性无法保证，显然一致性也无法保证。
>
>但是，如果你在事务里故意写出违反约束的代码，一致性还是无法保证的。例如，你在转账的例子中，你的代码里故意不给B账户加钱，那一致性还是无法保证。因此，还必须从应用层角度考虑。
>
>从应用层面，通过代码判断数据库数据是否有效，然后决定回滚还是提交数据！





## Mysql怎么保证原子性的 &&  ==undo log==日志？

>OK，是利用Innodb的undo log。
>
>undo log名为回滚日志，是实现原子性的关键，当事务回滚时能够撤销所有已经成功执行的sql语句，他需要记录你要回滚的相应日志信息。
>
>例如
>
>- (1)当你delete一条数据的时候，就需要记录这条数据的信息，回滚的时候，insert这条旧数据
>- (2)当你update一条数据的时候，就需要记录之前的旧值，回滚的时候，根据旧值执行update操作
>- (3)当年insert一条数据的时候，就需要这条记录的主键，回滚的时候，根据主键执行delete操
>
>undo log记录了这些回滚需要的信息，当事务执行失败或调用了rollback，导致事务需要回滚，便可以利用undo log中的信息将数据回滚到修改之前的样子。
>



## Mysql怎么保证持久性的？

>OK，是利用Innodb的redo log。
>
>正如之前说的，Mysql是先把磁盘上的数据加载到内存中，在内存中对数据进行修改，再刷回磁盘上。如果此时突然宕机，内存中的数据就会丢失。
>
>**怎么解决这个问题？**
>
>简单啊，事务提交前直接把数据写入磁盘就行啊。
>
>**这么做有什么问题？**
>
>只修改一个页面里的一个字节，就要将整个页面刷入磁盘，太浪费资源了。毕竟一个页面16kb大小，你只改其中一点点东西，就要将16kb的内容刷入磁盘，听着也不合理。
>
>毕竟一个事务里的SQL可能牵涉到多个数据页的修改，而这些数据页可能不是相邻的，也就是属于随机IO。显然操作随机IO，速度会比较慢。
>
>于是，决定采用redo log解决上面的问题。当做数据修改的时候，不仅在内存中操作，还会在redo log中记录这次操作。当事务提交的时候，会将redo log日志进行刷盘(redo log一部分在内存中，一部分在磁盘上)。当数据库宕机重启的时候，会将redo log中的内容恢复到数据库中，再根据undo log和binlog内容决定回滚数据还是提交数据。





# 存储引擎 && 索引类型



## MyISAM 和 InnoDB 的区别

>1. `InnoDB` 支持事务，`MyISAM `不支持事务。这是 `MySQL `将默认存储引擎从 `MyISAM `变成` InnoDB `的重要原因之一；
>
>2. `InnoDB `支持外键，而 `MyISAM `不支持。对一个包含外键的` InnoDB` 表转为` MYISAM `会失败；  
>
>3. `InnoDB` 是聚集索引，`MyISAM` 是非聚集索引。聚簇索引的文件存放在主键索引的叶子节点上，因此` InnoDB `必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而 `MyISAM `是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。 
>
>4. `InnoDB `不保存表的具体行数，执行 `select count(*) from table `时需要全表扫描。而`MyISAM `用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快；    
>
>5. `InnoDB` 最小的锁粒度是行锁，`MyISAM` 最小的锁粒度是表锁。一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。这也是 `MySQL` 将默认存储引擎从 `MyISAM `变成 `InnoDB `的重要原因之一；
>
>**如何选择：**
>
>1. 是否要支持事务，如果要请选择 `InnoDB`，如果不需要可以考虑 `MyISAM`；
>2. 如果表中绝大多数都只是读查询，可以考虑 `MyISAM`，如果既有读写也挺频繁，请使用`InnoDB`。
>3. 系统奔溃后，`MyISAM`恢复起来更困难，能否接受，不能接受就选 `InnoDB`，也就是`Innodb `宕机恢复起来更好一些；



## ==B树和B+树区别==

>首先大多数场景下 我们选择`Innodb`存储引擎 需要满足我们大部分场景需求：在这里不进行选择B树和hash作为底层是有原因的。 mysql 核心需求：精准查询，范围查询，排序
>
>- 哈希虽然能够提供 `O(1)` 的单数据行操作性能，但是对于范围查询和排序却无法很好地支持，最终导致全表扫描；
>- B 树能够在非叶节点中存储数据，但是这也导致在查询连续数据时可能会带来更多的随机 I/O，而 B+ 树的所有叶节点可以通过指针相互连接，能够减少顺序遍历时产生的额外随机 I/O；
>
>
>
>为什么选择B+树？
>
>-----
>
>## 二叉搜索树
>
>二分查找，小的放左边，大的放右边。
>
>局限性：
>
>- 根节点的选取很重要，极限情况就成了一个链表了。（都比根节点大，就都在右边了）
>- 树的层数不固定，这都还好。
>- 数的层次过大，毕竟子的数量都是2，数据量大了可能几万层了，这样不管是内存（放不下）还是磁盘IO都很难（每一字访问节点都是一次读取）。
>
>## AVL树
>
>在二叉树的基础上做了平衡处理，虽然极大避免了退化问题，层数也固定了，但是最大的问题---层数过多的问题没有解决。
>
>## 红黑树
>
>红黑树只是优化了插入、更新，弱化了平衡，在更新和搜索中取了折中。但是一样，层数过多的问题没有解决。
>
>## B树
>
>为了降低层数，最简单的，一层多放一点元素不就好了。
>
>- 对于m阶每个节点最多有m-1个**关键字**（可以存有的键值对）。根节点最少可以只有1个**关键字**
>- 每个节点中的关键字都按照从小到大的顺序排列
>- 所有叶子节点都位于同一层
>- 每个节点都存有索引和数据，也就是对应的key和value。
>
>**缺点**：（对于范围查找）  由于所有的节点都可能包含目标数据，我们总是要从根节点向下遍历子树查找满足条件的数据行，这个特点带来了大量的随机 I/O，也是 B 树最大的性能问题。
>
>
>
>## B+树
>
>![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6ab0bb4d197f43dd926897265f5d729c~tplv-k3u1fbpfcp-watermark.awebp)
>
>很明显，将叶子节点用链表串联起来了， 还有就是子节点中包含了父节点的信息，比如22，这样的好处就是，可以直接访问到下一个，即，遍历了叶子节点就是遍历了全表。
>
>**相比于B树 B+树特点：**
>
>- **B+树有两种类型的节点：内部结点和叶子结点。内部节点只存储索引，叶子节点只存储数据。**
>- 子节点包含父节点的信息
>- 内部结点中的key都按照从小到大的顺序排列
>- 每个叶子结点都存有相邻叶子结点的指针，叶子节点使用链表串联起来的，更加便于查找。
>
>
>
>**B+树优势：**
>
>1. B数对于范围查找 ， 由于所有的节点都可能包含目标数据，我们总是要从根节点向下遍历子树查找满足条件的数据行，这个特点带来了大量的随机 I/O，也是 B 树最大的性能问题。
>2. 而对于B+树：所有的数据行都存储在叶子节点中，而这些叶节点可以**通过『指针』依次按顺序连接**，当我们在 B+ 树遍历数据时可以直接在多个子节点之间进行跳转，这样能够节省大量的磁盘 I/O 时间，也不需要在不同层级的节点之间对数据进行拼接和排序；通过一个 B+ 树最左侧的叶子节点，我们可以像链表一样遍历整个树中的全部数据



## 索引类型

>- 按数据结构分类可分为：**B+tree索引、Hash索引、Full-text索引**。
>- 按物理存储分类可分为：**聚簇索引、二级索引（辅助索引）**。
>- 按字段特性分类可分为：**主键索引、普通索引、前缀索引**。
>- 按字段个数分类可分为：**单列索引、联合索引（复合索引、组合索引）**。

##  **B+、Hash索引 性能对比**

>MySQL索引按数据结构分类可分为：**B+tree索引、Hash索引、Full-text索引**。
>
>| -               | InnoDB         | MyISAM | Memory |
>| --------------- | -------------- | ------ | ------ |
>| `B+tree`索引    | √              | √      | √      |
>| `Hash`索引      | ×              | ×      | √      |
>| `Full-text`索引 | √（MySQL5.6+） | √      | ×      |
>
>#### B+tree与Hash的对比
>
>Hash索引类似于等值查询效率非常快
>
>##### 1. Hash 索引仅仅能满足 `=` , `IN` 和 `<=>`(表示NULL安全的等价) 查询，不能使用范围查询。
>
>由于 Hash 索引比较的是进行 Hash 运算之后的 Hash值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的 Hash算法处理之后的 Hash 值的大小关系，并不能保证和Hash运算前完全一样。
>
>##### 2. Hash 索引无法适用数据的排序操作。
>
>由于 Hash 索引中存放的是经过 Hash 计算之后的 Hash值，而且Hash值的大小关系并不一定和 Hash运算前的键值完全一样，所以数据库无法利用索引的数据来避免任何排序运算；
>
>##### 3. Hash 索引不能利用部分索引键查询。
>
>对于组合索引，Hash 索引在计算 Hash 值的时候是组合索引键合并后再一起计算 Hash 值，而不是单独计算 Hash值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash 索引也无法被利用。
>
>##### 4. Hash 索引依然需要回表扫描。
>
>Hash 索引是将索引键通过 Hash 运算之后，将 Hash运算结果的 Hash值和所对应的行指针信息存放于一个 Hash 表中，由于不同索引键可能存在相同 Hash 值，所以即使取满足某个 Hash 键值的数据的记录条数，也无法从 Hash索引中直接完成查询，还是要通过访问表中的实际数据进行相应的比较，并得到相应的结果。
>
>##### 5. Hash索引遇到大量Hash值相等的情况后性能并不一定就会比B-Tree索引高。
>
>选择性比较低的索引键，如果创建 Hash 索引，那么将会存在大量记录指针信息存于同一个Hash值相关联。这样要定位某一条记录时就会非常麻烦，会浪费多次表数据的访问，而造成整体性能低下
>
>**由于范围查询是MySQL数据库查询中常见的场景，Hash表不适合做范围查询，它更适合做等值查询。另外Hash表还存在Hash函数选择和Hash值冲突等问题。因此，B+tree索引要比Hash表索引有更广的适用场景。**
>
>----------
>
>##### 为什么哈希表的时间复杂度是常数阶O(1)？
>
>顺序存储结构和链式存储结构（像栈，队列，树，图等是从逻辑结构去抽象的，映射到内存中，也这两种物理组织形式），在数组中根据下标查找某个元素，一次定位就可以达到，哈希表利用了这种特性，哈希表的主干就是数组。比如我们要新增或查找某个元素，我们通过把当前元素的关键字 通过某个函数映射到数组中的某个位置，通过数组下标一次定位就可完成操作。



## 聚族索引vs非聚族索引

>- 聚簇索引：将数据存储与索引放到了一块，找到索引也就找到了数据
>- 非聚簇索引：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，这也就是为什么索引不在key buffer命中时，速度慢的原因
>
>**澄清一个概念**：innodb中，在聚簇索引之上创建的索引称之为辅助索引，辅助索引访问数据总是需要二次查找，非聚簇索引都是辅助索引，像复合索引、前缀索引、唯一索引，辅助索引叶子节点存储的不再是行的物理位置，而是主键值。



## mysql六大索引类型

>#### 1. 主键索引
>
>建立在主键上的索引被称为**主键索引**，一张数据表只能有一个主键索引，索引列值不允许有空值，通常在创建表时一起创建。
>
>#### 2. 唯一索引
>
>建立在UNIQUE字段上的索引被称为**唯一索引**，一张表可以有多个唯一索引，索引列值允许为空，列值中出现多个空值不会发生重复冲突。
>
>#### 3. 普通索引
>
>建立在普通字段上的索引被称为**普通索引**。
>
>#### 4. 前缀索引
>
>**前缀索引**是指对字符类型字段的前几个字符或对二进制类型字段的前几个bytes建立的索引，而不是在整个字段上建索引。前缀索引可以建立在类型为char、varchar、binary、varbinary的列上，可以大大减少索引占用的存储空间，也能提升索引的查询效率。
>
>### 四、按索引字段个数分类
>
>MySQL索引按字段个数分类可分为：**单列索引、联合索引（复合索引、组合索引）**。
>
>#### 1. 单列索引
>
>建立在单个列上的索引被称为单列索引。
>
>#### 2. 联合索引（复合索引、组合索引）
>
>建立在多个列上的索引被称为联合索引，又叫复合索引、组合索引。



## ==主键索引和非主键索引有什么区别？==

>![img](https://img2018.cnblogs.com/blog/1644694/201905/1644694-20190505155026646-1387513390.png)
>
> 
>
>非主键索引的叶子节点存放的是**主键的值**，而主键索引的叶子节点存放的是**整行数据**，其中非主键索引也被称为**二级索引**，而主键索引也被称为**聚簇索引**。
>
>根据这两种结构我们来进行下查询，看看他们在查询上有什么区别。
>
>1、如果查询语句是 select * from table where ID = 100,即主键查询的方式，则只需要搜索 ID 这棵 B+树。
>
>2、如果查询语句是 select * from table where k = 1，即非主键的查询方式，则先搜索k索引树，得到ID=100,再到ID索引树搜索一次，这个过程也被称为回表。



## 如何避免回表

>![img](https://img-blog.csdnimg.cn/20200926083503245.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NQTEFTRl8=,size_16,color_FFFFFF,t_70#pic_center)
>
>那回表是什么：如果是通过非主键索引进行查询，select所要获取的字段不能通过非主键索引获取到，需要通过非主键索引获取到的主键，从聚集索引再次查询一遍，获取到所要查询的记录，这个查询的过程就是回表
>
>-----
>
>如何避免：
>
>1. 尽量使用主键索引进行查询
>2. 将查询的字段建立到联合索引里边。  `select id, name, sex=where name='ahui'  name和sex建立联合索引`





## ==联合索引什么时候会失效？为什么会失效？==

>https://blog.csdn.net/qq_35275233/article/details/87888809
>
>联合索引要遵循最左前缀匹配原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。
>
>**失效**：  
>
>1.假如联合索引三个字段 a,c 在等值查询的时候跳过中间一个字段 会导致后边的字段索引失效
>
>2.范围查询的时候： a=2,b>7,c=8 这时候索引字段c也会失效 但是b还是可以的
>
>3.模糊查询会失效。
>
>4.但是如果只是单单查询的时候顺序不同 例如a=1 and  c=3 and b=2  这种情况 **查询引擎会自动优化为匹配联合索引的顺序，这样是能够命中索引的**。
>
>-----
>
>**为什么会失效？**
>
>索引底层是一颗B+树，只不过联合索引的B+树节点中存储的是针对索引键值对，索引数据不是分开存储，假如a在等值的情况下，b值又是按顺序排列的，但是这种顺序是相对的。这是因为MySQL创建联合索引的规则是首先会对联合索引的最左边第一个字段排序，在第一个字段的排序基础上，然后在对第二个字段进行排序。所以类似于b=2这种查询条件没有办法利用索引。
>
>同时我们还可以发现在a值相等的情况下，b值又是按顺序排列的，但是这种顺序是相对的。所以最左匹配原则遇上范围查询就会停止，剩下的字段都无法使用索引。例如a = 1 and b = 2 a,b字段都可以使用索引，因为在a值确定的情况下b是相对有序的，而a>1and b=2，a字段可以匹配上索引，但b值不可以，因为a的值是一个范围，在这个范围中b是无序的。



## 索引优化手段

>### 创建原则
>
>在创建联合索引的时候，应该把频繁使用的列，区分度高的列放在前面，区分度高代表筛选粒度大，也可以在常需要作为查询返回的字段上增加到联合索引中，如果在联合索引上增加一个字段而使用到了覆盖索引(索引下推)，避免回表，就建议使用联合索引。
>
>##### 使用场景
>
>- 考虑当前是否已经存在多个可以合并的单列索引，如果有，将当前多个单列索引创建为一个联合索引。
>- 当前索引存在频繁使用作为返回字段的列，可以考虑当前列是否可以加入到当前已经存在的索引上，使其查询语句可以使用到覆盖索引。
>
>-----
>
>### 联合索引
>
>在建立索引的时候，尽量在多个单列索引上判断下是否可以使用联合索引，联合索引使用不仅可以节省空间，还可以更容易的使用到索引覆盖。
>
>索引的字段越多，更容易满足查询需要返回的数据。 例如联合索引(a_b_c)，等价于有了三个索引：a，a_b，a_b_c，索引树的叶节点数据没变，索引data字段数据是省数据了。
>
>-----
>
>### 调整索引列顺序
>
>基于上面对最左前缀索引的说明，讨论一个问题：在建立联合索引的时候，如何安排索引内的字段顺序。
>
>评估标准是，索引的复用能力。因为可以支持最左前缀，所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。
>
>要为高频请求创建 (身份证号，姓名）这个联合索引，并用这个索引支持“根据身份证号查询地址”的需求。
>
>那么，如果既有联合查询，又有基于 a、b 各自的查询呢？查询条件里面只有 b 的语句，是无法使用 (a,b) 这个联合索引的，这时候不得不维护另外一个索引，也就是说需要同时维护 (a,b)、(b) 这两个索引。
>
>----
>
>### 覆盖索引
>
>定义：索引包含所有需要查询的字段的值，避免回表。
> 覆盖索引是一种很常用的优化手段。因为在使用辅助索引的时候，我们只可以拿到主键值，相当于获取数据还需要再根据主键查询主键索引再获取到数据。
>
>但是试想下这么一种情况，在上面abc_innodb表中的组合索引查询时，如果我只需要abc字段的，那是不是意味着我们查询到组合索引的叶子节点就可以直接返回了，而不需要回表。这种情况就是覆盖索引。
>
>-----
>
>### 普通索引和唯一索引选择
>
>##### 查询过程区别
>
>对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。
>
>对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。
>
>两者性能区别微乎其微。
> 因为InnoDB 的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB。 即使普通索引需要继续往后查找，能在同一页内停止搜索概率还是很大的。



## 覆盖索引

>覆盖索引： 覆盖索引是指查询语句查询方式；联合索引是指索引组织的类型； 
>
>覆盖索引：如果查询条件使用的是普通索引（或是联合索引的最左原则字段），查询结果是联合索引的字段或是主键，不用回表操作，直接返回结果，减少IO磁盘读写读取正行数据
>
>现在我们已经知道了InnoDB的物理存储方式是一个聚集索引+多个辅助索引组成， 辅助索引包含单列索引以及上面提到的联合索引。 在使用索引进行数据查询时， 首先在辅助索引树中找到该条数据对应的主键id(Row ID)， 而后根据主键id在聚集索引树中进行查询， 粗略的认为就是2次逻辑I/O。
>
>覆盖索引的本质就是不使用聚集索引， 只使用辅助索引就能够将所需要的数据查询出来， 最典型的例子就是count(*)。



## 缺少主键MySQL如何处理

> `InnoDB`对聚簇索引处理如下： 
>
> - 如果定义了主键，那么`InnoDB`会使用主键作为聚簇索引 
>
> - 如果没有定义主键，那么会使用第一非空的唯一索引（`NOT NULL and UNIQUE INDEX`）作为聚簇索引 - 
> - 如果既没有主键也找不到合适的非空索引，那么InnoDB会自动生成一个不可见的名为`ROW_ID`的列名为GEN_CLUST_INDEX的聚簇索引，该列是一个6字节的自增数值，随着插入而自增
>
> 但是，问题真的只是查询影响吗？不是的，对于生成的ROW_ID，其自增的实现来源于一个全局的序列，而所以有ROW_ID的表共享该序列，这也意味着插入的时候生成需要共享一个序列，那么高并发插入的时候为了保持唯一性就避免不了锁的竞争，进而影响性能。









# 锁

https://blog.csdn.net/Saintyyu/article/details/91269087

https://zhuanlan.zhihu.com/p/52312376

mysql中表锁和行锁使用的是悲观锁还是乐观锁：https://segmentfault.com/a/1190000015815061

>对于`UPDATE、DELETE、INSERT`语句，`InnoDB`会自动给涉及数据集加排他锁`（X)` 。而`MyISAM`在执行查询语句`SELECT`前，会自动给涉及的所有表加读锁，在执行**增、删、改**操作前，会自动给涉及的表加写锁，这个过程并不需要我们去手动操作。
>
>
>
>全局锁：
>
>`MySQL `提供了一个加全局读锁的方法，命令是` Flush tables with read lock (FTWRL)`。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。
>
>**全局锁的典型使用场景是，做全库逻辑备份。**也就是把整库每个表都 select 出来存成文本。
>
>弊端：
>
>- 如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；
>- 如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 `binlog`，会导致主从延迟。
>
>-------------
>
>**表锁:** 开销小，加锁快；不会出现死锁；锁定力度大，发生锁冲突概率高，并发度最低。
>
>**行锁:** 开销大，加锁慢；会出现死锁；锁定粒度小，发生锁冲突的概率低，并发度高 不同的存储引擎支持的锁粒度是不一样的。
>
>- `InnoDB`行锁和表锁都支持、`MyISAM`只支持表锁！
>- `InnoDB`只有通过索引条件检索数据才使用行级锁，否则，`InnoDB`使用表锁也就是说，`InnoDB`的行锁是基于索引的！
>
>----------------
>
>----------------
>
>表锁下又分为两种模式： **表读锁**`（Table Read Lock）&&` **表写锁**`（Table Write Lock）`
>
>在表读锁和表写锁的环境下：**读读不阻塞，读写阻塞，写写阻塞！**
>
>**读读不阻塞：** 当前用户在读数据，其他的用户也在读数据，不会加锁
>
>**读写阻塞：** 当前用户在读数据，其他的用户不能修改当前用户读的数据，会加锁！
>
>**写写阻塞：** 当前用户在修改数据，其他的用户不能修改当前用户正在修改的数据，会加锁！
>
>-------------
>
>-----
>
>`InnoDB和MyISAM`有**两个本质的区别**：`InnoDB`支持行锁、`InnoDB`支持事务。
>
>`InnoDB`实现了以下两种类型的行锁：
>
>- **共享锁（S锁、读锁）：** 允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。即多个客户可以同时读取同一个资源，但不允许其他客户修改。
>- **排他锁（X锁、写锁)：** 允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的读锁和写锁。写锁是排他的，写锁会阻塞其他的写锁和读锁。
>
>--------------
>
>##### 两阶段锁协议：
>
>在 `InnoDB` 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议：上锁和释放锁。
>
>-------
>
>##### 死锁和死锁检测
>
>当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁
>
>当出现死锁时候检测策略：
>
>- 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数` innodb_lock_wait_timeout` 来设置。																		默认是`50`s，但是，我们又不可能直接把这个时间设置成一个很小的值，比如 `1s`。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。
>
>- 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数` innodb_deadlock_detect` 设置为 `on`，表示开启这个逻辑。`innodb_deadlock_detect `的默认值本身就是` on`。                                        
>
>弊端：假设对同一行数据进行更新，每个新来的线程都会检测一遍，时间复杂度太大，消耗`cpu`资源

## ==mysql怎么实现乐观锁和悲观锁==

>#### 悲观锁
>
>**悲观锁（Pessimistic Lock）**：就是很悲观，每次去取数据的时候都认为别人会去修改，所以每次在取数据的时候都会给它上锁，这样别人想拿这个数据就会block直到它取到锁。比如用在库存增减问题上，利用悲观锁可以有效的防止减库存问题。主要就是进行加锁
>
>**实现方式：**
>悲观锁的实现方式：悲观锁的实现，依靠数据库提供的锁机制。在数据库中，悲观锁的流程如下：
>
>1. 在对数据修改前，尝试增加排他锁。  实现悲观锁、排它锁 利用select ... for update加锁, 操作完成后使用commit来释放锁；
>2.  加锁失败，意味着数据正在被修改，进行等待或者抛出异常。
>3. 加锁成功，对数据进行修改，提交事务，锁释放。
>4. 如果我们加锁成功，有其他线程对该数据进行操作或者加排他锁的操作，只能等待或者抛出异常。
>
>
>
>锁范围： `innodb`引擎时, 默认行级锁, 当有明确字段时会锁一行, 如无查询条件；字段不明确时, 会锁整个表，条件为范围时会锁整个表；
>
>-----
>
>
>
>#### 乐观锁
>
>**乐观锁实现方式：**
>
>假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。
>
>方式一：   version方式：一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。
>
>方式二： 使用时间戳`（timestamp）`。乐观锁定的第二种实现方式和第一种差不多，同样是在需要乐观锁控制的`table`中增加一个字段，名称无所谓，字段类型使用时间戳`（timestamp）`, 和上面的version类似，也是在更新提交的时候检查当前数据库中数据的时间戳和自己更新前取到的时间戳进行对比，如果一致则OK，否则就是版本冲突。
>
>------
>
>**区别和总结：**
>
>1. MySQL的乐观锁与悲观锁主要都是用来解决并发的场景，避免丢失更新问题。
>2. 乐观锁：比较适合读取操作比较频繁的场景，如果出现大量的写入操作，数据发生冲突的可能性就会增大，为了保证数据的一致性，应用层需要不断的重新获取数据，这样会增加大量的查询操作，降低了系统的吞吐量。
>3. 悲观锁：比较适合写入操作比较频繁的场景，如果出现大量的读取操作，每次读取的时候都会进行加锁，这样会增加大量的锁的开销，降低了系统的吞吐量。



## 行锁/表锁

>**表锁:** 开销小，加锁快；不会出现死锁；锁定力度大，发生锁冲突概率高，并发度最低。
>
>**行锁:** 开销大，加锁慢；会出现死锁；锁定粒度小，发生锁冲突的概率低，并发度高 不同的存储引擎支持的锁粒度是不一样的。
>
>- `InnoDB`行锁和表锁都支持、`MyISAM`只支持表锁！
>- `InnoDB`只有通过索引条件检索数据才使用行级锁，否则，`InnoDB`使用表锁也就是说，`InnoDB`的行锁是基于索引的！
>
>----
>
>##### `InnoDB`：如何加锁
>
>`InnoDB` 采用的是**两阶段锁定协议**：即在事务执行过程中，随时都可以执行加锁操作，但是**只有在事务执行 COMMIT 或者 ROLLBACK 的时候才会释放锁**，并且所有的锁是在同一时刻被释放。
>
>**行锁**：
>
>`select: `在查询语句后加上`for update`，则查询到的数据会被加上一条排它锁，其它事务可以读取，但不能进行更新和插入操作
>
>1. 对于常见`insert`，`delete`，`update`在事务中都会自动默认加上排它锁 
>
>2. 默认情况下对于普通 `SELECT` 语句，`InnoDB `不会加任何锁，但是在 Serializable 隔离级别下会加行级读锁
>
>   `SELECT * FROM table_name WHERE ... FOR UPDATE`，加行级写锁
>
>   `SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE`，加行级读锁
>
>`InnoDB `存储引擎的行级锁是基于索引的,也就是说**当索引失效或者说根本没有用索引的时候，行锁就会升级成表锁**。
>
>**表锁**：
>
>1. 隐式锁定：对于常见的 `DDL` 语句（如 `ALTER`、`CREATE` 等），`InnoDB `会自动给相应的表加表级锁
>
>2. 显示锁定：在执行 SQL 语句时，也可以明确显示指定对某个表进行加锁（`lock table user read(write)`）





## **意向锁**

>InnoDB 存储引擎支持 **多粒度（granular）锁定**，就是说**允许事务在行级上的锁和表级上的锁同时存在**。
>
>那么为了实现行锁和表锁并存，InnoDB 存储引擎就设计出了 **意向锁（Intention Lock）** 这个东西：
>
>很好理解：意向锁是一个**表级锁**，其作用就是指明接下来的事务将会用到哪种锁。
>
>有两种意向锁：
>
>- **意向共享锁（IS Lock）**：当事务想要获得一张表中某几行的共享锁行级锁）时，InnoDB 存储引擎会自动地先获取该表的意向共享锁（表级锁）
>- **意向排他锁（IX Lock）**：当事务想要获得一张表中某几行的排他锁（行级锁）时，InnoDB 存储引擎会自动地先获取该表的意向排他锁（表级锁）
>
>---
>
>**为什么没有意向锁的话，表锁和行锁不能共存？**
>
>假设行锁和表锁能共存，举个例子：事务 T1 锁住表中的某一行（行级写锁），事务 T2 锁住整个表（表级写锁）。
>
>问题很明显，既然事务 T1 锁住了某一行，那么其他事务就不可能修改这一行。这与 ”事务 T2 锁住整个表就能修改表中的任意一行“ 形成了冲突。所以，没有意向锁的时候，行锁与表锁是无法共存的。
>
>-----
>
>**意向锁是如何让表锁和行锁共存的？**
>
>有了意向锁之后，事务 T1 在申请行级写锁之前，MySQL 会先自动给事务 T1 申请这张表的意向排他锁，当表上有意向排他锁时其他事务申请表级写锁会被阻塞，也即事务 T2 申请这张表的写锁就会失败。
>
>----
>
>`Innodb`内部维护意向锁





## 间隙锁

>间隙锁锁住一个间隙以防止插入。假设索引列有2, 4, 8 三个值，如果对 4 加锁，那么也会同时对(2,4)和(4,8)这两个间隙加锁。其他事务无法插入索引值在这两个间隙之间的记录。但是，间隙锁有个例外:
>
>1. 如果索引列是唯一索引，那么只会锁住这条记录(只加行锁)，而不会锁住间隙。
>2. 对于联合索引且是唯一索引，如果 where 条件只包括联合索引的一部分，那么依然会加间隙锁。
>
>`InnoDB`使用间隙锁的目的，一方面是为了防止幻读，以满足相关隔离级别的要求
>
>```mysql
>-- 用户A
>update user set count=8 where id>2 and id<6
>
>-- 用户B
>update user set count=10 where id=5;
>```
>
>如果用户`A`在进行了上述操作后，事务还未提交，则`B`无法对`2~6`之间的记录进行更新或插入记录，会阻塞，当`A`将事务提交后，`B`的更新操作会执行。





## 共享锁/排他锁

>- 共享锁 / 读锁：允许事务读（`select`）数据。**读锁是共享的**，或者说是相互不阻塞的。多个事务在同一时刻可以同时读取同一个资源，而互不干扰
>- 排他锁 / 写锁：允许事务删除（`delete`）或更新（`update`）数据。**写锁是排他的**，也就是说一个写锁会阻塞其他的读锁和写锁，这样就能确保在给定的时间里，只有一个事务能执行写入，并防止其他用户读取正在写入的同一资源。



## ==死锁 && 解决 && 预防==

>**死锁发生原因：**
>
>当两个及以上的事务，双方都在等待对方释放已经持有的锁或因为加锁顺序不一致造成循环等待锁资源，就会出现死锁。
>
>举例来说 A 事务持有 X1 锁 ，申请 X2 锁，B事务持有 X2 锁，申请 X1 锁。A 和 B 事务持有锁并且申请对方持有的锁进入循环等待，就造成了死锁。
>
>----
>
>**死锁的表现：**
>
>1. Mysql 增删改语句无法正常生效
>2. 使用Mysql GUI 工具编辑字段的值时，会出现异常。
>
>-----
>
>**死锁检测：**
>
>- 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数` innodb_lock_wait_timeout` 来设置。默认是`50`s，但是，我们又不可能直接把这个时间设置成一个很小的值，比如 `1s`。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。服务器压力比较大。
>- 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数` innodb_deadlock_detect` 设置为 `on`，表示开启这个逻辑。`innodb_deadlock_detect `的默认值本身就是` on`。
>
>**上述两种 是mysql自带的死锁检测机制。但是当真正遇到死锁，需要额外的检测手段**:
>
>1. 查看正在进行中的事务   `SELECT * FROM information_schema.INNODB_TRX`
>2. 查看正在锁的事务  `SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;` 
>3. 查看等待锁的事务 `SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS;`
>4. 查询是否锁表        `SHOW OPEN TABLES where In_use > 0;`       在发生死锁时，上述四种都可以查询到和当前死锁相关的信息。
>
>5. 查看最近死锁的日志   `show engine innodb status`
>
>**解除死锁： 最简单办法 是kill  掉当前进程**
>
>---
>
>**死锁条件：**
>
>满足死锁的四个条件：
>
>1. 互斥条件:一个资源每次只能一个进程使用
>2. 不可抢占：进程1在获取资源，使用的过程中，进程2不能抢占进程1正在使用的资源
>3. 占有且等待：进程在申请资源的时，不能释放已经持有的资源
>4. 循环等待:进程1等待进程2资源，同时进程2等待进程1持有的资源，出现循环等待的情况
>
>----
>
>**死锁预防**
>
>1. 合理的设计索引，区分度高的列放到组合索引前面，使业务 SQL 尽可能通过索引定位更少的行，减少锁竞争。
>2. 调整业务逻辑 SQL 执行顺序， 避免 `update/delete `长时间持有锁的 SQL 在事务前面。
>3. 避免大事务，尽量将大事务拆成多个小事务来处理，小事务发生锁冲突的几率也更小。
>4. 以固定的顺序访问表和行。比如两个更新数据的事务，事务 A 更新数据的顺序为 1，2;事务 B 更新数据的顺序为 2，1。这样更可能会造成死锁。
>5. 在并发比较高的系统中，不要显式加锁，特别是是在事务里显式加锁。如 `select … forupdate `语句，如果是在事务里（运行了 start transaction 或设置了autocommit 等于0）,那么就会锁定所查找到的记录。
>6. 尽量按主键/索引去查找记录，范围查找增加了锁冲突的可能性，也不要利用数据库做一些额外额度计算工作。比如有的程序会用到` “select … where … order by rand()；”`这样的语句，由于类似这样的语句用不到索引，因此将导致整个表的数据都被锁住。

##  ==事务隔离级别==

https://www.jianshu.com/p/8d735db9c2c0

>事物的四种特性
>
>1. 原子性： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；
>2. 一致性： 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的；，必须保证数据库的完整性
>3. 隔离性：数据库允许多个并发事务同时对数据进行操作，隔离性保证各个事务相互独立，事务处理时的中间状态对其它事务是不可见的，以此防止出现数据不一致状态。 也就是说任何事务都不可能看到一个处在不完整状态下的事务。
>4. 持久性： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。
>
>------------------
>
>当数据库上有多个事务同时执行的时候，就可能出现脏读（`dirty read`）、不可重复读（`non-repeatable read`）、幻读（`phantom read`）的问题
>
>- **脏读**：一个事务在对一条数据进行修改的过程中，其它的事务可以对数据进行读取。 所谓脏读是指一个事务中访问到了另外一个事务未提交的数据
>- **不可重复读**：一个事务在对数据进行读取的过程中，其它事务可以对此数据进行修改。
>- **幻读**：一个事务前后两次查询同一范围的数据过程中，其它事务可以在这个范围内插入新的数据。
>
>-------------------------------
>
>为了解决并发一致性问题，就有了**隔离级别**的概念。
>
>在` InnoDB` 中，默认为` Repeatable` 级别，`InnoDB` 中使用一种被称为 `next-key locking` 的策略来避免幻读（`phantom`）现象的产生。
>
>谈隔离级别之前，你首先要知道，你隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间寻找一个平衡点
>
>- 共享锁（读锁）：其他事务可以读，但不能写。
>- 排他锁（写锁） ：其他事务不能读取，也不能写。
>
>| 隔离级别 | 脏读   | 不可重复读 | 幻读   |
>| -------- | ------ | ---------- | ------ |
>| 读未提交 | 可能   | 可能       | 可能   |
>| 读提交   | 不可能 | 可能       | 可能   |
>| 可重复读 | 不可能 | 不可能     | 可能   |
>| 串行化   | 不可能 | 不可能     | 不可能 |
>
>**读未提交（RU）**所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。读取未提交的数据，也被称之为脏读（`Dirty Read`）。 对于脏读、不可重复度、幻读都没有解决
>
>**读已提交（RC）**一个事务只能看见已经提交事务所做的改变。 解决了脏读
>
>**可重复读（RR） **这是`MySQL`的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读 。简单的说，幻读指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有的幻影 行。`InnoDB`和`Falcon`存储引擎通过多版本并发控制（`MVCC，Multiversion Concurrency Control`）机制解决了该问题。              如何实现可重复读：   **快照度`mvvc` 当前读加行锁、**
>
>**串行化（serializable）**写会加写锁，读会加读锁。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。三个问题全部解决。

## `MVCC`

https://zhuanlan.zhihu.com/p/52977862

>- 数据库为什么要有事物：       为了保证数据最终的一致性。
>
>- 事务包括哪几个特性：           原子性、隔离性、一致性、持久性。
>
>- 事务的并发引起了哪些问题：事务并发会引起脏读、重复读、幻读问题。
>
>- 怎么解决事务并发出现的问题：设置事务隔离级别，读未提交，读提交，重复读，序列化。
>
>----
>
>
>
>**为什么需要MVVC 多版本并发控制：**
>
>数据库通常使用锁来实现隔离性。最原生的锁，锁住一个资源后会禁止其他任何线程访问同一个资源。但是很多应用的一个特点都是读多写少的场景，很多数据的读取次数远大于修改的次数，而读取数据间互相排斥显得不是很必要。所以就使用了一种读写锁的方法，读锁和读锁之间不互斥，而写锁和写锁、读锁都互斥。这样就很大提升了系统的并发能力。之后人们发现并发读还是不够，又提出了能不能让读写之间也不冲突的方法，就是读取数据时通过一种类似快照的方式将数据保存下来，这样读锁就和写锁不冲突了，不同的事务session会看到自己特定版本的数据。
>
>------
>
>
>
>##### 什么是`MVCC`:
>
>什么是`MVCC`：`MVCC`是在并发访问数据库时，通过对数据做多版本管理，**避免因为写锁的阻塞而造成读数据的并发阻塞问题**。通俗的讲就是`MVCC`通过保存数据的历史版本，根据比较版本号来处理数据的是否显示，从而达到读取数据的时候不需要加锁就可以保证事务隔离性的效果。
>
>-----
>
>
>
>**MVCC在四种隔离级别下的工作状态:**`
>
>`MVCC`只在  **读以提交** 和 **可重复度** 两个隔离级别下 工作。  
>
> 其他两个隔离级别够和`MVCC`不兼容, 因为 **读未提交** 总是读取最新的数据行, 而不是符合当前事务版本的数据行。而 **串行化** 则会对所有读取的行都加锁。
>
>-----
>
>
>
>#### MVVC在可重复度读隔离级别下是如何工作的？
>
>##### 查询（SELECT）
>
> 1. InnoDB只查找版本早于当前事务版本的数据行（也就是，行的系统版本号小于或等于事务的系统版本号），这样可以**确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的**。
>2. 行的删除版本要么未定义，要么大于当前事务版本号。这可以确保**事务读取到的行，在事务开始之前未被删除**。
>
>只有符合上述两个条件的记录，才能返回作为查询结果。
> 
>##### 插入（INSERT）：InnoDB为新插入的每一行保存当前系统版本号作为行版本号。
> 
>##### 删除（DELETE）：InnoDB为删除的每一行保存当前系统版本号作为行删除标识。删除在内部被视为更新，行中的一个特殊位会被设置为已删除。
>
>##### 更新（UPDATE）：InnoDB为插入一行新记录，保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为行删除标识。
> 
>-----
> 
>
>
>#### InnoDB 是如何存储记录的多个版本的? 或者MVCC是如何进行实现的。
>
>1. 事务版本号：每开启一个事务，我们都会从数据库中获得一个事务 ID（也就是事务版本号），这个事务 ID 是自增长的，通过 ID 大小，我们就可以判断事务的时间顺序。
>2. 行记录的隐藏列：`InnoDB` 的叶子段存储了数据页，数据页中保存了行记录
>3. `undo log` :  主要用于记录数据被修改之前的日志，在表信息修改之前先会把数据拷贝到`undo log` 里，当事务进行回滚时可以通过`undo log` 里的日志进行数据还原。
>4. `read view`:  在`innodb `中每个`SQL`语句执行前都会得到一个`read_view`。副本主要保存了当前数据库系统中正处于活跃（没有`commit`）的事务的ID号，其实简单的说这个副本中保存的是系统中当前不应该被本事务看到的其他事务id列表。
>
>
>
>----
>
>##### **快照读和当前读区别：**
>
>快照读:
>
>快照读是指读取数据时不是读取最新版本的数据，而是基于历史版本读取的一个快照信息（`mysql`读取`undo log`历史版本) ，快照读可以使普通的`SELECT `读取数据时不用对表数据进行加锁，从而解决了因为对数据库表的加锁而导致的两个如下问题
>
>1、解决了因加锁导致的修改数据时无法对数据读取问题;
>
>2、解决了因加锁导致读取数据时无法对数据进行修改的问题;
>
>当前读:
>
>当前读是读取的数据库最新的数据，当前读和快照读不同，因为要读取最新的数据而且要保证事务的隔离性，所以当前读是需要对数据进行加锁的（`Update delete insert select ....lock in share mode select for update `为当前读）





# 场景提

## 字段类型 int1和int10有什么区别 

## 字段类型 cha和varchan在比较的时候有什么区别

## MySQL在生产环境中如何进行主库的切换，并且切换过程不影响业务的执行？

>https://blog.csdn.net/u014106644/article/details/104178547



## 唯一索引和普通索引 vs 主键

>区别：
>
>普通索引和唯一索引   ： 普通索引就是可以重复 唯一索引可以有多个 主键但是就只能有一个被
>
>普通索引可以重复，唯一索引和主键一样不能重复。 唯一索引可以作为数据的一个合法验证手段，例如学生表的身份证号码字段，我们人为规定该字段不得重复，那么就使用唯一索引。（一般设置学号字段为主键） 主键和唯一索引 主键保证数据库里面的每一行都是唯一的，比如身份证，学号等，在表中要求唯一，不重复。唯一索引的作用跟主键的作用一样。 不同的是，在一张表里面只能有一个主键，主键不能为空，唯一索引可以有多个，唯一索引可以有一条记录为空，即保证跟别人不一样就行。 比如学生表，在学校里面一般用学号做主键，身份证则弄成唯一索引；而到了教育局，他们就把身份证号弄成主键，学号换成了唯一索引。 
>
>------------------
>
>`B+`树：
>
>![b+树](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2014/7af22798.jpg)
>
>`B+`树查找过程：
>
>如图所示，如果要查找数据项`29`，那么首先会把磁盘块1由磁盘加载到内存，此时发生一次`IO`，在内存中用二分查找确定`29在17和35`之间，锁定磁盘块1的`P2`指针，内存时间因为非常短（相比磁盘的`IO`）可以忽略不计，通过磁盘块1的`P2`指针的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO，29在26和30之间，锁定磁盘块3的P2指针，通过指针加载磁盘块8到内存，发生第三次IO，同时内存中做二分查找找到29，结束查询，总计三次IO。真实的情况是，3层的b+树可以表示上百万的数据，如果上百万的数据查找只需要三次IO，性能提高将是巨大的，如果没有索引，每个数据项都要发生一次IO，那么总共需要百万次的IO，显然成本非常非常高。
>
>通过上面的分析，我们知道IO次数取决于b+数的高度h，假设当前数据表的数据为N，每个磁盘块的数据项的数量是m，则有`h=㏒(m+1)N`，当数据量N一定的情况下，m越大，h越小；而m = 磁盘块的大小 / 数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的，如果数据项占的空间越小，数据项的数量越多，树的高度越低。这就是为什么每个数据项，即索引字段要尽量的小，比如`int`占4字节，要比`bigint8`字节少一半。这也是为什么`b+`树要求把真实的数据放到叶子节点而不是内层节点，一旦放到内层节点，磁盘块的数据项会大幅度下降，导致树增高。当数据项等于1时将会退化成线性表。
>
>-------------------
>
>示例：
>
>一个市民系统，每个人都有个唯一身份证号；业务代码已保证不会写入两个重复的身份证号；如果市民系统需要按照身份证号查姓名，就会执行类似`SQL：`
>
>```mysql
>select name from CUser where id_card = 'xxxxxxxyyyyyyzzzzz';
>```
>
>相信你一定会在`id_card`字段上建索引。
>
>由于身份证号字段比较大，不建推荐把身份证号做主键。
>因此现在有两个选择
>
>1. 给`id_card`字段创建唯一索引
>2. 创建一个普通索引
>
>如果业务代码已保证不会写入重复的身份证号，那这两个选择逻辑上都正确。
>
>但从性能角度考虑，唯一索引还是普通索引呢？
>假设字段 `k `上的值都不重复。
>
>- InnoDB的索引组织结构![img](https://img-blog.csdnimg.cn/20200725201145788.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMzNTg5NTEw,size_1,color_FFFFFF,t_70)
>  接下来从这两种索引对查询语句和更新语句的性能影响来进行分析。
>
>---------------
>
>查询语句:
>
>```
>select id from T where k=5
>```
>
>该语句在索引树查找的过程：
>先通过B+树从树根开始，按层搜索到叶节点，即图中右下角的数据页，然后可认为数据页内部是通过二分法定位记录。
>
>- 对普通索引，查找到满足条件的第一个记录(5,500)后，需查找下个记录，直到碰到第一个不满足k=5条件的记录
>- 对唯一索引，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止检索。
>
>该不同点带来的性能差距会有多少呢？
>微乎其微！
>
>`InnoDB`数据是按数据页为单位读写。即当需读一条记录时，并非将该记录本身从磁盘读出，而是以页为单位，将其整体读入内存。
>
>`InnoDB`中，每个数据页的大小默认是`16KB。`
>
>因引擎按页读写，所以，当找到`k=5`记录时，它所在数据页就都在内存了。
>对普通索引，要多做的那一次“查找和判断下一条记录”的操作，就只需要一次指针寻找和一次计算。
>如果`k=5`记录刚好是该数据页的最后一个记录，那么要取下个记录，必须读取下个数据页，操作会稍微复杂。
>对于整型字段，一个数据页可存近千个`key`，因此这种情况概率很低。所以，计算平均性能差异时，仍可认为该操作成本对现在的CPU可忽略不计。



## 字符串 前缀索引 hash索引

>由于要使用邮箱登录，所以业务代码中一定会出现类似于这样的语句：
>
>```mysql
>mysql> select f1, f2 from SUser where email='xxx';
>```
>
>们可以知道，如果` email `这个字段上没有索引，那么这个语句就只能做全表扫描。
>
>同时，`MySQL` 是支持前缀索引的，也就是说，你可以定义字符串的一部分作为索引。默认地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。
>
>比如，这两个在` email `字段上创建索引的语句：
>
>```mysql
>mysql> alter table SUser add index index1(email);
>或
>mysql> alter table SUser add index index2(email(6));
>```
>
>第一个语句创建的` index1 `索引里面，包含了每个记录的整个字符串；而第二个语句创建的 `index2` 索引里面，对于每个记录都是只取前 `6` 个字节。
>
>**如果使用的是 index1**（即 email 整个字符串的索引结构），执行顺序是这样的：
>
>1. 从 index1 索引树找到满足索引值`’zhangssxyz@xxx.com`的这条记录，取得 ID2 的值；
>2. 到主键上查到主键值是 ID2 的行，判断 email 的值是正确的，将这行记录加入结果集；
>3. 取 index1 索引树上刚刚查到的位置的下一条记录，发现已经不满足` email='zhangssxyz@xxx.com’`的条件了，循环结束。
>
>这个过程中，只需要回主键索引取一次数据，所以系统认为只扫描了一行。
>
>
>
>**如果使用的是 index2**（即` email(6)` 索引结构），执行顺序是这样的：
>
>1. 从` index2  `索引树找到满足索引值是`’zhangs’`的记录，找到的第一个是 `ID1；`
>2. 到主键上查到主键值是` ID1` 的行，判断出 `email `的值不是`’zhangssxyz@xxx.com’，`这行记录丢弃；
>3. 取 `index2` 上刚刚查到的位置的下一条记录，发现仍然是`’zhangs’`，取出 ID2，再到 ID 索引上取整行然后判断，这次值对了，将这行记录加入结果集；
>4. 重复上一步，直到在 idxe2 上取到的值不是’zhangs’时，循环结束。
>
>
>
>总结：
>
>我们在建立索引时关注的是区分度，区分度越高越好。因为区分度越高，意味着重复的键值越少。因此，我们可以通过统计索引上有多少个不同的值来判断要使用多长的前缀。也就是说**使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。**
>
>--------------------
>
>
>
>**第一种方式是使用倒序存储。**如果你存储身份证号的时候把它倒过来存，每次查询的时候，你可以这么写：
>
>```
>mysql> select field_list from t where id_card = reverse('input_id_card_string');
>复制代码
>```
>
>由于身份证号的最后 6 位没有地址码这样的重复逻辑，所以最后这 6 位很可能就提供了足够的区分度。当然了，实践中你不要忘记使用 count(distinct) 方法去做个验证。
>
>
>
>**第二种方式是使用 hash 字段。**你可以在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。
>
>```mysql
>mysql> alter table t add id_card_crc int unsigned, add index(id_card_crc);
>```
>
>然后每次插入新记录的时候，都同时用 `crc32() `这个函数得到校验码填到这个新字段。由于校验码可能存在冲突，也就是说两个不同的身份证号通过` crc32() `函数得到的结果可能是相同的，所以你的查询语句 where 部分要判断 id_card 的值是否精确相同。
>
>```mysql
>mysql> select field_list from t where id_card_crc=crc32('input_id_card_string') and id_card='input_id_card_string'
>```
>
>这样，索引的长度变成了 4 个字节，比原来小了很多。
>
>接下来，我们再一起看看**使用倒序存储和使用 hash 字段这两种方法的异同点。**
>
>首先，它们的相同点是，都不支持范围查询。倒序存储的字段上创建的索引是按照倒序字符串的方式排序的，已经没有办法利用索引方式查出身份证号码在 [ID_X, ID_Y] 的所有市民了。同样地，hash 字段的方式也只能支持等值查询。



>https://juejin.cn/post/6844903750839058446#heading-109  优化问题
>
>

## 删除一个表里面的前 10000 行数据

>最后，我给你留下一个问题吧。如果你要删除一个表里面的前` 10000 `行数据，有以下三种方法可以做到：
>
>- 第一种，直接执行 `delete from T limit 10000;`
>- 第二种，在一个连接中循环执行 `20 次 delete from T limit 500;`
>- 第三种，在 `20 `个连接中同时执行` delete from T limit 500。`
>
>你会选择哪一种方法呢？为什么呢？
>
>第二种方式，即：在一个连接中循环执行 `20 次 delete from T limit 500`。确实是这样的，第二种方式是相对较好的。
>
>第一种方式（即：直接执行` delete from T limit 10000`）里面，单个语句占用时间长，锁的时间也比较长；而且大事务还会导致主从延迟。
>
>第三种方式（即：在 20 个连接中同时执行 `delete from T limit 500`），会人为造成锁冲突。





## 是每条事务执行前都会进行死锁检测吗

> 如果他要加锁访问的行上有锁，他才要检测。
>
> 1. 一致性读不会加锁，就不需要做死锁检测；
>
> 2. 并不是每次死锁检测都都要扫所有事务。比如某个时刻，事务等待状态是这样的：
>
>    `B`在等`A`，
>    `D`在等`C`，
>    现在来了一个`E`，发现`E`需要等`D`，那么E就判断跟D、C是否会形成死锁，这个检测不用管B和A





## 自增id  自增id用完怎么办？

>1. 表的自增` id `达到上限后，再申请时它的值就不会改变，进而导致继续插入数据时报主键冲突的错误。
>2. 如果你创建的 `InnoDB` 表没有指定主键，那么` InnoDB `会给你创建一个不可见的，长度为 `6` 个字节的 `row_id`,`row_id` 达到上限后，则会归 `0` 再重新递增，如果出现相同的` row_id`，后写的数据会覆盖之前的数据。 
>3. thread_id 是我们使用中最常见的，而且也是处理得最好的一个自增 id 逻辑了



## ==mysql主键自增和UUID的区别==

>1、自增主键
>在进行数据库插入时，位置相对固定（B+树中的右下角）增加数据插入效率，减少插入的磁盘IO消耗，每页的空间在填满的情况下再去申请下一个空间，底层物理连续性更好，能更好的支持区间查找
>
>2、UUID
>由于UUID是随机生成的 插入时位置具有一定的不确定性，无序插入，会存在许多内存碎片，内存空间的占用量也会比自增主键大，区间查找也没自增主键性能优

## 设计一个高考查分系统，几亿人访问，秒级反馈

>我刚开始的回答是Redis 集群模式，但是面试官提示说高考查询成绩查询次数多吗，需要用到缓存吗🤣🤣，然后答案应该是采取分库分表，将考生号进行hash存放在不同的数据库中。一般这种题可以先回答一个不那么完美的答案，然后面试官会有提示😁



## ==设计聊天功能==

>1. 未读消息列表，时间倒序
>2. 点进会话，定会上次已读位置
>3. 未读消息需要显示其未读的数量
>     要求：需要设计哪些表，哪些必要字段 单聊如何实现 群聊如何实现
>
>三张表，一个用户表，一个消息表，一个群表；
>消息（创建时间，有个是否已读字段，版本号，发送方和接收方（userId || groupId））创建时间实现倒序、版本号实现定位
>群表 id 和用户list 
>
>https://blog.csdn.net/u010098331/article/details/51493016
>
>------
>
>```mysql
># 用户表
>ma_im_user {
>  id,           // ID 
>  re_id,        // 关联ID
>  re_type,      // 关联类型
>  avatar,       // 头像
>  nick_name,    // 昵称
>  sex,          // 性别
>  program_id,   // 应用ID
>  updated_at,   // 更新时间
>  created_at,   // 创建时间
>}
>
># 用户好友
>ma_im_user_friend {
>  id,           // ID
>  user_id,      // 用户ID
>  friend_id,    // 好友ID
>  status,       // 状态 0=删除 1=正常
>  program_id,   // 应用ID
>  updated_at,   // 更新时间
>  created_at,   // 创建时间
>}
>
># 群组
>ma_im_room {
>  id,           // ID
>  sn,           // 编号
>  name,         // 名称
>  logo,         // 图标
>  desc,         // 描述
>  number,       // 成员数（冗余字段）
>  program_id,   // 应用ID
>  updated_at,   // 更新时间
>  created_at,   // 创建时间
>}
>
># 用户群组
>ma_im_user_room {
>  id,           // ID
>  user_id,      // 用户ID
>  room_id,      // 群组ID
>  status,       // 状态 0=删除 1=正常
>  program_id,   // 应用ID
>  updated_at,   // 更新时间
>  created_at,   // 创建时间
>}
>
># 聊天室
>ma_im_chat {
>  id,           // ID
>  re_id,        // 关联ID
>  re_type,      // 关联类型 群组（1个）、好友（2个）
>  new_id,       // 最新消息ID
>  program_id,   // 应用ID
>  updated_at,   // 更新时间
>  created_at,   // 创建时间
>}
>
># 聊天室消息
>ma_im_chat_msg {
>  id,           // ID
>  uuid,         // 唯一消息标识 (时间戳（毫秒）+ 聊天室ID + 机子编号 + 序号)
>  chat_id,      // 聊天室ID
>  type,         // 类型 0=消息 1=图片 2=图文 4=卡片
>  content,      // 消息内容 JSON
>  program_id,   // 应用ID
>  updated_at,   // 更新时间
>  created_at,   // 创建时间
>}
>
># 用户聊天室
>ma_im_user_chat {
>  id,           // ID
>  user_id,      // 用户ID
>  chat_id,      // 聊天室ID
>  read_id,      // 已阅读消息ID
>  re_id,        // 关联ID
>  re_type,      // 关联类型 用户、群组
>  status,       // 状态 0=删除 1=正常
>  program_id,   // 应用ID
>  updated_at,   // 更新时间
>  created_at,   // 创建时间
>}
>```
>



## 大数据量,mysql需要如何处理

>https://www.zhihu.com/question/19719997					这个就是挺好
>
>https://www.cnblogs.com/520playboy/p/6275233.html
>
>![preview](https://pic1.zhimg.com/v2-0deb7c3dff1051fee85baf6daa4bd219_r.jpg?source=1940ef5c)
>
>很多人第一反应是各种切分；我给的顺序是:
>
>1. 第一优化你的sql和索引；
>
>2. 第二加缓存，memcached,redis;
>
>3. 第三以上都做了后，还是慢，就做主从复制或主主复制，读写分离，可以在应用层做，效率高，也可以用三方工具，第三方工具推荐360的atlas,其它的要么效率不高，要么没人维护;
>
>4. 第四如果以上都做了还是慢，不要想着去做切分，mysql自带分区表，先试试这个，对你的应用是透明的，无需更改代码,但是sql语句是需要针对分区表做优化的，sql条件中要带上分区条件的列，从而使查询定位到少量的分区上，否则就会扫描全部分区，另外分区表还有一些坑，在这里就不多说了；
>
>5. 第五如果以上都做了，那就先做垂直拆分，其实就是根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统；
>
>6. 第六才是水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding key,为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表；
>
>
>
>mysql数据库一般都是按照这个步骤去演化的，成本也是由低到高；
>
>有人也许要说第一步优化sql和索引这还用说吗？的确，大家都知道，但是很多情况下，这一步做的并不到位，甚至有的只做了根据sql去建索引，根本没对sql优化（中枪了没？），除了最简单的增删改查外，想实现一个查询，可以写出很多种查询语句，不同的语句，根据你选择的引擎、表中数据的分布情况、索引情况、数据库优化策略、查询中的锁策略等因素，最终查询的效率相差很大；优化要从整体去考虑，有时你优化一条语句后，其它查询反而效率被降低了，所以要取一个平衡点；即使精通mysql的话，除了纯技术面优化，还要根据业务面去优化sql语句，这样才能达到最优效果；你敢说你的sql和索引已经是最优了吗?
>
>再说一下不同引擎的优化，myisam读的效果好，写的效率差，这和它数据存储格式，索引的指针和锁的策略有关的，它的数据是顺序存储的（innodb数据存储方式是聚簇索引），他的索引btree上的节点是一个指向数据物理位置的指针，所以查找起来很快，（innodb索引节点存的则是数据的主键，所以需要根据主键二次查找）；myisam锁是表锁，只有读读之间是并发的，写写之间和读写之间（读和插入之间是可以并发的，去设置concurrent_insert参数，定期执行表优化操作，更新操作就没有办法了）是串行的，所以写起来慢，并且默认的写优先级比读优先级高，高到写操作来了后，可以马上插入到读操作前面去，如果批量写，会导致读请求饿死，所以要设置读写优先级或设置多少写操作后执行读操作的策略;myisam不要使用查询时间太长的sql，如果策略使用不当，也会导致写饿死，所以尽量去拆分查询效率低的sql,
>
>innodb一般都是行锁，这个一般指的是sql用到索引的时候，行锁是加在索引上的，不是加在数据记录上的，如果sql没有用到索引，仍然会锁定表,mysql的读写之间是可以并发的，普通的select是不需要锁的，当查询的记录遇到锁时，用的是一致性的非锁定快照读，也就是根据数据库隔离级别策略，会去读被锁定行的快照，其它更新或加锁读语句用的是当前读，读取原始行；因为普通读与写不冲突，所以innodb不会出现读写饿死的情况，又因为在使用索引的时候用的是行锁，锁的粒度小，竞争相同锁的情况就少，就增加了并发处理，所以并发读写的效率还是很优秀的，问题在于索引查询后的根据主键的二次查找导致效率低；
>
>ps:很奇怪，为什innodb的索引叶子节点存的是主键而不是像mysism一样存数据的物理地址指针吗？如果存的是物理地址指针不就不需要二次查找了吗，这也是我开始的疑惑，根据mysism和innodb数据存储方式的差异去想，你就会明白了，我就不费口舌了！
>
>所以innodb为了避免二次查找可以使用索引覆盖技术，无法使用索引覆盖的，再延伸一下就是基于索引覆盖实现延迟关联；不知道什么是索引覆盖的，建议你无论如何都要弄清楚它是怎么回事！
>
>尽你所能去优化你的sql吧！说它成本低，却又是一项费时费力的活，需要在技术与业务都熟悉的情况下，用心去优化才能做到最优，优化后的效果也是立竿见影的！



## Redis与MySQL双写一致性如何保证？

>https://juejin.cn/post/6964531365643550751



## 怎么查看数据库是否使用索引了

>https://www.cnblogs.com/acm-bingzi/p/mysqlExplain.html  
>
>explain显示了MySQL如何使用索引来处理select语句以及连接表。可以帮助选择更好的索引和写出更优化的查询语句。简单讲，它的作用就是分析查询性能。
>
>explain关键字的使用方法很简单，就是把它放在select查询语句的前面。
>
>mysql查看是否使用索引，简单的看type类型就可以。如果它是all，那说明这条查询语句遍历了所有的行，并没有使用到索引。
>
>依次从好到差：`system，const，eq_ref，ref，fulltext，ref_or_null，unique_subquery，index_subquery，range，index_merge，index，ALL，`除了all之外，其他的type都可以使用到索引，除了index_merge之外，其他的type只可以用到一个索引



# ==-----------------------------------------------------------------------------redis==





https://www.jianshu.com/p/9d8296562806  跳表的数据结构 讲解的不错

# ==基本数据结构和使用场景== 

![image-20220221122224302](/Users/whig/Library/Application Support/typora-user-images/image-20220221122224302.png)

# ![img](https://static001.geekbang.org/resource/image/82/01/8219f7yy651e566d47cc9f661b399f01.jpg)

>--------
>
>**string 动态字符串：**
>
>- 底层数据结构：
>
>动态字符串，底层实现有点类似于 Java 中的 **ArrayList**，内部SDS结构体中泛型定义了好多次。因为当字符串比较短的时候，len 和 alloc 可以使用 byte 和 short 来表示，**Redis 为了对内存做极致的优化，不同长度的字符串使用不同的结构体来表示**。
>
>扩容机制：当字符串的长度小于 1MB时，每次扩容都是加倍现有的空间。如果字符串长度超过 1MB时，每次扩容时只会扩展 1MB 的空间。**字符串最大长度为** **`512MB`.**。
>
>- 应用场景
>
>1. 简单 kEY VALUE存储  例如手机验证码
>
>2. SETEX==SET + EXPIRE (对有所KEY类型都成立 )设置过期时间  例如就是12306 淘宝订单 手机验证码等操作
>3. INCR 计数：博客访问数量         ` incr   [key]   如果value为整数 可用 incr命令每次自增1`
>4. 分布式 session共享
>
>--------
>
>**list 压缩链表和双向链表：**
>
>- 底层数据结构：`redis`配置文件---> 压缩列表转双向链表
>
>```xml
>单字符串的值长度超过 server.list_max_ziplist_value （默认值为 64 ）。
>ziplist 包含的节点超过 server.list_max_ziplist_entries （默认值为 512 ）。
>```
>
>`Redis`中的`list`和`Java`中的`LinkedList`很像，底层都是一种链表结构， `list`的插入和删除操作非常快，时间复杂度为 0(1)，不像数组结构插入、删除操作需要移动数据。当数据量较少的时候它的底层存储结构为一块连续内存，称之为`ziplist(压缩列表)`，它将所有的元素紧挨着一起存储，分配的是一块连续的内存；当数据量较多的时候将会变成`quicklist(快速链表)：：ziplist+双向链表`结构。
>
>缺点：可单纯的链表也是有缺陷的，链表的前后指针 `prev` 和 `next` 会占用较多的内存，会比较浪费空间，而且会加重内存的碎片化。
>
>- 应用场景
>
>1. 消息队列：`lpop`和`rpush`（或者反过来，`lpush`和`rpop`）能实现队列的功能   同理可以实现栈的功能 `rpush  [key] [value1] [value2] `
>
>2. 朋友圈的点赞列表、评论列表、排行榜：`lpush`命令和`lrange`命令能实现最新列表的功能，每次通过`lpush`命令往列表里插入新的元素，然后通过`lrange`命令读取最新的元素列表    `lrange [key]  [start_index] [end_index]   `获取集合元素 时间复杂度为O（n）
>
>--------
>
>**hash：**
>
>- hash表+压缩列表： 超过这个长度就会转化为hash表
>
>```xml
>/*redis.conf配置*/
>hash-max-ziplist-value 64     //ziplist中最大能存放的值长度
>hash-max-ziplist-entries 512  //ziplist中最多能存放的entry节点数量
>```
>
>Redis 中的字典结构相当于 Java 中的 **HashMap**，内部实现也差不多类似，都是通过 **"数组 + 链表"** 的链地址法来解决部分 **哈希冲突**。**内部包含两个 hashtable**，通常情况下只有一个 hashtable 是有值的，但是在字典扩容缩容时，需要分配新的 hashtable，然后进行 **渐进式搬迁**。如果一次性将表0迁移到表1这种操作O(n) 级别的，作为单线程的 Redis 很难承受这样耗时的过程，所以 Redis 使用 **渐进式 rehash** 小步搬迁：是分多次、渐进式的完成的。目的：如果服务器中包含很多键值对，要一次性的将这些键值对全部rehash到ht[1]的话，庞大的计算量可能导致服务器在一段时间内停止服务于。
>
>`Hash` 和`String`都可以用来存储用户信息 ，但不同的是`Hash`可以对用户信息的每个字段单独存储
>
>- 应用场景
>
>1. 购物车：`hset [key] [field] [value]` 命令， 可以实现以`用户Id`，`商品Id`为`field`，商品数量为`value`，恰好构成了购物车的3个要素。
>
>2. 存储对象：`hash`类型的`(key, field, value)`的结构与对象的`(对象id, 属性, 值)`的结构相似，也可以用来存储对象。
>
>-------
>
>**set：**
>
>- Hash + 压缩列表：
>
>```xml
>hash-max-ziplist-value 64     //ziplist中最大能存放的值长度
>hash-max-ziplist-entries 512  //ziplist中最多能存放的entry节点数量
>一个哈希对象超过配置的阈值（键和值的长度有>64byte，键值对个数>512个）时，会转换成哈希表（hashtable）。
>```
>
>Redis 的集合相当于 Java 语言中的 **HashSet**，它内部的键值对是**无序、唯一**的。它的内部实现相当于一个特殊的字典，字典中所有的 value 都是一个值 NULL。当集合中最后一个元素被移除之后，数据结构被自动删除，内存被回收。
>
>- 当数据较少时，sorted set是由一个ziplist来实现的。
>- 当数据多的时候，sorted set是由一个叫zset的数据结构来实现的，这个zset包含一个dict + 一个skiplist。dict用来查询数据到分数(score)的对应关系，而skiplist用来根据分数查询数据（可能是范围查找）。
>
>- 应用场景
>
>1. 交集、并集、差集的操作，比如交集，可以把两个人的粉丝列表整一个交集。利用唯一性
>
>2. 存储某活动中中奖的用户ID ，因为有去重功能，可以保证同一个用户不会中奖两次。
>
>------
>
>**zset：**
>
>- 跳表 + 压缩列表 ：在`redis conif` 可以配置
>
>```xml
>1、zset-max-ziplist-entries 128:zset 采用压缩列表时，元素个数最大值。默认值为128。
>2、zset-max-ziplist-value 64:zset    采用压缩列表时，每个元素的字符串长度最大值。默认值为64。
>zset在转为跳跃表之后，即使元素被逐渐删除，也不会重新转为压缩列表。
>```
>
>它类似于 Java 中 **SortedSet** 和 **HashMap** 的结合体，一方面它是一个 set，保证了内部 value 的唯一性，另一方面它可以为每个 value 赋予一个 score 值，用来代表排序的权重。它的内部实现用的是一种叫做 **「跳跃表」** 的数据结构
>
>- 应用场景
>
>1. 排行榜功能或者topN功能。
>2. 交集、并集、差集的操作，比如交集，可以把两个人的粉丝列表整一个交集。利用唯一性
>2. 存储某活动中中奖的用户ID ，因为有去重功能，可以保证同一个用户不会中奖两次。

-----

>还有几种不常见的就是  **Geo** 这个就是关于地理的      **HyperLogLog**关于计数的



## 跳表 Skip List

>![img](http://zhangtielei.com/assets/photos_redis/skiplist/skiplist_insertions.png)
>
>跳跃表以有序的方式在层次化的链表中保存元素， 效率和平衡树媲美 —— 查找、删除、添加等操作都可以在对数期望时间下完成， 并且比起平衡树来说， 跳跃表的实现要简单直观得多。
>
>1. **跳跃表 skiplist** 就是受到多层链表结构的启发而设计出来的。上面的每一层链表的节点个数，是下面一层的节点个数的一半，这样查找过程就非常类似于一个二分查找，使得查找的时间复杂度可以降低到 *O(logn)*。
>
>2. 但是，这种方法在插入数据的时候有很大的问题。新插入一个节点之后，就会打乱上下相邻两层链表上节点个数严格的 2:1 的对应关系。如果要维持这种对应关系，就必须把新插入的节点后面的所有节点 *（也包括新插入的节点）* 重新进行调整，这会让时间复杂度重新蜕化成 *O(n)*。删除数据也有同样的问题。
>
>3. **redis skiplist** 为了避免这一问题，它不要求上下相邻两层链表之间的节点个数有严格的对应关系，而是 **为每个节点随机出一个层数(level)**。比如，一个节点随机出的层数是 3，那么就把它链入到第 1 层到第 3 层这三层链表中。
>
>----
>
>##### 随机层数
>
>在redis中，**返回一个随机层数值**，随机算法所使用的**幂次定律**。
>
>- 含义是：**如果某件事的发生频率和它的某个属性成幂关系，那么这个频率就可以称之为符合幂次定律。**
>- 表现是：**少数几个事件的发生频率占了整个发生频率的大部分， 而其余的大多数事件只占整个发生频率的一个小部分。**
>
>1. 节点层数恰好等于1的概率为p^0(1-p)。
>
>2. 节点层数恰好等于2的概率为p^1(1-p)。
>
>3. 节点层数恰好等于3的概率为p^2(1-p)。
>
>4. 节点层数恰好等于4的概率为p^3(1-p)。
>
>5. 依次递推节点层数恰好等于K的概率为p^(k-1)(1-p)
>
><img src="https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/12/28/16f4cc7ce547fe00~tplv-t2oaga2asx-no-mark:1280:960:0:0.awebp" alt="img" style="zoom:50%;" />
>
>结点层数的期望值与1-p成反比。 **对于Redis而言，当p=0.25时结点层数的期望是1.33。**



## 为什么选择跳表而不选择红黑树

>Redis 中的有序集合(zset) 支持的操作：
>
>1. 插入一个元素
>2. 删除一个元素
>3. 查找一个元素
>4. 有序输出所有元素
>5. 按照范围区间查找元素（比如查找值在 [100, 356] 之间的数据）
>
>其中，前四个操作红黑树也可以完成，且时间复杂度跟跳表是一样的。但是，按照区间来查找数据这个操作，红黑树的效率没有跳表高。按照区间查找数据时，跳表可以做到 O(logn) 的时间复杂度定位区间的起点，然后在原始链表中顺序往后遍历就可以了，非常高效。







## hash表是如何进行扩容？

>**redis扩容条件**：
>
>1. 子进程没有执行aof文件重写或者生成RDB文件（BGSAVE或BGREWRITEAOF命令）持久化命令，并且哈希表负载因子大于等于1，哈希表中保存的key数量超过了哈希表的大小，则会进行扩容。
>2. 当前子进程执行执行aof文件重写或者生成RDB文件（持久化命令），为了提高子进程使用效率，服务器会提高执行扩容操作所需的负载因子默认是5，就会进行强制扩容，从而尽可能避免在子进程存在期间进行哈希表扩展操作，这可以避免不必要的内存写入，最大限度的节约空间。
>
>缩容条件：
>
>1. **元素个数低于数组长度的 10%**，缩容不会考虑 Redis 是否在做 持久化操作。　
>
>---------
>
>**扩容机制**：不必说：单线程渐进式rehash里的单线程是指只有一个线程在扩容，而在扩容的同时其他的线程可以并发的进行读写。
>
>**如果一次性将表0迁移到表1这种操作O(n) 级别的，作为单线程的 Redis 很难承受这样耗时的过程，所以 Redis 使用 渐进式 rehash 小步搬迁：是分多次、渐进式的完成的。目的：如果服务器中包含很多键值对，要一次性的将这些键值对全部rehash到ht[1]的话，庞大的计算量可能导致服务器在一段时间内停止服务于。**
>
>　　1、为ht[1]分配空间，让字典同时持有ht[0]和ht[1]两个哈希表。表1的大小要取决去表0：h[1]大小==ht[0].used*2的2^n；
>
>　　2、在字典中维持一个索引计数器变量rehashidx，并将它置为0，表示rehash工作开始。
>
>　　3、在rehash进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定操作以外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]中，当rehash工作完成之后，程序将rehashidx属性的值+1。
>
>　　4、随着字典操作的不断进行，最终在某个时间点上，ht[0]的所有键值对都被rehash到ht[1]上，这时将rehashidx属性设为-1，表示rehash完成。
>
>　　**渐进式rehash** 的好处在于其采取分而治之的方式，将rehash键值对所需要的计算工作均摊到字典的每个添加、删除、查找和更新操作上，从而避免了集中式rehash而带来的庞大计算量。
>
>因为在渐进式rehash的过程中，字典会同时使用ht[0]和ht[1]两个哈希表，所以在渐进式rehash进行期间，字典的删除、查找、更新等操作都是在两个表上进行的。
>
>　　1. 查找操作会先在ht[0]上进行，如果没找到再在ht[1]上进行。
>  　　2. 添加操作的键值对会一律保存到ht[1]中，这一措施保证ht[0]包含的键值对只会减少不会增加。
>
>---------
>
>**HashMap扩容机制：**
>
>扩容阈值 `threshold == capacity * load factor`
>
>扩容机制： `resize()`
>
>1. 第一次`put`操作也会触发扩容机制，懒加载；
>
>  -----指定初始化容量了：		`cap==threshold=2^n     threshold == capacity * load factor`
>
>  -----没有指定初始化容量：    `cap=16   threshold =12 =capacity * load factor`
>
>2. 当`put`操作时,`Node`节点个数`size>threshold`   `size`表示`K V`键值对 
>
>3. 当`put`操作 链表节点个数大于`8`个 判断是否可以树化的时候 并且 数组长度`len<64`个  这时候进行扩容
>
>扩容优化
>
>1. `HashMap`不是第一次扩容。如果`HashMap`已经扩容过的话，那么每次`table`的容量以及`threshold`量为原有的两倍。
>
>-----
>
>**ConcurrentHashMap扩容机制：**
>
>而ConcurrentHashMap采用的扩容策略为： “**多线程协同式rehash**“。这里的多线程指的是，有多个线程并发的把数据从旧的容器搬运到新的容器中。
>
>扩容时大致过程如下：ConcurrentHashMap 扩容是从数组队尾开始拷贝，拷贝槽点时会锁住槽点，拷贝完成后将槽点设置为转移节点。所以槽点拷贝完成后将新数组赋值给容器
>
>线程A在扩容把数据从oldTable搬到到newTable，这时其他线程
>
>1. 进行get操作：这个线程知道数据存放在oldTable或是newTable中，直接取即可。
>
>2. 进行写操作：如果要写的桶位，已经被线程A搬运到了newTable。那么这个线程知道正在扩容**，它也一起帮着扩容，扩容完成后才进行put操作**。
>
>3. 进行删除操作：与写一致。
>
>---------





## string中SDS为什么不直接使用Int类型

>Redis 中的字符串是一种 **动态字符串**，这意味着使用者可以修改，它的底层实现有点类似于 Java 中的 **ArrayList**，有一个字符数组.会发现同样一组结构 Redis 使用泛型定义了好多次,因为当字符串比较短的时候，len 和 alloc 可以使用 byte 和 short 来表示，**Redis 为了对内存做极致的优化，不同长度的字符串使用不同的结构体来表示。**
>
>------
>
>#### String中底层SDS结构与C字符串有什么区别？
>
>- **获取字符串长度为 O(N) 级别的操作** → 因为 C 不保存数组的长度，每次都需要遍历一遍整个数组；
>- 不能很好的杜绝 **缓冲区溢出/内存泄漏** 的问题 → 跟上述问题原因一样，如果执行拼接 or 缩短字符串的操作，如果操作不当就很容易造成上述问题；
>- C 字符串 **只能保存文本数据** → 因为 C 语言中的字符串必须符合某种编码（比如 ASCII），例如中间出现的 `'\0'` 可能会被判定为提前结束的字符串而识别不了；
>
>------
>
>- 当字符串的长度小于 1MB时，每次扩容都是加倍现有的空间。
>- 如果字符串长度超过 1MB时，每次扩容时只会扩展 1MB 的空间。**字符串最大长度为** **`512MB`.**。
>
>-----
>
>基本命令：
>
>```sql
>set   [key]  [value]   给指定key设置值（set 可覆盖老的值）
>
>get  [key]   获取指定key 的值
>
>del  [key]   删除指定key
>
>exists  [key]  判断是否存在指定key
>
>mset  [key1]  [value1]  [key2]  [value2] ...... 批量存键值对
>
>mget  [key1]  [key2] ......   批量取key
>
>expire [key]  [time]    给指定key 设置过期时间  单位秒
>
>setex    [key]  [time]  [value]  等价于 set + expire 命令组合
>
>setnx  [key]  [value]   如果key不存在则set 创建，否则返回0
>
>incr   [key]           如果value为整数 可用 incr命令每次自增1
>
>incrby  [key] [number]  使用incrby命令对整数值 进行增加 number
>```



# ==redis 为什么这么快 IO多路复用==

>https://xie.infoq.cn/article/b3816e9fe3ac77684b4f29348
>
>- 完全基于内存
>- IO 多路复用
>
>#### 一 、比如在处理客户端的连接上 我们可以有如下选择
>
>### 1、多进程
>
>对于并发情况，假如一个进程不行，那搞多个进程不就可以同时处理多个客户端连接了么？
>
>多进程这种方式的确可以解决了服务器在同一时间能处理多个客户端连接请求的问题，但是仍存在一些缺点：
>
>- fork()等系统调用会使得进程上下文进行切换，效率较低
>- 进程创建的数量随着连接请求的增加而增加。比如 10w 个请求，就要 fork 10w 个进程，开销太大
>- 进程与进程之间的地址空间是私有、独立的，使得进程之间的数据共享变得困难
>
>### 2、多线程
>
>线程是运行在进程上下文的逻辑流，一个进程可以包含多个线程，多个线程运行在同一进程上下文中，因此可共享这个进程地址空间的所有内容，解决了进程与进程之间通信难的问题。
>
>同时，由于一个线程的上下文要比一个进程的上下文小得多，所以线程的上下文切换，要比进程的上下文切换效率高得多。
>
>### 3、IO 多路复用  redis
>
>简单理解就是：一个服务端进程可以同时处理多个套接字描述符。
>
>- **多路**：多个客户端连接（连接就是套接字描述符）
>- **复用**：使用单进程就能够实现同时处理多个客户端的连接
>
>以上是通过增加进程和线程的数量来并发处理多个套接字，免不了上下文切换的开销，而 IO 多路复用只需要一个进程就能够处理多个套接字，从而解决了上下文切换的问题。
>
>其发展可以分 **select->poll→epoll** 三个阶段来描述。
>
>#### 二、IO 多路复用在redis上的应用
>
>Redis 服务器是一个事件驱动程序， 服务器处理的事件分为时间事件和文件事件两类。
>
>- **文件事件**：Redis 主进程中，主要处理客户端的连接请求与相应。
>- **时间事件**：fork 出的子进程中，处理如 AOF 持久化任务等。
>
>由于 Redis 的文件事件是单进程，单线程模型，但是确保持着优秀的吞吐量，IO 多路复用起到了主要作用。
>
>文件事件是对套接字操作的抽象，每当一个套接字准备好执行连接应答、写入、读取、关闭等操作时，就会产生一个文件事件。因为一个服务器通常会连接多个套接字，所以多个文件事件有可能会并发地出现。
>
>IO 多路复用程序负责监听多个套接字并向文件事件分派器传送那些产生了事件的套接字。文件事件分派器接收 IO 多路复用程序传来的套接字，并根据套接字产生的事件的类型，调用相应的事件处理器。示例如图所示：
>
>![img](https://static001.geekbang.org/infoq/22/225e6ad72395a6686eba04d82bfec23f.jpeg?x-oss-process=image/resize,p_80/auto-orient,1)
>
>文件处理器的四个组成部分
>
>Redis 的 IO 多路复用程序的所有功能都是通过包装常见的 select、poll、evport 和 kqueue 这些 IO 多路复用函数库来实现的，每个 IO 多路复用函数库在 Redis 源码中都有对应的一个单独的文件。
>
>Redis 为每个 IO 多路复用函数库都实现了相同的 API，所以 IO 多路复用程序的底层实现是可以互换的。如图：
>
>![img](https://static001.geekbang.org/infoq/04/04dd554ab597afc58aa94357ecec97f3.jpeg?x-oss-process=image/resize,p_80/auto-orient,1)
>
>多个IO复用库实现可选
>
>
>
>Redis 把所有连接与读写事件、还有我们没提到的时间事件一起集中管理，并对底层 IO 多路复用机制进行了封装，最终实现了单进程能够处理多个连接以及读写事件。这就是 IO 多路复用在 redis 中的应用。



# IO 多路复用选择器 select poll epoll  recato模式

>-  **Select uninx网络变成环境**
>
><img src="https://img-blog.csdnimg.cn/20210124201118898.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1h1ZXlpbkd1bw==,size_16,color_FFFFFF,t_70" alt="img" style="zoom:67%;" />
>
>通过一次系统调用，把文件描述符fds，传递给内核，内核通过读取bitmap读、写、异常的标志位，内核进行遍历，在遍历过程中判断fds是否有数据，如果没有数据进行阻塞，有数据则对有数据的dfs进行置位，并返回给用户态进行操作。 内核来帮我们监听数据。
>
>缺点：
>
>1.  bitmap默认大小是1024  （bitmap）是表示fd的集合。
>2.  内核态在在对有数据的fds上，置位了bitmap，再次重新进行遍历的时候导致bitmap不可重用了。
>3.  用户态到内核态仍有一个开销
>4.  重内核态对bitmap标志有数据的fds，在返回给用户态 用户态还需要再次遍历一遍来查看哪里有数据 还需要O(n)时间复杂度
>
>------
>
>- **poll **
>
>poll其实跟select差不多，区别就是select使用bitmap来表示文件描述符。 而poll不是构建一个描述符集，而是构造一个pollfd的数组，每个数组的元素制定一个描述符编号**（结构体中的fd）**以及我们对该描述符感兴趣的条件**（short events）**。 `int fd \ short event  \ short revents`
>
>1. 在内核进行遍历的时候 对有数据的fds只需要修改 `short revenets`字段   。 当用户态读取完数据之后会把`revebts`字段置位0 达到复用。
>2. `pollfd`是数组 没有像select 中Bitmap1024大小的限制
>
>-----
>
>- **epoll**
>
>epoll有三个函数
>
>epoll_create:  会在内核常见红黑树和就绪链表
>
>Epoll_ctl:        对红黑树进行操作，添加所有socket节点
>
>Epoll_wait:    阻塞线程，内核中查找红黑树已经准备好的`socket` 并放入到就绪链表当中。就绪链表中的内容复制到events单中。用户态可以直接进行访问，也就是`epoll`相当于事件通知，只把准备好的告诉你
>
>优点：
>
>1.  在文件描述符`fds`状态感知的情况下，`epoll`是事件通知的形式  时间复杂度为O(1)
>2.  文件描述符的数量没有限制
>3.  不需要对原数据进行重置
>
>缺点：
>
>1. Epoll 并没有完全解决用户态和内核态之间的复制，只是减少了频繁操作而已。





# redis分布式锁

>为什么需要redis分布式锁： 需要该怎么设计 在这里哈呢   首先要解释为什么需要分布式锁
>
>当服务是单机时：我们利用jvm特性 在这里就是可以实现线程安全：例如加入synchronized 、lock、 cas等这些操作
>
>但是当业务量大的时候单机的性能不满足我们的需求 所以在这里需要进行分布式上的锁：
>
>当多个请求同时请求一个共享变量的时候 我们就是需要进行分布式情况下的锁安全，synchronized只是对jvm层面上的线程安全，当多个jvm或者就是tomact实例在进行运行的时候，单机应用在这里就是不行呗。
>
>-----
>
>为什么要用redis作为分布式锁：
>
>因为redis在这里就是单线程：假如在我们这里不进行搭集群，就是单机redis 我们访问在这里就是多个服务都会走到redis单线程这里边。
>
>```redis
>setnx set if not exist： 这个命令就是重点 关键点 如果不存在我们设置这个值 并且返回true  如果存在我们不设置并且返回fasle
>```
>
>```java
>public static void main(String[] args){
>private int count; //这个就是商品数量 我们在这里就是简单的进行一下秒杀设置呗
>
>  //进行商品售卖函数
>  public void sell(){
>  try{
>  boolean flag = redis.setnx("lock",uuid,过期时间)  //这里边就是我们搭建这个就是必须在起义  不能分开进行先关操作 否则就会造成
>  //redis在这里就是原子性操作呗 否则设置完Lock在这里就是宕机 使我们不允许生成的情况 这个锁就不会进行释放
>    
>     //这里边就是进行一下一直开启一个线程么 在这里哈呢 进行时间判断呗
>     
>     new Thread(()->{
>        public void run(){
>          //这里边就是进行时间判断呗 对巴哈呢 
>        }
>     })
>     
>     if(flag){
>        //进行业务操作  
>       }
>     else{
>        //在这里就是直接返回呗  因为这里边已经有线程进行抢占了  所以在这里进行返回呗
>       return;  //这里边能不能进行自旋操作进行优化 CAS操作呗
>     }
>     }catch(Exception e){
>     
>      print.e;
>    }
>     	finally{
>      if(redis.get("lock")==uuid){ //这里就是必须判断这里边是不是这个线程ID呢  否则会误删除
>       redis.delete(key);
>     }
>     }
>     } 
>     }
>    ```
>  





# redis如何保证原子性

>原子性是数据库的事务中的特性。在数据库事务的情景下，原子性指的是：一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。
>
>对于Redis而言，命令的原子性指的是：一个操作的不可以再分，操作要么执行，要么不执行。
>
>Redis操作原子性的原因
>
>Redis的操作之所以是原子性的，是因为Redis是单线程的。
>
>----
>
>如果想在上面的程序中实现原子性，可以将get和set改成单命令操作，比如incr，或者使用Redis的事务，或者使用Redis+Lua的方式实现。



# redis事务

>什么是事务？
>事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。
>
>事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。
>
>1. **Redis事务的概念**
>     Redis 事务的本质是通过MULTI、EXEC、WATCH等一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。
>
>总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。
>
>2. **Redis事务的三个阶段**
>     事务开始 MULTI
>     命令入队
>     事务执行 EXEC
>     事务执行过程中，如果服务端收到有EXEC、DISCARD、WATCH、MULTI之外的请求，将会把请求放入队列中排队
>
>3. **Redis事务相关命令**
>     Redis事务功能是通过MULTI、EXEC、DISCARD和WATCH 四个原语实现的
>
>Redis会将一个事务中的所有命令序列化，然后按顺序执行。
>
>redis 不支持回滚，“Redis 在事务失败时不进行回滚，而是继续执行余下的命令”， 所以 Redis 的内部可以保持简单且快速。
>如果在一个事务中的命令出现错误，那么所有的命令都不会执行；
>如果在一个事务中出现运行错误，那么正确的命令会被执行。
>WATCH 命令是一个乐观锁，可以为 Redis 事务提供 check-and-set （CAS）行为。 可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。
>MULTI命令用于开启一个事务，它总是返回OK。 MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当EXEC命令被调用时，所有队列中的命令才会被执行。
>EXEC：执行所有事务块内的命令。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。 当操作被打断时，返回空值 nil 。
>通过调用DISCARD，客户端可以清空事务队列，并放弃执行事务， 并且客户端会从事务状态中退出。
>UNWATCH命令可以取消watch对所有key的监控。
>事务管理（ACID）概述
>原子性（Atomicity）
>原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。
>
>一致性（Consistency）
>事务前后数据的完整性必须保持一致。
>
>隔离性（Isolation）
>多个事务并发执行时，一个事务的执行不应影响其他事务的执行
>
>持久性（Durability）
>持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来即使数据库发生故障也不应该对其有任何影响
>
>Redis的事务总是具有ACID中的一致性和隔离性，其他特性是不支持的。当服务器运行在AOF持久化模式下，并且appendfsync选项的值为always时，事务也具有耐久性。
>
>Redis事务支持隔离性吗
>Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。因此，Redis 的事务是总是带有隔离性的。
>
>Redis事务保证原子性吗，支持回滚吗
>Redis中，单条命令是原子性执行的，但事务不保证原子性，且没有回滚。事务中任意命令执行失败，其余的命令仍会被执行。
>
>Redis事务其他实现
>基于Lua脚本，Redis可以保证脚本内的命令一次性、按顺序地执行，
>其同时也不提供事务运行错误的回滚，执行过程中如果部分命令运行错误，剩下的命令还是会继续运行完
>基于中间标记变量，通过另外的标记变量来标识事务是否执行完成，读取数据时先读取该标记变量判断是否事务执行完成。但这样会需要额外写代码实现，比较繁琐





# 持久化、主从复制、哨兵、集群  高可用

>在 `Web` 服务器中，**高可用** 是指服务器可以 **正常访问** 的时间，衡量的标准是在 **多长时间** 内可以提供正常服务（`99.9%`、`99.99%`、`99.999%` 等等）。在 `Redis` 层面，**高可用** 的含义要宽泛一些，除了保证提供 **正常服务**（如 **主从分离**、**快速容灾技术** 等），还需要考虑 **数据容量扩展**、**数据安全** 等等。
>
>在 `Redis` 中，实现 **高可用** 的技术主要包括 **持久化**、**复制**、**哨兵** 和 **集群**，下面简单说明它们的作用，以及解决了什么样的问题：
>
>- **持久化**：持久化是 **最简单的** 高可用方法。它的主要作用是 **数据备份**，即将数据存储在 **硬盘**，保证数据不会因进程退出而丢失。
>- **主从复制**：复制是高可用 `Redis` 的基础，**哨兵** 和 **集群** 都是在 **复制基础** 上实现高可用的。复制主要实现了数据的多机备份以及对于读操作的负载均衡和简单的故障恢复。缺陷是故障恢复无法自动化、写操作无法负载均衡、存储能力受到单机的限制。
>- **哨兵**：在复制的基础上，哨兵实现了 **自动化** 的 **故障恢复**。缺陷是 **写操作** 无法 **负载均衡**，**存储能力** 受到 **单机** 的限制。
>- **集群**：通过集群，`Redis` 解决了 **写操作** 无法 **负载均衡** 以及 **存储能力** 受到 **单机限制** 的问题，实现了较为 **完善** 的 **高可用方案**。



## ==持久化 AOF RDB==

> ### Redis 的持久化机制是什么？各自的优缺点？
>
> Redis 提供两种持久化机制 RDB（默认） 和 AOF 机制:
>
> **RDB：是Redis DataBase缩写快照**
>
> RDB是Redis默认的持久化方式。按照一定的时间将内存的数据以快照的形式保存到硬盘中，对应产生的数据文件为dump.rdb。通过配置文件中的save参数来定义快照的周期。
>
> ![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MDU1NjY2LWMwNzAyMjIzMTUxODUyMjkucG5n?x-oss-process=image/format,png)
>
> 优点：
>
> - 1、只有一个文件 dump.rdb，方便持久化。
> - 2、容灾性好，一个文件可以保存到安全的磁盘。
> - 3、性能最大化，fork 子进程来完成写操作，让主进程继续处理命令，所以是 IO 最大化。使用单独子进程来进行持久化，主进程不会进行任何 IO 操作，保证了 redis 的高性能
> - 4、相对于数据集大时，比 AOF 的启动效率更高。
>
> 缺点：
>
> - 1、数据安全性低。RDB 是间隔一段时间进行持久化，如果持久化之间 redis 发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候)
> - 2、AOF（Append-only file)持久化方式： 是指所有的命令行记录以 redis 命令请 求协议的格式完全持久化存储)保存为 aof 文件。
>
> **AOF：持久化**
>
> AOF持久化(即Append Only File持久化)，则是将Redis执行的每次写命令记录到单独的日志文件中，当重启Redis会重新将持久化的日志中文件恢复数据。
>
> 当两种方式同时开启时，数据恢复Redis会优先选择AOF恢复。
>
> ![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy80MDU1NjY2LWUxN2NlNTY0NGZjN2FjZjMucG5n?x-oss-process=image/format,png)
>
> 优点：
>
> - 1、数据安全，aof 持久化可以配置 appendfsync 属性，有 always，每进行一次 命令操作就记录到 aof 文件中一次。
> - 2、通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof 工具解决数据一致性问题。
> - 3、AOF 机制的 rewrite 模式。AOF 文件没被 rewrite 之前（文件过大时会对命令 进行合并重写），可以删除其中的某些命令（比如误操作的 flushall）)
>
> 缺点：
>
> - 1、AOF 文件比 RDB 文件大，且恢复速度慢。
> - 2、数据集大的时候，比 rdb 启动效率低。
>
> 优缺点是什么？
>
> - AOF文件比RDB更新频率高，优先使用AOF还原数据。
> - AOF比RDB更安全也更大
> - RDB性能比AOF好
> - 如果两个都配了优先加载AOF
> - 
>
> **RDB和AOF到底该如何选择**
>
> - 不要仅仅使用 RDB，因为那样会导致你丢失很多数据；
> - 也不要仅仅使用 AOF，因为那样有两个问题：第一，你通过 AOF 做冷备，没有 RDB 做冷备来的恢复速度更快；第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug；
> - redis 支持同时开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。



## 主从复制

>### **什么是主从复制**
>
>![img](https://pic3.zhimg.com/80/v2-b5cc2323bd8770d8711808ea243b77ea_1440w.jpg)
>
>主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave),数据的复制是单向的，只能由主节点到从节点。
>
>默认情况下，每台Redis服务器都是主节点；且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。
>
>### **主从复制的作用**
>
>1. 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。
>
>2. 故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。
>
>3. 负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。
>
>4. 读写分离：可以用于实现读写分离，主库写、从库读，读写分离不仅可以提高服务器的负载能力，同时可根据需求的变化，改变从库的数量；
>
>5. 高可用基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。
>
>-----
>
>### 如何实现主从复制
>
>主从复制的开启 完全是由从节点发起的， 不需要我们在主节点做任何事情。
>
>1. **连接**： 保存主节点信息、 建立socket连接。
>2. **数据同步阶段：**从节点向主节点发送psync命令，开始同步。 这个时候就是同步的开始呗 
>
>----
>
>### 数据同步阶段是全量复制还是部分复制
>
>从节点可以发送psync命令请求同步数据，此时根据主从节点当前状态的不同，同步方式可能是全量复制或部分复制。
>
>1. 全量复制：用于初次复制或其他无法进行部分复制的情况，将主节点中的所有数据都发送给从节点，是一个非常重型的操作。
>2. 部分复制：用于网络中断等情况后的复制，只将中断期间主节点执行的写命令发送给从节点，与全量复制相比更加高效。需要注意的是，如果网络中断时间过长，导致主节点没有能够完整地保存中断期间执行的写命令，则无法进行部分复制，仍使用全量复制。









## 哨兵

>### 哨兵作用
>
>哨兵是 Redis 的一种运行模式，它专注于**对 Redis 实例（主节点、从节点）运行状态的监控，并能够在主节点发生故障时通过一系列的机制实现选主及主从切换，实现故障转移，确保整个 Redis 系统的可用性**。结合 Redis 的 [官方文档](https://link.segmentfault.com/?enc=hwIRyOkPoqL8B8FtqnUkAA%3D%3D.Sb6ABWKyb1QkG27CN1CSP20PiWbleJYHDPGZSWrFyZU8aOKfLuZrYrq%2Bw3u62Qfj)，可以知道 Redis 哨兵具备的能力有如下几个：
>
>- **监控**：持续监控 master 、slave 是否处于预期工作状态。
>- **自动切换主库**：当 Master 运行故障，哨兵启动自动故障恢复流程：从 slave 中选择一台作为新 master。
>- **通知**：让 slave 执行 replicaof ，与新的 master 同步；并且通知客户端与新 master 建立连接。
>
>
>
>#### 1. 哨兵工作原理
>
>-----
>
>![img](https://images2018.cnblogs.com/blog/1174710/201809/1174710-20180908182924632-1069251418.png)
>
>- **哨兵主要任务**
>
>  Redis 哨兵机制是实现 Redis 不间断服务的高可用手段之一。[主从架构集群的数据同步](https://link.segmentfault.com/?enc=akUGr6uTf6j1HePuOmNEig%3D%3D.NN4vZfFN08NB%2F1VmptEsh%2Fy0d1tjETXeKVkEYbkiiQ4dpAoSSe1l9Tb6YDu7a0cXrllNicxcTLm7q7K4vYnpHA%3D%3D)，是数据可靠的基础保障；主库宕机，自动执行主从切换是服务不间断的关键支撑。
>
>  - 监控 master 与 slave 运行状态，判断是否客观下线；
>  - master 客观下线后，选择一个 slave 切换成 master；
>  - 通知 slave 和客户端新 master 信息。
>
>- **哨兵集群原理**
>
>  为了避免单个哨兵故障后无法进行主从切换，以及为了减少误判率，又引入了哨兵集群；哨兵集群又需要有一些机制来支撑它的正常运行：
>
>  - 基于 pub/sub 机制实现哨兵集群之间的通信； 
>  - 每个 sentinel 哨兵节点每隔1s 向所有的`master、slave`以及其他 `sentinel `节点发送一个`PING`命令，作用是通过心跳检测，检测主从服务器的网络连接状态
>  - 通过哨兵的 pub/sub，实现了与客户端和哨兵之间的事件通知。
>
>  主从切换，并不是随意选择一个哨兵就可以执行，而是通过投票仲裁，raft推荐算法选择一个 Leader，由这个 Leader 负责主从切换。
>
>----
>
>#### ==为什么哨兵需要奇数个节点?==
>
>其主要原因还是从成本上考虑的，因为奇数个节点和偶数个节点允许宕机的节点数是一样的，比如3个节点和4个节点都只允许宕机一台，那么为什么要搞4个节点去浪费服务资源呢？
>
>集群中，半数以上节点认为主节点故障了，才会选举新的节点。 
>
>4个节点的性能和容量是比3个节点高的，如果对性能方面有要求的，也可以偶数个节点，Redis是完全支持的
>
>-----
>
>#### 2. 如何判断master节点是否下线？
>
>1. 每个 sentinel 哨兵节点每隔1s 向所有的master、slave以及其他 sentinel 节点发送一个PING命令，作用是通过心跳检测，检测主从服务器的网络连接状态
>
>2. 如果 master 节点回复 PING 命令的时间超过 down-after-milliseconds 设定的阈值（默认30s），则这个 master 会被 sentinel 标记为主观下线，修改其 flags 状态为SRI_S_DOWN
>
>3. 当sentinel 哨兵节点将 master 标记为主观下线后，会向其余所有的 sentinel 发送sentinel is-master-down-by-addr消息，询问其他sentinel是否同意该master下线
>
>4. 每个sentinel收到命令之后，会根据发送过来的 ip和port 检查自己判断的结果，回复自己是否认为该master节点已经下线了
>
>5. sentinel收到回复之后，如果同意master节点进入主观下线的sentinel数量大于等于quorum，则master会被标记为客观下线，即认为该节点已经不可用。
>
>6. 在一般情况下，每个 Sentinel 每隔 10s 向所有的Master，Slave发送 INFO 命令。当Master 被 Sentinel 标记为客观下线时，Sentinel 向下线的 Master 的所有 Slave 发送 INFO 命令的频率会从 10 秒一次改为每秒一次。作用：发现最新的集群拓扑结构
>
>
>
>#### 3. 基于Raft算法选举领头sentinel  也就是回答为什么哨兵需要奇数个节点？
>
>到现在为止，已经知道了master客观下线，那就需要一个sentinel来负责故障转移，那到底是哪个sentinel节点来做这件事呢？需要通过选举实现，具体的选举过程如下：
>
>1. 判断客观下线的sentinel节点向其他 sentinel 节点发送 SENTINEL is-master-down-by-addr ip port current_epoch runid注意：这时的runid是自己的run id，每个sentinel节点都有一个自己运行时id
>
>2. 目标sentinel回复是否同意master下线并选举领头sentinel，选择领头sentinel的过程符合先到先得的原则。举例：sentinel1判断了客观下线，向sentinel2发送了第一步中的命令，sentinel2回复了sentinel1，说选你为领头，这时候sentinel3也向sentinel2发送第一步的命令，sentinel2会直接拒绝回复
>
>3. 当sentinel发现选自己的节点个数超过 majority 的个数的时候，自己就是领头节点
>
>4. 如果没有一个sentinel达到了majority的数量，等一段时间，重新选举
>
>
>
>#### 4、故障转移：
>
>有了领头sentinel之后，下面就是要做故障转移了，故障转移的一个主要问题和选择领头sentinel问题差不多，到底要选择哪一个slaver节点来作为master呢？按照我们一般的常识，我们会认为哪个slave节点中的数据和master中的数据相识度高哪个slaver就是master了，其实哨兵模式也差不多是这样判断的，不过还有别的判断条件，详细介绍如下：
>
>1. 在进行选择之前需要先剔除掉一些不满足条件的slaver，这些slaver不会作为变成master的备选
>
>① 剔除列表中已经下线的从服务
>② 剔除有5s没有回复sentinel的info命令的slave
>③ 剔除与已经下线的主服务连接断开时间超过 down-after-milliseconds * 10 + master宕机时长 的slaver
>
>2. 选主过程：
>
>① 选择优先级最高的节点，通过sentinel配置文件中的replica-priority配置项，这个参数越小，表示优先级越高
>
>② 如果第一步中的优先级相同，选择offset最大的，offset表示主节点向从节点同步数据的偏移量，越大表示同步的数据越多
>
>③ 如果第二步offset也相同，选择run id较小的
>
>
>
>#### 5、修改配置
>
>新的master节点选择出来之后，还需要做一些事情配置的修改，如下：
>
>1. 领头sentinel会对选出来的从节点执行slaveof no one 命令让其成为主节点
>
>2. 领头sentinel 向别的slave发送slaveof命令，告诉他们新的master是谁谁谁，你们向这个master复制数据
>
>3. 如果之前的master重新上线时，领头sentinel同样会给起发送slaveof命令，将其变成从节点



## 集群

>#### 为什么存在持久化、主从复制、哨兵 还需要集群？
>
>持久化、主从复制和哨兵，但这些方案仍有不足，其中最主要的问题是存储能力受单机限制，以及无法实现写操作的负载均衡。
>
>1. 写并发：
>
>Redis单实例读写分离可以解决读操作的负载均衡，但对于写操作，仍然是全部落在了master节点上面，在海量数据高并发场景，一个节点写数据容易出现瓶颈，造成master节点的压力上升。
>
>2. 海量数据的存储压力：
>
>单实例Redis本质上只有一台Master作为存储，如果面对海量数据的存储，一台Redis的服务器就应付不过来了，而且数据量太大意味着持久化成本高，严重时可能会阻塞服务器，造成服务请求成功率下降，降低服务的稳定性。
>
>**集群模式：实现了数据的分布式存储，对数据进行分片，将不同的数据存储在不同的master节点上面，从而解决了海量数据的存储问题。**
>
><img src="https://img-blog.csdnimg.cn/img_convert/da559cf66bf39b98d52cb7d4fdde3b7a.png" alt="img" style="zoom:50%;" />
>
>Redis集群采用去中心化的思想，没有中心节点的说法。Redis也内置了高可用机制，支持N个master节点，每个master节点都可以挂载多个slave节点，当master节点挂掉时，集群会提升它的某个slave节点作为新的master节点。
>
>----
>
>#### 数据分配算法： 哈希槽算法
>
>Redis集群采用的算法是哈希槽分区算法。Redis集群中有16384个哈希槽（槽的范围是 0 -16383，哈希槽），将不同的哈希槽分布在不同的Redis节点上面进行管理，也就是说每个Redis节点只负责一部分的哈希槽。在对数据进行操作的时候，集群会对使用CRC16算法对key进行计算并对16384取模（slot = CRC16(key)%16383），得到的结果就是 Key-Value 所放入的槽，通过这个值，去找到对应的槽所对应的Redis节点，然后直接到这个对应的节点上进行存取操作。
>
>使用哈希槽的好处就在于可以方便的添加或者移除节点，并且无论是添加删除或者修改某一个节点，都不会造成集群不可用的状态。当需要增加节点时，只需要把其他节点的某些哈希槽挪到新节点就可以了；当需要移除节点时，只需要把移除节点上的哈希槽挪到其他节点就行了；哈希槽数据分区算法具有以下几种特点：
>
>1. **解耦数据和节点之间的关系，简化了扩容和收缩难度；**
>2. **节点自身维护槽的映射关系，不需要客户端代理服务维护槽分区元数据**
>3. 支持节点、槽、键之间的映射查询，用于数据路由，在线伸缩等场景
>
>-----
>
>#### Redis集群中节点的通信机制：goosip协议
>
>redis集群的哈希槽算法解决的是数据的存取问题，不同的哈希槽位于不同的节点上，而不同的节点维护着一份它所认为的当前集群的状态，同时，Redis集群是去中心化的架构。那么，当集群的状态发生变化时，比如新节点加入、slot迁移、节点宕机、slave提升为新Master等等，我们希望这些变化尽快被其他节点发现，Redis是如何进行处理的呢？也就是说，Redis不同节点之间是如何进行通信进行维护集群的同步状态呢？
>
>在Redis集群中，不同的节点之间采用gossip协议进行通信，节点之间通讯的目的是为了维护节点之间的元数据信息。这些元数据就是每个节点包含哪些数据，是否出现故障，通过gossip协议，达到最终数据的一致性。
>gossip协议常见的消息类型包含： ping、pong、meet、fail等等。
>
>1. meet：主要用于通知新节点加入到集群中，通过「cluster meet ip port」命令，已有集群的节点会向新的节点发送邀请，加入现有集群。
>
>2. ping：用于交换节点的元数据。每个节点每秒会向集群中其他节点发送 ping 消息，消息中封装了自身节点状态还有其他部分节点的状态数据，也包括自身所管理的槽信息等等。
>3. pong：ping和meet消息的响应，同样包含了自身节点的状态和集群元数据信息。
>4. fail：某个节点判断另一个节点 fail 之后，向集群所有节点广播该节点挂掉的消息，其他节点收到消息后标记已下线。
>
>-----
>
>#### 集群的故障检测与故障转恢复机制：
>
>Redis集群的**故障检测**是基于gossip协议的，集群中的每个节点都会定期地向集群中的其他节点发送PING消息，以此交换各个节点状态信息，检测各个节点状态：在线状态、疑似下线状态PFAIL、已下线状态FAIL。
>
>1. 主观下线（pfail）：当节点A检测到与节点B的通讯时间超过了cluster-node-timeout 的时候，就会更新本地节点状态，把节点B更新为主观下线。
>
>主观下线并不能代表某个节点真的下线了，有可能是节点A与节点B之间的网络断开了，但是其他的节点依旧可以和节点B进行通讯。
>
>2. 客观下线：
>
>由于集群内的节点会不断地与其他节点进行通讯，下线信息也会通过 Gossip 消息传遍所有节点，因此集群内的节点会不断收到下线报告。
>
>当半数以上的主节点标记了节点B是主观下线时，便会触发客观下线的流程（该流程只针对主节点，如果是从节点就会忽略）。将主观下线的报告保存到本地的 ClusterNode 的结构fail_reports链表中，并且对主观下线报告的时效性进行检查，如果超过 cluster-node-timeout*2 的时间，就忽略这个报告，否则就记录报告内容，将其标记为客观下线。
>
>接着向集群广播一条主节点B的Fail 消息，所有收到消息的节点都会标记节点B为客观下线。
>
>
>
>2、**集群地故障恢复**：
>
>当故障节点下线后，如果是持有槽的主节点则需要在其从节点中找出一个替换它，从而保证高可用。此时下线主节点的所有从节点都担负着恢复义务，这些从节点会定时监测主节点是否进入客观下线状态，如果是，则触发故障恢复流程。故障恢复也就是选举一个节点充当新的master，选举的过程是基于Raft协议选举方式来实现的。
>
>1. 从节点过滤：
>
>检查每个slave节点与master节点断开连接的时间，如果超过了cluster-node-timeout * cluster-slave-validity-factor，那么就没有资格切换成master
>
>2. 投票选举：
>
>（1）节点排序：按照选举优先级进行排序
>
>对通过过滤条件的所有从节点进行排序，按照priority、offset、run id排序，排序越靠前的节点，越优先进行选举。priority的值越低，优先级越高
>offset越大，表示从master节点复制的数据越多，选举时间越靠前，优先进行选举 如果offset相同，run id越小，优先级越高
>
>（3）发起选举：
>
>更新完配置纪元以后，从节点会向集群发起广播选举的消息（CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST），要求所有收到这条消息，并且具有投票权的主节点进行投票。每个从节点在一个纪元中只能发起一次选举。
>
>（4）选举投票：
>
>如果一个主节点具有投票权，并且这个主节点尚未投票给其他从节点，那么主节点将向要求投票的从节点返回一条CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK消息，表示这个主节点支持从节点成为新的主节点。每个参与选举的从节点都会接收CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK消息，并根据自己收到了多少条这种消息来统计自己获得了多少主节点的支持。
>
>如果超过(N/2 + 1)数量的master节点都投票给了某个从节点，那么选举通过，这个从节点可以切换成master，如果在 cluster-node-timeout*2 的时间内从节点没有获得足够数量的票数，本次选举作废，更新配置纪元，并进行第二轮选举，直到选出新的主节点为止。
>
>在第(1)步排序领先的从节点通常会获得更多的票，因为它触发选举的时间更早一些，获得票的机会更大
>
>2.3、替换主节点：
>
>当满足投票条件的从节点被选出来以后，会触发替换主节点的操作。删除原主节点负责的槽数据，把这些槽数据添加到自己节点上，并且广播让其他的节点都知道这件事情，新的主节点诞生了。
>
>（1）被选中的从节点执行SLAVEOF NO ONE命令，使其成为新的主节点
>
>（2）新的主节点会撤销所有对已下线主节点的槽指派，并将这些槽全部指派给自己
>
>（3）新的主节点对集群进行广播PONG消息，告知其他节点已经成为新的主节点
>
>（4）新的主节点开始接收和处理槽相关的请求
>
>备注：如果集群中某个节点的master和slave节点都宕机了，那么集群就会进入fail状态，因为集群的slot映射不完整。如果集群超过半数以上的master挂掉，无论是否有slave，集群都会进入fail状态。



# redis-config

```bash
---------------------------------------网络-------------------
bind 127.0.0.1            绑定地址
protected-mode yes		  保护模式
port 6379				  端口

---------------------------------------通用模式-------------------
daemonize yes             守护进程
pidfile /var/run/redis_6379.pid   pid文件位置
always-show-logo yes      是否展示logo

---------------------------------------快照-  持久化到.rdb .aof------------------
save 900 1                900s内 至少有一个key进行修改 持久化操作
save 300 10				        300s内 至少有10个key进行修改 持久化操作
save 60 10000             60s内 至少有10000个key进行修改 持久化操作
stop-writes-on-bgsave-error yes   持久化出错是否还继续工作
rdbcompression yes        是否压缩rdb文件
rdbchecksum yes			      检查rdb文件进行错误的校验
dir ./					          当前目录rdb文件保存的目录

---------------------------------------安全
config set requirepass "ahusimidama"  设置redis密码
auth ahuisimida101 登录


---------------------------------------客户端
maxclients 10000           默认连接的最大客户端
maxmemory <bytes>          最大内存设置
maxmemory-policy noeviction 内存达到上限的处理策略
		
		1、volatile-lru：   只对设置了过期时间的key进行LRU（默认值） 
		2、allkeys-lru ：   删除lru算法的key   
		3、volatile-random：随机删除即将过期key   
		4、allkeys-random： 随机删除   
		5、volatile-ttl ：  删除即将过期的   
		6、noeviction ：    永不过期，返回错误
		
appendonly no  			默认不开启AOF模式


```

------



# 布隆过滤器

> 随着网络爬虫的过滤、垃圾邮箱的过滤等场景，布隆过滤器应运而生了。它解决了如何准确快速的判断某个数据是否在大数据量集合中。

- 布隆过滤器：一种数据结构，是由一串很长的二进制向量组成，可以将其看成一个二进制数组。既然是二进制，那么里面存放的不是0，就是1，但是初始默认值都是0。当要向布隆过滤器中添加一个元素key时，我们通过多个hash函数，算出一个值，然后将这个值对应的方格置为1。

- **判断数据是否存在？**很简单，我们只需要将这个新的数据通过上面自定义的几个哈希函数，分别算出各个值，然后看其对应的地方是否都是1，如果**存在一个不是1的情况**，那么我们可以说，该新**数据一定不存在**于这个布隆过滤器中。

- **布隆过滤器可以判断某个数据一定不存在，但是无法判断一定存在**。

- **布隆过滤器优缺点**

  ​		优点：优点很明显，二进制组成的数组，占用内存极少，并且插入和查询速度都足够快。

  　　 缺点：随着数据的增加，误判率会增加；还有无法判断数据一定存在；另外还有一个重要缺点，无法删除数据。

> **误判率**
>
> 布隆过滤器的误判是指多个输入经过哈希之后在相同的bit位置1了，这样就无法判断究竟是哪个输入产生的，因此误判的根源在于相同的 bit 位被多次映射且置 1。
>
> 这种情况也造成了布隆过滤器的删除问题，因为布隆过滤器的每一个 bit 并不是独占的，很有可能多个元素共享了某一位。如果我们直接删除这一位的话，会影响其他的元素。(比如上图中的第 3 位)
>
> ### 面试
>
> 9 亿个 IP 地址，都为白名单，判断某个 IP 是否在该白名单中，内存管够（HashMap、布隆过滤器、桶[排序]()，看在哪个桶的范围内，桶内[二分查找]()）这个问题扯了好久，面试官一直问还有没有别的；如果白名单是动态的呢，怎么维护布隆过滤器。   
>
> #### 使用bloom filter实现一个支持增量请求的白名单
>
> 白名单通常是需要更新的，更新的方式一般有**全量和增量更新**。全量不必说，重新定义个bloom filter将当前所有数据放入其中即可。增量更新的话，一般会提供一段时间内新增和删除的数据，所以需要在白名单中将数据进行合并，该添加的添加，该删除的删除。可是...... 原生的bloom filter并不支持元素的删除操作，因为某一位可能为多个元素所用。一种不切实际的想法是为bloom filter的每一位设置一个引用计数，每删除一个元素减1。
>
> 一种可行的做法是，另外使用一个map来保存已删除的元素，在判断元素是否存在时先判断在该deletemap中是否存在，如果存在，直接false。如果不存在，再通过bloom filter进行判断。在新添加元素时，如果deletemap中存在，删除该deletemap中的该元素，再添加到bloom filter中。在实际应用中，使用白名单的场景需要删除的元素一般是较少的，所以这种方式从效率是可行的。这种方式存在一个问题，当deletemap中元素过多时，势必会造成bloom filter的误判率上升，因为某些原本被删除元素设置为1的位并没有被归0。该问题的解决措施是，当deletemap的容量到达的一个界线时，使用全量同步更新该bloom filter。
>
> 

> Redis 实现布隆过滤器的底层就是通过 **bitmap** 这种数据结构，至于如何实现，这里就不重复造轮子了，介绍业界比较好用的一个客户端工具——**Redisson**。Redisson 是用于在 Java 程序中操作 Redis 的库，利用Redisson 我们可以在程序中轻松地使用 Redis。

```java
  package com.ys.rediscluster.bloomfilter.redisson;
  
  import org.redisson.Redisson;
  import org.redisson.api.RBloomFilter;
  import org.redisson.api.RedissonClient;
  import org.redisson.config.Config;
  
  public class RedissonBloomFilter {
  
      public static void main(String[] args) {
          Config config = new Config();
          config.useSingleServer().setAddress("redis://192.168.14.104:6379");
          config.useSingleServer().setPassword("123");
          //构造Redisson
          RedissonClient redisson = Redisson.create(config);
  
          RBloomFilter<String> bloomFilter = redisson.getBloomFilter("phoneList");
          //初始化布隆过滤器：预计元素为100000000L,误差率为3%
          bloomFilter.tryInit(100000000L,0.03);
          //将号码10086插入到布隆过滤器中
          bloomFilter.add("10086");
  
          //判断下面号码是否在布隆过滤器中
          System.out.println(bloomFilter.contains("123456"));//false
          System.out.println(bloomFilter.contains("10086"));//true
      }
  }

```

- 这是单节点的Redis实现方式，如果数据量比较大，期望的误差率又很低，那单节点所提供的内存是无法满足的，这时候可以使用分布式布隆过滤器，同样也可以用 Redisson 来实现。

**不用Redis如何来实现布隆过滤器？**

```java
package com.ys.rediscluster.bloomfilter;

import com.google.common.base.Charsets;
import com.google.common.hash.BloomFilter;
import com.google.common.hash.Funnel;
import com.google.common.hash.Funnels;

public class GuavaBloomFilter {
    public static void main(String[] args) {
        BloomFilter<String> bloomFilter = BloomFilter.create(Funnels.stringFunnel(Charsets.UTF_8),100000,0.01);

        bloomFilter.put("10086");

        System.out.println(bloomFilter.mightContain("123456"));
        System.out.println(bloomFilter.mightContain("10086"));
    }

```



# redis 一次性获取多条消息的命令 

>https://www.cnblogs.com/jimoer/p/14227467.html   
>
>`mget: `命令返回所有(一个或多个)给定 key 的值。 如果给定的 key 里面，有某个 key 不存在，那么这个 key 返回特殊值 nil 。
>
>`MGET KEY1 KEY2 .. KEYN`
>
>----
>
>管道 
>
>Lua脚本 通过lua脚本 我们可以原子化 操作很多指令呗 









# Redis 6.0 新特性-多线程

>**1.`Redis6.0`之前的版本真的是单线程吗？**
>
>`  Redis`在处理客户端的请求时，包括获取 (`socket` 读)、解析、执行、内容返回 (`socke`t 写) 等都由一个顺序串行的主线程处理，这就是所谓的“单线程”。但如果严格来讲从Redis4.0之后并不是单线程，除了主线程外，它也有后台线程在处理一些较为缓慢的操作，例如清理脏数据、无用连接的释放、大 `key` 的删除等等。
>
>
>
>**2.Redis6.0之前为什么一直不使用多线程？**
>
>使用`Redis`时，几乎不存在`CPU`成为瓶颈的情况，` Redis`主要受限于内存和网络。它几乎不会占用太多CPU。
>
>使用了单线程后，可维护性高。多线程模型虽然在某些方面表现优异，但是它却引入了程序执行顺序的不确定性，带来了并发读写的一系列问题，增加了系统复杂度、同时可能存在线程切换、甚至加锁解锁、死锁造成的性能损耗。redis采用IO复用计数处理网络请求处理性能非常高。
>
>
>
>**3.Redis6.0为什么要引入多线程呢？**
>
>业务系统变得复杂：数据分区无法解决热点读/写问题；数据偏斜，重新分配和放大/缩小变得更加复杂等等。
>
>从Redis自身角度来说，因为读写网络的read/write系统调用占用了Redis执行期间大部分CPU时间，所以对`io`网络请求进行优化
>
>协议栈优化的这种方式跟 Redis 关系不大，支持多线程是一种最有效最便捷的操作方式。所以总结起来，redis支持多线程主要就是两个原因：
>
>• 可以充分利用服务器 CPU 资源，目前主线程只能利用一个核
>
>• 多线程任务可以分摊 Redis 同步 IO 读写负荷
>
>
>
>**4.Redis6.0默认是否开启了多线程？** 
>
>Redis6.0的多线程默认是禁用的，只使用主线程。如需开启需要修改`redis.con`f配置文件：`	io-threads-do-reads yes	`
>
>
>
>![图片](https://mmbiz.qpic.cn/mmbiz_jpg/DkA0VYrOHvtWkvO02tIickx6ibOgCywvlibpOoSj6Fd9SaGQNcjsvDUHl2gVep84hxRDXmiaWIq8MLd07zWUPZTj3g/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)
>
>
>
>**5.Redis6.0多线程开启时，线程数如何设置？**
>
>开启多线程后，还需要设置线程数，否则是不生效的。同样修改redis.conf配置文件
>
>
>
>![图片](https://mmbiz.qpic.cn/mmbiz_png/DkA0VYrOHvtWkvO02tIickx6ibOgCywvlibYWv1pgKKRwJnujEG5b7ecLeAU1b8O8XqPzWz5dIcg2LvFXGbUYrZXg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)
>
>
>
>关于线程数的设置，官方有一个建议：4核的机器建议设置为2或3个线程，8核的建议设置为6个线程，线程数一定要小于机器核数。还需要注意的是，线程数并不是越大越好，官方认为超过了8个基本就没什么意义了。
>
>
>
>**6.Redis6.0采用多线程后，性能的提升效果如何？**
>
>Redis 6 引入的多线程 IO 特性对性能提升至少是一倍以上。国内也有大牛曾使用unstable版本在阿里云esc进行过测试，GET/SET 命令在4线程 IO时性能相比单线程是几乎是翻倍了。
>
>
>
>**7.Redis6.0多线程的实现机制？** 
>
>![图片](https://mmbiz.qpic.cn/mmbiz_png/DkA0VYrOHvtWkvO02tIickx6ibOgCywvlibHt0WSa1QYguvtDPUmGffgRave8k5wKbLK359HaJltbObPPiblicUcy3A/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)
>
>
>
>**流程简述如下：**
>
>1、主线程负责接收建立连接请求，获取 `socket` 放入全局等待读处理队列
>
>2、主线程处理完读事件之后，通过 `RR(Round Robin) `将这些连接分配给这些` IO` 线程
>
>3、主线程阻塞等待` IO` 线程读取 `socket` 完毕
>
>4、主线程通过单线程的方式执行请求命令，请求数据读取并解析完成，但并不执行
>
>5、主线程阻塞等待 IO 线程将数据回写 socket 完毕
>
>6、解除绑定，清空等待队列
>
>
>
>![图片](https://mmbiz.qpic.cn/mmbiz_png/DkA0VYrOHvtWkvO02tIickx6ibOgCywvlibpbYER5698cvSsm69yWHQ7iaUwQ140o9PbN5R9kHtlIzGiaoBN2LbwmyA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)
>
>
>
>**该设计有如下特点：**
>
>1、`IO `线程要么同时在读 `socket`，要么同时在写，不会同时读或写
>
>2、`IO `线程只负责读写` socket `解析命令，不负责命令处理
>
>
>
>**8.开启多线程后，是否会存在线程并发安全问题？** 
>
>从上面的实现机制可以看出，`Redis`的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程顺序执行。所以我们不需要去考虑控制 `key、lua`、事务，`LPUSH/LPOP `等等的并发及线程安全问题。







# 常见面试题 场景提

## 1. 假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？

>使用keys指令可以扫出指定模式的key列表。
>
>对方接着追问：如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？
>
>这个时候你要回答redis关键的一个特性：redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。





## 2. 使用Redis做过异步队列吗，是如何实现的

使用list类型保存数据信息，rpush生产消息，lpop消费消息，当lpop没有消息时，可以sleep一段时间，然后再检查有没有信息，如果不想sleep的话，可以使用blpop，在没有信息的时候，会一直阻塞，直到信息的到来。redis可以通过pub/sub主题订阅模式实现一个生产者，多个消费者，当然也存在一定的缺点，当消费者下线时，生产的消息会丢失。

## 3. Redis如何实现延时队列

使用sortedset，使用时间戳做score，消息内容作为key，调用zadd来生产消息，消费者使用zrangbyscore获取n秒之前的数据做轮询处理。

## 4. 为什么要用 Redis 而不用 map/guava 做缓存?

缓存分为本地缓存和分布式缓存。以 Java 为例，使用自带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。

使用 redis 或 memcached 之类的称为分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。缺点是需要保持 redis 或 memcached服务的高可用，整个程序架构上较为复杂。

## 5. Redis线程模型

Redis基于Reactor模式开发了网络事件处理器，这个处理器被称为文件事件处理器（file event handler）。它的组成结构为4部分：多个套接字、IO多路复用程序、文件事件分派器、事件处理器。因为文件事件分派器队列的消费是单线程的，所以Redis才叫单线程模型。

文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字， 并根据套接字目前执行的任务来为套接字关联不同的事件处理器。
当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作时， 与操作相对应的文件事件就会产生， 这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。
虽然文件事件处理器以单线程方式运行， 但通过使用 I/O 多路复用程序来监听多个套接字， 文件事件处理器既实现了高性能的网络通信模型， 又可以很好地与 redis 服务器中其他同样以单线程方式运行的模块进行对接， 这保持了 Redis 内部单线程设计的简单性。

# ==缓存穿透、雪崩、过期、热点失效==

## 缓存雪崩

>一、缓存雪崩：
>1、什么是缓存雪崩：
>
>如果缓在某一个时刻出现大规模的key失效，那么就会导致大量的请求打在了数据库上面，导致数据库压力巨大，如果在高并发的情况下，可能瞬间就会导致数据库宕机。这时候如果运维马上又重启数据库，马上又会有新的流量把数据库打死。这就是缓存雪崩。
>
>2、问题分析：
>
>造成缓存雪崩的关键在于同一时间的大规模的key失效，为什么会出现这个问题，主要有两种可能：第一种是Redis宕机，第二种可能就是采用了相同的过期时间。搞清楚原因之后，那么有什么解决方案呢？
>
>3、解决方案：
>
>（1）事前：
>
>① 均匀过期：设置不同的过期时间，让缓存失效的时间尽量均匀，避免相同的过期时间导致缓存雪崩，造成大量数据库的访问。
>
>② 分级缓存：第一级缓存失效的基础上，访问二级缓存，每一级缓存的失效时间都不同。
>
>③ 热点数据缓存永远不过期。
>
>永不过期实际包含两层意思：
>
>物理不过期，针对热点key不设置过期时间
>
>逻辑过期，把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建
>
>④ 保证Redis缓存的高可用，防止Redis宕机导致缓存雪崩的问题。可以使用 主从+ 哨兵，Redis集群来避免 Redis 全盘崩溃的情况。
>
>（2）事中：
>
>① 互斥锁：在缓存失效后，通过互斥锁或者队列来控制读数据写缓存的线程数量，比如某个key只允许一个线程查询数据和写缓存，其他线程等待。这种方式会阻塞其他的线程，此时系统的吞吐量会下降
>
>② 使用熔断机制，限流降级。当流量达到一定的阈值，直接返回“系统拥挤”之类的提示，防止过多的请求打在数据库上将数据库击垮，至少能保证一部分用户是可以正常使用，其他用户多刷新几次也能得到结果。
>
>（3）事后：
>
>① 开启Redis持久化机制，尽快恢复缓存数据，一旦重启，就能从磁盘上自动加载数据恢复内存中的数据。
>
>

## 缓存击穿：

>二、缓存击穿：
>
>1. 什么是缓存击穿：
>
>缓存击穿跟缓存雪崩有点类似，缓存雪崩是大规模的key失效，而缓存击穿是某个热点的key失效，大并发集中对其进行请求，就会造成大量请求读缓存没读到数据，从而导致高并发访问数据库，引起数据库压力剧增。这种现象就叫做缓存击穿。
>
>2. 问题分析：
>
>关键在于某个热点的key失效了，导致大并发集中打在数据库上。所以要从两个方面解决，第一是否可以考虑热点key不设置过期时间，第二是否可以考虑降低打在数据库上的请求数量。
>
>3. **解决方案**：
>
>（1）在缓存失效后，通过互斥锁或者队列来控制读数据写缓存的线程数量，比如某个key只允许一个线程查询数据和写缓存，其他线程等待。这种方式会阻塞其他的线程，此时系统的吞吐量会下降
>
>（2）热点数据缓存永远不过期。
>
>永不过期实际包含两层意思：
>
>物理不过期，针对热点key不设置过期时间
>
>逻辑过期，把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建



## 缓存穿透

>三、缓存穿透：
>1、什么是缓存穿透：
>
>缓存穿透是指用户请求的数据在缓存中不存在即没有命中，同时在数据库中也不存在，导致用户每次请求该数据都要去数据库中查询一遍。如果有恶意攻击者不断请求系统中不存在的数据，会导致短时间大量请求落在数据库上，造成数据库压力过大，甚至导致数据库承受不住而宕机崩溃。
>
>2、问题分析：
>
>缓存穿透的关键在于在Redis中查不到key值，它和缓存击穿的根本区别在于传进来的key在Redis中是不存在的。假如有黑客传进大量的不存在的key，那么大量的请求打在数据库上是很致命的问题，所以在日常开发中要对参数做好校验，一些非法的参数，不可能存在的key就直接返回错误提示。
>
>
>
>3、解决方法：
>
>（1）将无效的key存放进Redis中：
>
>当出现Redis查不到数据，数据库也查不到数据的情况，我们就把这个key保存到Redis中，设置value="null"，并设置其过期时间极短，后面再出现查询这个key的请求的时候，直接返回null，就不需要再查询数据库了。但这种处理方式是有问题的，假如传进来的这个不存在的Key值每次都是随机的，那存进Redis也没有意义。
>
>（2）使用布隆过滤器：
>
>如果布隆过滤器判定某个 key 不存在布隆过滤器中，那么就一定不存在，如果判定某个 key 存在，那么很大可能是存在(存在一定的误判率)。于是我们可以在缓存之前再加一个布隆过滤器，将数据库中的所有key都存储在布隆过滤器中，在查询Redis前先去布隆过滤器查询 key 是否存在，如果不存在就直接返回，不让其访问数据库，从而避免了对底层存储系统的查询压力。
>
>
>
>如何选择：针对一些恶意攻击，攻击带过来的大量key是随机，那么我们采用第一种方案就会缓存大量不存在key的数据。那么这种方案就不合适了，我们可以先对使用布隆过滤器方案进行过滤掉这些key。所以，针对这种key异常多、请求重复率比较低的数据，优先使用第二种方案直接过滤掉。而对于空数据的key有限的，重复率比较高的，则可优先采用第一种方式进行缓存。



## 缓存预热

>四、缓存预热：
>1、什么是缓存预热：
>
>缓存预热是指系统上线后，提前将相关的缓存数据加载到缓存系统。避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题，用户直接查询事先被预热的缓存数据。
>
>如果不进行预热，那么Redis初始状态数据为空，系统上线初期，对于高并发的流量，都会访问到数据库中， 对数据库造成流量的压力。
>
>2、缓存预热解决方案：
>
>（1）数据量不大的时候，工程启动的时候进行加载缓存动作；
>
>（2）数据量大的时候，设置一个定时任务脚本，进行缓存的刷新；
>
>（3）数据量太大的时候，优先保证热点数据进行提前加载到缓存。



## ==Redis的过期键的删除策略==

> 我们都知道，Redis是key-value数据库，我们可以设置Redis中缓存的key的过期时间。Redis的过期策略就是指当Redis中缓存的key过期了，Redis如何处理。
>
> 过期策略通常有以下三种：
>
> - 定时过期：每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。	
> - 惰性过期：只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。
> - 定期过期：每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个**折中方案**。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。(expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。)
>
> **Redis中同时使用了惰性过期和定期过期两种过期策略。惰性删除能够保证过期的数据我们在获取时一定获取不到，而定期删除设置合适的频率，则可以保证无效的数据及时得到释放，而不会一直占用内存数据。**
>
> ### Redis key的过期时间和永久有效分别怎么设置？
>
> EXPIRE和PERSIST命令。
>
> ### 我们知道通过expire来设置key 的过期时间，那么对过期的数据怎么处理呢?
>
> 除了缓存服务器自带的缓存失效策略之外（Redis默认的有6种策略可供选择），我们还可以根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种：
>
> 1. 定时去清理过期的缓存；
> 2. 当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。
>
> 两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂！具体用哪种方案，大家可以根据自己的应用场景来权衡。

## Redis的内存淘汰策略

> - 一共有六种 就是可以在配置文件当中进行修改选择。
>
> - 当现有内存大于 maxmemory 时，便会触发redis主动淘汰内存方式，通过设置 maxmemory-policy ，有如下几种淘汰方式：
>
>   1）**volatile-lru**   利用LRU算法移除设置过过期时间的key (LRU:最近使用 Least Recently Used ) 。
>
>   2）**allkeys-lru**   利用LRU算法移除任何key （和上一个相比，删除的key包括设置过期时间和不设置过期时间的）。**通常使用该方式**。
>
>   3）**volatile-random** 随机移除设置过过期时间的key 。
>
> ​	    4）**allkeys-random**  无差别的随机移除。
>
> ​	    5）**volatile-ttl**   移除即将过期的key(minor TTL) 
>
>  	   6）**noeviction** 不移除任何key，只是返回一个写错误 ，**默认选项，一般不会选用。**
>
> - Redis是部署在物理机上的，内存不可能无限扩充的，当内存达到我们设定的界限后，便自动触发Redis内存淘汰策略，而具体的策略方式要根据实际业务情况进行选取。
>
> ### 回收策略
>
> 如果数据呈现幂律分布，也就是一部分数据访问频率高，一部分数据访问频率低，则使用 lru；
> 如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使用 random
>
> **来一个LRU算法。**
>
> ```java
> class SelfLRUCache<K, V> extends LinkedHashMap<K, V> {
>  private final int CACHE_SIZE;
>  /**
>      * 传递进来最多能缓存多少数据
>      * @param cacheSize 缓存大小
>   */
>  public SelfLRUCache(int cacheSize) {
> // true 表示让 linkedHashMap 按照访问顺序来进行排序，最近访问的放在头部，最老访问的放在尾部。
>      super((int) Math.ceil(cacheSize / 0.75) + 1, 0.75f, true);
>      CACHE_SIZE = cacheSize;
>  }
>  @Override
>  protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {
>      // 当 map中的数据量大于指定的缓存个数的时候，就自动删除最老的数据。
>      return size() > CACHE_SIZE;
>  }
> }
> 
> ```
>
> 

## ==解决热点数据集中失效问题==

> 我们在设置缓存的时候，一般会给缓存设置一个失效时间，过了这个时间，缓存就失效了。
>
> 对于一些热点的数据来说，当缓存失效以后会存在大量的请求过来，然后打到数据库去，从而可能导致数据库崩溃的情况。
>
> **解决办法**
>
> - 设置不同的失效时间
>
> 为了避免这些热点的数据集中失效，那么我们在设置缓存过期时间的时候，我们让他们失效的时间错开。
>
> 比如在一个基础的时间上加上或者减去一个范围内的随机值。
>
> - 互斥锁
>
> 结合上面的击穿的情况，在第一个请求去查询数据库的时候对他加一个互斥锁，其余的查询请求都会被阻塞住，直到锁被释放，从而保护数据库。但是也是由于它会阻塞其他的线程，此时系统吞吐量会下降。需要结合实际的业务去考虑是否要这么做。
>
> 



## Redis回收使用的是什么算法？

> LRU是Least Recently Used 近期最少使用算法，，在学习操作系统的内存回收的时候也用到了这种机制进行内存的回收，类似的还有LFU（Least Frequently Used）最不经常使用算法，这种算法。
>
> - 根据LRU算法删除设置了超时属性（expire）的键，直到腾出足够空间为止。
> - 据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。
> - 在java里边我实现了一个这种基于缓存的数据结构：get或者put操作数据都会被更新为热点数据  如果存放数据超出给定的内存空间，就删除不经常put 或者 get的key-value    **实现插入和删除操作都是O(1)，那就是hash表来操作  我们用hashMap呗    又有更新操作删除操作 自定义一个双向链表  HashMap<Integer,DoubleList>**    可以更新或插入采用头插法 删除采用尾插法

# ==-----------------------------------------------------------------------------Kafka==

https://www.51cto.com/article/637229.html  讲解kafka宕机 是因为_consumer_offset 只保存一个副本

https://blog.csdn.net/weixin_44052055/article/details/103726373  log日志满和jre内存满了 当值宕机

https://juejin.cn/post/6844904094021189639

https://new.qq.com/omn/20210609/20210609A07ETR00.html   消费者只消费一次消息 非常漂亮 实现幂等性

>- 消息队列如何保证消息被消费到
>- 如何检测网络抖动导致的数据丢失
>- 大数据量查询如何优化效率
>- 介绍消息队列整体架构
>- 死信队列，延迟消费（如何实现延时策略，多次失败控制）
>- 如何保证消息消费的幂等性
>- 如何保证分布式系统中数据库插入的幂等性
>- MQ中如何保证消息消费的幂等性
>- MQ能保证不出现重复消息吗
>- [项目](https://www.nowcoder.com/jump/super-jump/word?word=项目)中的MQ怎么保证幂等性的
>- rocketmq 保证消息不丢 和 消息的幂等性(这个好像是) 的原理,这题我直接把rocketmq整个架构答了一遍,然后说了消息不丢的所有情况,然后说了rocketmq原生无法保证绝对的不重复性要在业务保证,这里我连续说了5分钟没停,因为说了整个架构
>- 追问我业务怎么保证消息的幂等性,[redis](https://www.nowcoder.com/jump/super-jump/word?word=redis)标志位(不完美方案),或者在业务上设计成幂等性的
>- mq在[项目](https://www.nowcoder.com/jump/super-jump/word?word=项目)里怎么用
>- rabbitmq有几种工作模式？ 
>- mq里的订单如何删掉？(设置过期时间) 
>- RbbbitMQ的一个重复推送问题怎么解决？它都有哪种模式？ 
>- 中间件有了解吗?讲一下中间件 
>- 消息队列方式有什么优缺点? 
>- 消息队列为什么比共享内存慢？（需要额外的复制） 
>- 共享内存有什么缺点？它怎么保证同步操作？ 
>- 消息队列如何保证消息顺序性，可靠性



# kafka基础概念和知识

## kafka 基本结构？问什么选择Kakfa



>
>
>![图片](https://mmbiz.qpic.cn/mmbiz_png/iaIdQfEric9Tw5HhjBWfamF35XaNsxW3GH7CcZ39jmlbghrJ6qF7fUFFIoAia2xGQaNia0a4JtMmIrpWoib79wkPVXg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)
>
>kafka发布订阅模型呗 
>
>![3.1、初识Kafka 的逻辑结构和物理结构_༺ bestcxx的专栏༻-CSDN博客](https://img-blog.csdnimg.cn/20191212232001964.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Jlc3RjeHg=,size_16,color_FFFFFF,t_70)



## 项目中为什么使用mq

>使用 mq 做一些异步的操作 ， 比如说我们这个接口是属于http协议接口 是同步调用过程中相应比较慢的情况下 会导致我们的客户端比较超时 ， 比如说某些业务接口确实比较耗时，相应比较满的情况下， 那么我们客户端他会同步进行阻塞等待，容易引发我们客户端超时，客户端一旦发生超时会出发重试的策略过程中会导致我们的业务可能重复执行， 所以我们需要去注意一些幂等性，执行耗时的接口使用mq异步的去实现，能够提高我们http接口相应的速度。比如说异步发优惠券、异步发库存。
>
>----
>
>应用解耦、异步处理、流量消费、日志处理。 相比于其他mq发送速度更快 
>
>RocketMQ 选择了 mmap + write 这种零拷贝方式，适用于业务级消息这种小块文件的数据持久化和传输；**而 Kafka 采用的是 sendfile 这种零拷贝方式，适用于系统日志消息这种高吞吐量的大块文件的数据持久化和传输。但是值得注意的一点是，Kafka 的索引文件使用的是 mmap + write 方式，数据文件使用的是 sendfile 方式。**
>
>![preview](https://pic3.zhimg.com/v2-da99a5a5b027c7f374186b55919b0f0e_r.jpg)





## Kafka为什么分区？分区策略？

>https://blog.csdn.net/qq_38262266/article/details/107356824  
>
>**为什么要分区patition？**
>
>（1）方便在集群中扩展，每个 Partition 可以通过调整以适应它所在的机器，而一个 topic又可以有多个 Partition 组成，因此整个集群就可以适应任意大小的数据了；
>
>（2）可以提高并发，因为可以以 Partition 为单位读写了。
>
>
>-----
>
>**分区策略？**
>
>Producer发送数据封装成对象时的参数，根据参数设定，我们就能将数据放在对应的partition中。
>
>1. 指明 partition 的情况下，直接将数据放在对应的 partiton ；
>2. 没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition 数进行取余得到 partition 值；
>3. 既没有 partition 值又没有 key 值的情况下，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到 partition 值，也就是常说的 round-robin 算法。



## [kafka如何保证消息得顺序性](https://www.cnblogs.com/yfb918/p/12192857.html)？

>**保证消费消息的顺序性？**
>
>1. 比如说我们建了一个 topic，有三个 partition。
>
>2. 生产者在写的时候，其实可以指定一个 key，比如说我们指定了某个订单 id 作为 key，那么这个订单相关的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的。
>
>3. 消费者从 partition 中取出来数据的时候，也一定是有顺序的。到这里，顺序还是 ok 的，没有错乱。
>
>
>
>  接着，我们在消费者里可能会搞多个线程来并发处理消息。因为如果消费者是单线程消费处理，而处理比较耗时的话，比如处理一条消息耗时几十 ms，那么 1 秒钟只能处理几十条消息，这吞吐量太低了。而多个线程并发跑的话，顺序可能就乱掉了。
>
>​       II. 解决方案
>
>一个 topic，一个 partition，一个 consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个。
>写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。
>
><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWcyMDE4LmNuYmxvZ3MuY29tL2ktYmV0YS8xNjA4MTA0LzIwMjAwMS8xNjA4MTA0LTIwMjAwMTE0MTY0OTA0NTkyLTk0NjMzNzA4My5wbmc?x-oss-process=image/format,png" alt="img" style="zoom:80%;" />





## kafka是如何消费的？

>Kafka 是支持订阅/发布模式的，生产者发送数据给 Kafka Broker，那么消费者是如何知道生产者发送了数据呢？其实生产者产生的数据消费者是不知道的，KafkaConsumer 采用轮询的方式定期去 Kafka Broker 中进行数据的检索，如果有数据就用来消费，如果没有就再继续轮询等待，下面是轮询等待的具体实现
>
>```java
>try {
>while (true) {
>ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(100));
>for (ConsumerRecord<String, String> record : records) {
> int updateCount = 1;
> if (map.containsKey(record.value())) {
>   updateCount = (int) map.get(record.value() + 1);
> }
> map.put(record.value(), updateCount);
>}
>}
>}finally {
>consumer.close();
>}
>```
>
>- 这是一个无限循环。消费者实际上是一个长期运行的应用程序，它通过轮询的方式向 Kafka 请求数据。
>- 第三行代码非常重要，Kafka 必须定期循环请求数据，否则就会认为该 Consumer 已经挂了，会触发重平衡，它的分区会移交给群组中的其它消费者。传给 `poll()` 方法的是一个超市时间，用 `java.time.Duration` 类来表示，如果该参数被设置为 0 ，poll() 方法会立刻返回，否则就会在指定的毫秒数内一直等待 broker 返回数据。
>- poll() 方法会返回一个记录列表。每条记录都包含了记录所属主题的信息，记录所在分区的信息、记录在分区中的偏移量，以及记录的键值对。我们一般会遍历这个列表，逐条处理每条记录。
>- 在退出应用程序之前使用 `close()` 方法关闭消费者。网络连接和 socket 也会随之关闭，并立即触发一次重平衡，而不是等待群组协调器发现它不再发送心跳并认定它已经死亡。











## kafka如何保证消息不丢失

>**broker**:    kafka生产者提交消息到broker, 对于集群模式下会有多个`broker`, 我们如果设置`ack=1`就是代表一个broker收到消息就会保存该消息代表成功。也可以另所有Broker保存消息才算提交成功，但是无论哪种提交 最后都会进行持久化操作。
>
>**生产者**： 1.  send()方法是异步发送，在调用send()方法的时候可以采用添加回调函数的用法。如果发送失败，检查发送失败的原因。
>
>```java
>   ListenableFuture<SendResult<String, Object>> future = kafkaTemplate.send(topic, o);
>   future.addCallback(result -> logger.info("生产者成功发送消息到topic:{} partition:{}的消息", result.getRecordMetadata().topic(), result.getRecordMetadata().partition()),
>           ex -> logger.error("生产者发送消失败，原因：{}", ex.getMessage()));
>
>```
>
>​            	 2.   推荐为 Producer 的`retries`（重试次数）设置一个比较合理的值，一般是 3 ，但是为了保证消息不丢失的话一般会设置比较大一点。设置完成之后，当出现网络问题之后能够自动重试消息发送，避免消息丢失。另外，建议还要设置重试间隔，因为间隔太小的话重试的效果就不明显了，网络波动一次你3次一下子就重试完了
>
>-----
>
>
>
>**消费者**：
>
>          1. 如果kafka自动帮消费者提交某个分区的`offset` ，如果消费者突然挂掉，实际上并没有被消费，但是却自动提交了offset.
>          1. 如果关闭kakfa自动提交`offset`改成消费者来控制`offset`，消费者消费完消息在提交`offset`，但是这里会导致重复消费信息。
>
>------



## 如何保证消费者消费信息不丢失

>
>
>手动提交Offset   如果说在提前之前宕机， 会产生重复消费， 如果产生重复消费 。为每个消息加一个标志ID
>
>手动存储offset 到redis        重启kafka 指定redis 当中存储的offset开始进行消费

## kafka 1.0版本

>Kafka offset是在broker当中

## kafka如何保证消息消费的幂等性

>幂等，就是指多接口的多次调用所产生的结果和只调用一次是一致的。没有幂等性的情况下就会重复发送数据。
>
>Kafka的幂等性机制能保证单个分区不会重复写入数据，多分区的话需要实现事务，而实现幂等性的核心就是引入了producer id 和 sequence number序列号字段 这两个概念。对于新接受到的消息，broker端会进行如下判断：
>
>1. 如果新消息的sequence number正好是broker端维护的<PID,Partition> -> sequence number大1，说broker会接受处理这条消息。
>2. 如果新消息的sequence number比broker端维护的sequence number要小，说明时重复消息，broker可以将其直接丢弃
>3. 如果新消息的sequence number比broker端维护的sequence number要大过1，说明中间存在了丢数据的情况，那么会响应该情况，对应Producer会抛出OutOfOrderSequenceException。
>
> Properties.put(“enable.idempotence”,true);   开启幂等性。  就是主要防止生产者 生产重复消息。
>
>
>
>**kafka事务特性**
>
>Kafka事务性主要是为了解决幂等性无法跨Partition运作的问题，事务性提供了多个Partition写入的原子性，即写入多个Partition要么全部成功，要么全部失败，不会出现部分成功部分失败这种情况
>
>---------
>
>https://new.qq.com/omn/20210609/20210609A07ETR00.html   
>
>**实现消费者只消费一次  非常之重点：**
>
>**生产者**可以增加幂等性：来保证不发送重复消息。   Properties.put(“enable.idempotence”,true);   开启幂等性。  就是主要防止生产者 生产重复消息。
>
>在消费者当中： 1. 在消费者消费的时候引入事务的方案，例如入库操作，保证消息处理和写入数据库必须同时成功或者同时失败。
>
>​							2. 业务层进行处理： 其中有一种是增加乐观锁的方式。比如，你的消息处理程序需要给一个人的账号加钱，那么你可以通过乐观锁的方式来解决。具体的操作方式是这样的：你给每个人的账号数据中增加一个版本号的字段，在生产消息时先查询这个账户的版本号，并且将版本号连同消息一起发送给消息队列。消费端在拿到消息和版本号后，在执行更新账户金额 SQL 的时候带上版本号，类似于执行：你看，我们在更新数据时给数据加了乐观锁，这样在消费第一条消息时，version 值为 1，SQL 可以执行成功，并且同时把 version 值改为了 2；在执行第二条相同的消息时，由于 version 值不再是 1，所以这条 SQL 不能执行成功，也就保证了消息的幂等性。



## kafka 消息堆积  如何解决

>https://blog.csdn.net/qq_16681169/article/details/101081656
>
>max.poll.records       一次poll返回的最大记录数默认是500
>max.poll.interval.ms   两次poll方法最大时间间隔这个参数，默认是300s
>
>这次问题出现的原因为由于业务上下方的消息增量变多，导致堆积的消息过多，每一批poll()的处理都能达到500条消息，导致poll之后消费的时间过长。 服务端约定了和客户端max.poll.interval.ms，两次poll最大间隔。如果客户端处理一批消息花费的时间超过了这个限制时间，broker可能就会把消费者客户端移除掉，提交偏移量又会报错。所以拉取偏移量没有提交到broker，分区又rebalance，下一次重新分配分区时，消费者会从最新的已提交偏移量处开始消费，这里就出现了重复消费的问题
>
>
>
>
>1. 防止消费者挂掉的 需要设置消费者消费能力 设置kakfa配置参数 ，消费者每次poll的数据业务处理时间不能超过kafka的max.poll.interval.ms，可以考虑调大超时时间或者调小每次poll的数据量。增加max.poll.interval.ms处理时长(默认间隔300s)
>2. 可以考虑增强消费者的消费能力，做消费者集群， 使用线程池消费或者将消费者中耗时业务改成异步，并保证对消息是幂等处理
>3. 不但要有消息积压的监控，还可以考虑做消息消费速度的监控（前后两次offset比较）





## kafka 消息队列方式有什么优缺点? 

>**优点：解耦、异步、削峰**
>
>缺点：
>
>**系统可用性降低**：系统引入的外部依赖越多，越容易挂掉，本来你就是A系统调用BCD三个系统的接口就好了，人ABCD四个系统好好的，没啥问题，你偏加个MQ进来，万一MQ挂了咋整？MQ挂了，整套系统崩溃了，你不就完了么。
>
>**系统复杂性提高**：硬生生加个MQ进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？头大头大，问题一大堆，痛苦不已
>
>**一致性问题**：A系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是BCD三个系统那里，BD两个系统写库成功了，结果C系统写库失败了，咋整？你这数据就不一致了。





# kafka面试

## kafka优势 

## kafka produce生产一条消息流程



## kafka consumer只能消费一个分区么



## kafka 宕机原因分析



## kafka如何保证幂等性












>https://www.cnblogs.com/thisiswhy/p/12690630.html
>
>https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html
>
>https://blog.csdn.net/javazejian/article/details/70768369    三个不错的博文
>
>https://blog.csdn.net/javazejian/article/details/72772461





# ==-------------------------------------------------------------------JAVA语言基础==

# 基础语法、概念

## 面向对象几大特征

>1. 面向对象几大特征
>
>- 封装   封装是面向对象的特征之一，是对象和类概念的主要特性。封装，也就是把客观事物封装成抽象的类，并且类可以把自己的数据和方法只让可信的类或者对象操作，对不可信的进行信息隐藏。
>- 继承  它可以使用现有类的所有功能，并在无需重新编写原来的类的情况下对这些功能进行扩展。通过继承创建的新类称为“子类”或“派生类”，被继承的类称为“基类”、“父类”或“超类”。
>- 多态  父类引用指向子类对象。允许将子类类型的指针赋值给父类类型的指针。所谓多态就是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序运行期间才确定，即一个引用变量倒底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运行期间才能决定。那可能是 还要给你买一个你说hai'ti
>
>-----------------------
>
>- 为什么继承破坏了封装？
>
>
>子类对象确实拥有父类对象中所有的属性和方法。
>
>------------------
>
>- 继承时候可以去访问私有对象么 ?
>
>
>子类对象确实拥有父类对象中所有的属性和方法，但是父类对象中的私有属性和方法，子类是无法访问到的，只是拥有，但不能使用。就像有些东西你可能拥有，但是你并不能使用
>
>----------------------------
>
>
>如何访问一个私有的对象？  采用反射机制
>
>---------------
>
>- 继承 会不会创建父类对象
>
>
>继承不会创建父类对象 ，假设夫类对象是抽象类，然而抽象类是不能创建对象的，所以指定不会创建父类对象。其次子类创建对象只是调用了夫类的构造方法，调用父类的构造方法并不是一定就是创建父类对象，构造方法只是父类的一个成员函数而已。





## 接口和抽象类区别？使用场景

>**相同点**：
>
>1. 都不能被实例化 
>2. 接口的实现类或抽象类的子类都只有实现了接口或抽象类中的方法后才能实例化。
>
>
>
>**不同点**：
>
>（1）接口只有定义，不能有方法的实现，`java 1.8`中可以定`义default`方法体，而抽象类可以有定义与实现，方法可在抽象类中实现。
>
>（2）实现接口的关键字`implements`，继承抽象类的关键字为`extends`。一个类可以实现多个接口，但一个类只能继承一个抽象类。所以，使用接口可以间接地实现多重继承。
>
>（3）接口强调特定功能的实现，而抽象类强调所属关系。
>
>（4）接口成员变量默认为`public static final，`必须赋初值，不能被修改；其所有的成员方法都是`public、abstract`的。方法体只能被这几个修饰符所    修饰 `abstract public default 无`
>
>​        抽象类中成员变量默认`default`，可在子类中被重新定义，也可被重新赋值；抽象方法被abstract修饰，不能被`private、static、synchronized和native`等修饰，必须以分号结尾，不带花括号。

-----



>1. 接口不加限定词是什么状态，是包可见的么  public 默认就是包可见
>
>1. 继承抽象类，为什么必须要写构造函数呢     这里边就是不必须要写构造函数呢
>2. 抽象类实现接口，                                           可以不用实现具体方法呗
>
>---------------------
>
>情景：抽象类实现接口  子类继承了抽象类  如果抽象类重写了接口中的方法 那么子类就是不需要再进行重写了呗  如果抽象类没有重写 那么子类需要再进行写



## 泛型

>https://blog.csdn.net/briblue/article/details/76736356   blog总结泛型很到位
>
>泛型概念：
>
>0. 泛型本质上其实就是一个『语法糖』，本质上就是编译器为了提供更好的可读性而提供的一种小「手段」，虚拟机层面是不存在所谓『泛型』的概念的。
>
>1. 与普通的 Object 代替一切类型这样简单粗暴而言，泛型使得数据的类别可以像参数一样由外部传递进来。它提供了一种扩展能力。
>2. 当具体的类型确定后，泛型又提供了一种类型检测的机制，只有相匹配的数据才能正常的赋值，否则编译器就不通过。所以说，它是一种类型安全检测机制。
>
>------
>
>泛型的实现机制：
>
>**类型擦除：**
>
>1. 泛型这种语法糖，编译器会在编译期间「擦除」泛型语法并相应的做出一些类型转换动作。
>2. 如果泛型没有指定上限  那么类型擦除后都会转化为`Object`
>3. 如果指定上限了，   那么类型擦除后都会转化为该上限
>
>泛型有三种表达方法：泛型类 泛型方法 泛型接口
>
>为什么还需要有通配符呢？   因为： List<父类>  List<子类>    这个时候父类不能被子类赋值 因为类型不一致 List<父类>和List<子类>没有继承关系
>
>1. `<?>`被称作无限定的通配符。
>2. `<? extends T>`被称作有上限的通配符。 包含T和T的子类
>3. `<? super T>`被称作有下限的通配符。

-----------------

**泛型中重要类型擦除**:

>如下泛型编程题目：``List<String>`和 `List<Integer>`在` jvm `中的` Class `都是 `List.class。`  因为泛型信息都被擦除了 
>
>那么类型 String 和 Integer 怎么办？   答案是泛型转译  通过反射拿到的字段属性是Object
>
>泛型类被类型擦除后，相应的类型就被替换成 Object 类型呢？ 不一定 如果指定了上限如 `<T extends String>`则类型参数就被替换成类型上限

>-----------------------
>
>- 泛型题目
>
>```java
>List<String> l1 = new ArrayList<String>();
>List<Integer> l2 = new ArrayList<Integer>();
>
>System.out.println(l1.getClass() == l2.getClass());
>```
>
>答案是`true`

>`public static void he (List<Object>)` 加入传进参数  `List<String>` 可以么
>
>答案是不可以  在这里边编译阶段在这里就是过不去呢

## 多态

>多态是建立在重写的基础之上的，是类与类之间的关系，是发生在不同的类之间的，子类重写父类的方法。实现不同的子类，不同的实现形态。
>
>1. 继承
>2. 重写(重写父类继承的方法)
>3. 父类引用指向子类对象(父类  对象名= new 子类();语句在堆内存中开辟了子类的对象，并把栈内存中的父类的引用指向了这个子类对象。)
>
>---
>
>**多态的实现：**
>
>虚拟机栈中会存放当前方法调用的栈帧，在栈帧中，存储着局部变量表、操作栈、动态连接 、返回地址和其他附加信息。多态的实现过程，就是方法调用动态分派的过程，通过栈帧的信息去找到被调用方法的具体实现，然后使用这个具体实现的直接引用完成方法调用。
>
>以  `invokevirtual `指令为例，在执行时，大致可以分为以下几步：
>
>1. **先从操作栈中找到对象的实际类型 class；**
>2. **找到 class 中与被调用方法签名相同的方法，如果有访问权限就返回这个方法的直接引用，如果没有访问权限就报错 java.lang.IllegalAccessError** 
>3. **如果第 2 步找不到相符的方法，就去搜索 class 的父类，按照继承关系自下而上依次执行第 2 步的操作；**
>4. **如果第 3 步找不到相符的方法，就报错 java.lang.AbstractMethodError ；**
>
>**可以看到，如果子类覆盖了父类的方法，则在多态调用中，动态绑定过程会首先确定实际类型是子类，从而先搜索到子类中的方法。这个过程便是方法覆盖的本质。**
>
>实际上，商用虚拟机为了保证性能，通常会使用虚方法表和接口方法表，而不是每次都执行一遍上面的步骤。以虚方法表为例，虚方法表在类加载的解析阶段填充完成，其中存储了所有方法的直接引用。也就是说，动态分派在填充虚方法表的时候就已经完成了。
>
>在子类的虚方法表中，如果子类覆盖了父类的某个方法，则这个方法的直接引用指向子类的实现；而子类没有覆盖的那些方法，比如 Object 的方法，直接引用指向父类或 Object 的实现。



## ==重载和重写的区别==

>1. 一个类实现两个接口 两个接口里的方法名参数列表等都一样, 重写用的是哪个接口的方法(懵)
>
>重写：重写是子类对父类的允许访问的方法的实现过程进行重新编写, 返回值和形参都不能改变。是多态的体现形式
>
>重载：一个类中允许同时存在一个以上的同名方法，这些方法的参数个数或者类型不同，返回类型、访问修饰符、异常都可以不一样
>
>------

>重载和重写在异常声明上：
>
>重写：子类不能抛出比父类范围更大的异常。（编译时异常）
>
>重载：方法的重载主需要确定方法名一致，参数列表不一致。 其余的没有额外要求，异常处理这里边可以不同。
>
>-------
>
>**底层实现原理：**
>
>`jvm`支持字节码指令   调用静态方法 一种是调用动态方法
>
>重载：Java在实现重载时，是使用静态选择的，因为在编译期，要调用哪个重载方法已经确定下来了。编译器能够区分出方法的重载版本。
>
>重写：重写是多态的表现形式之一，方法签名在编译期确定，具体调用子类还是父类的方法，得看接受者的实际类型，得在运行期确定。调用动态方法。





## 内部类和静态内部类区别

>静态内部类：
>
>只是为了降低包的深度，方便类的使用，静态内部类适用于包含类当中，但又不依赖与外在的类，不用使用外在类的非静态属性和方法，只是为了方便管理类结构而定义。在创建静态内部类的时候，不需要外部类对象的引用。
>
>
>
>**内部类存在内存泄漏：**
>
>- 内部类方法可以访问该类定义所在的作用域中的数据，包括私有的数据
>- 内部类可以对同一个包的其他类隐藏
>- 外部类访问不到内部类
>- 静态内部类和非静态内部类最大的区别是：**非静态内部类编译后隐式保存着外部类的引用（就算外部类对象没用了也GC不掉）**，但是静态内部类没有。



## 枚举类存在得意思，与Class有什么不同

>- https://blog.csdn.net/javazejian/article/details/70768369   
>- 相比与`class`文件定义`final int `常量，枚举常量在类型安全性和便捷性都很有保证，如果出现类型问题编译器也会提示我们改进。
>- 并且枚举类经过编译器编译之后     变成 `final` 类继承自`java.lang.Enum`（抽象类） 编译器还为我们生成了两个静态方法，分别是`values()和 valueOf()`
>- `ordinal()` 返回枚举常量的序数（它在枚举声明中的位置，其中初始常量序数为零）  `compareTo(E o)`方法则是比较枚举的大小
>- `enum`类并不能再继承其它类，但并不妨碍它实现接口，因此`enum`类同样是可以实现多接口



## java基本类型 && 包装器类型

>**为什么存在这两种类型呢？**
>
>我们都知道在Java语言中，new一个对象存储在堆里，我们通过栈中的引用来使用这些对象；但是对于经常用到的一系列类型如int，如果我们用new将其存储在堆里就不是很有效——特别是简单的小的变量。所以就出现了基本类型，同C++一样，Java采用了相似的做法，对于这些类型不是用new关键字来创建，而是直接将变量的值存储在栈中，因此更加高效。
>
>
>
>**有了基本类型为什么还要有包装类型呢？**
>
>我们知道Java是一个面相对象的编程语言，基本类型并不具有对象的性质，为了让基本类型也具有对象的特征，就出现了包装类型（如我们在使用集合类型Collection时就一定要使用包装类型而非基本类型），它相当于将基本类型“包装起来”，使得它具有了对象的性质，并且为其添加了属性和方法，丰富了基本类型的操作。
>
>另外，当需要往ArrayList，HashMap中放东西时，像int，double这种基本类型是放不进去的，因为容器都是装object的，这是就需要这些基本类型的包装器类了
>
>-----
>
>
>
>
>**二者的区别：**
>
>1. 声明方式不同：
>
>基本类型不使用new关键字，而包装类型需要使用new关键字来在堆中分配存储空间；
>
>2. 存储方式及位置不同：
>
>基本类型是直接将变量值存储在栈中，而包装类型是将对象放在堆中，然后通过引用来使用；
>
>3. 初始值不同：
>
>基本类型的初始值如int为0，boolean为false，而包装类型的初始值为null；
>
>4. 使用方式不同：
>
>基本类型直接赋值直接使用就好，而包装类型在集合如Collection、Map时会使用到。









# ==------------------------------------------------------------------------------关键字==

# public && private && protect && default 

>`protect  private public default    java` 语言中，不加任何限定符表示的是什么
>
>| 修饰符    | 类内部 | 同个包（package） | 子类           | 其他范围 |
>| --------- | ------ | ----------------- | -------------- | -------- |
>| public    | Y      | Y                 | Y              | Y        |
>| protected | Y      | Y                 | Y              | N        |
>| 无修饰符  | Y      | Y                 | Y或者N(见说明) | N        |
>| private   | Y      | N                 | N              | N        |
>
>需要特别说明“无修饰符”这个情况，子类能否访问父类中无修饰符的变量/方法，取决于子类的位置。如果子类和父类在同一个包中，那么子类可以访问父类中的无修饰符的变量/方法，否则不行。



# final && finally && finalize

>- **final关键字作用**
>
>1. 当*final*修饰**变量**时，被修饰的变量必须被初始化(赋值)，且后续不能修改其值，实质上是常量；
>2. 当*final*修饰**方法**时，被修饰的方法无法被所在类的子类重写（覆写）；
>3. 当*final*修饰**类**时，被修饰的类不能被继承，并且*final*类中的所有成员方法都会被隐式地指定为*final*方法，但成员变量则不会变。
>
>-----
>
>- `final finally finalize `三者区别
>
>1. `final`可以修饰类、变量、方法，修饰类表示该类不能被继承、修饰方法表示该方法不能被重写、修饰变量表
>     示该变量是一个常量不能被重新赋值。
>2. `finally`一般作用在`try-catch`代码块中，在处理异常的时候，通常我们将一定要执行的代码方法`finally`代码块中，表示不管是否出现异常，该代码块都会执行，一般用来存放一些关闭资源的代码。jdk1.8以后 可以利用lambda表达式来代替try catch
>3. `finalize`是一个方法，属于`Object`类的一个方法，而`Object`类是所有类的父类，该方法一般由垃圾回收器来调
>     用，当我们调用`System.gc() `方法的时候，由垃圾回收器调用`finalize()`，回收垃圾，一个对象是否可回收的最后判断。
>
>----
>
>- **finally 中执行return语句会发生什么 **
>
>1. 如果是在` finally`中发生异常、前面的代码中用了`System.exit()`退出程序。不会执行finally语句中方法返回
>2. 其次如果try里边发生异常，也不会返回
>3. 正常情况下 最后是返回finally语句中的返回值









# this && super

>**this与super的区别**
>
>- super:　引用当前对象的直接父类中的成员（用来访问直接父类中被隐藏的父类中成员数据或函数，基类与派生类中有相同成员定义时如：super.变量名 super.成员函数据名（实参）
>- this：它代表当前对象名（在程序中易产生二义性之处，应使用this来指明当前对象；如果函数的形参与类中的成员数据同名，这时需用this来指明成员变量名）
>- super()和this()类似,区别是，super()在子类中调用父类的构造方法，this()在本类内调用本类的其它构造方法。
>- super()和this()均需放在构造方法内第一行。
>- 尽管可以用this调用一个构造器，但却不能调用两个。
>- this和super不能同时出现在一个构造函数里面，因为this必然会调用其它的构造函数，其它的构造函数必然也会有super语句的存在，所以在同一个构造函数里面有相同的语句，就失去了语句的意义，编译器也不会通过。
>- this()和super()都指的是对象，所以，均不可以在static环境中使用。包括：static变量,static方法，static语句块。
>- 从本质上讲，this是一个指向本对象的指针, 然而super是一个Java关键字。





# static

>- **static关键字作用 **   **被static修饰的成员变量和成员方法独立于该类的任何对象**
>
>1. 修饰内部类： 普通类不允许声明为静态的，只有内部类才可以
>2. 修饰方法：    直接类名.方法() 调用即可
>3. 修饰类变量： `static` 和` static final`两方面修饰类变量进行分析
>
>`public static int value=1;`
>变量`value`准备阶段后的初始值为`0`，而把`value`赋值为`1`的动作要等到类得初始化阶段才会执行
>
>`public static final int value=1`
>编译时`javac`将会把`value`生成`ConstValue`属性，在准备阶段 虚拟机就会把`value`值赋值为`1`

------------------------

## **staitic 方法是否可以被继承**

>静态方法和属性是属于类的，调用的时候直接通过类名.方法名完成对，不需要继承机制及可以调用。如果子类里面定义了静态方法和属性，那么这时候父类的静态方法或属性称之为"隐藏"。如果你想要调用父类的静态方法和属性，直接通过父类名.方法或变量名完成，至于是否继承一说，子类是有继承静态方法和属性，但是跟实例方法和属性不太一样，存在"隐藏"的这种情况



## Static 方法可以被重写么

>首先`java`的静态方法不能被重写
>
>1. 静态方法，可以通过类直接调用（是属于类的方法，静态方法在代码中的调用方式一般形式是：Math.abs(); 当然通过引用该类型对象的变量也可以调用，只是通常不这样使用）；
>
>2. 实例方法，只能通过对象调用；
>
>3. 重写的目的在于父类引用可以根据子类对象的运行时实际类型不同而调用不同实现代码，从而表现出多态。并且，静态方法无需创建对象即可使用，而重写的方法发挥作用，需要父类引用，和（不同的）子类对象。
>
>-----
>
>如果子类和父类有相同的静态方法 那么谁调用 就是谁的。







# 基础



我认为男人啊 还是得有事业呗 就是哈呢 好像就是好像你你呗 就是哈在这里哈呢  在这里就是好像你  哈哈还是这个键盘膜就是得劲呗 我可以看见默认迷人的心碎  你眼光独有的温暖 是所有的惊天 明天 元这个  这个更加珍贵  授信的蔷薇 你知道呗疼爱

# ==--------------------------------------------------------------------------java基础==



## 一段Java代码程序到执行经历怎么样的过程

>重 编译原理 从代码变成二进制的过程。
>
>![preview](https://pic2.zhimg.com/v2-8edf65dab99c1fbc1c04d4f66b1d5eed_r.jpg)
>
>**编译阶段：**
>
>1. 在硬盘新建xxx.java文件
>
>2. 用文本编辑器打开文件编写java源代码
>
>3. javac命令(编译命令)对xxx.java文件编译
>
>4. 编译通过为.class字节码文件，未通过报错
>
>  **运行阶段：**
>
>  2. javac(负责运行的命令)执行xxx.class字节码
>  3. 启动JVM，JVM启动类加载器，类加载器去硬盘找类对应的字节码文件
>  4. JVM对字节码进行解释，将字节码转换为二进制
>  5. JVM将二进制码交给操作系统，操作系统执行二进制码和硬件进行交互



## `java c c++ `区别

>- 面向过程和面向对象
>
>面向过程是一种以事件为中心的编程思想，编程的时候把解决问题的步骤分析出来，然后用函数把这些步骤实现，在一步一步的具体步骤中再按顺序调用函数。
>
>面向对象的编程思想。面向对象是一种以“对象”为中心的编程思想，把要解决的问题分解成各个对象，建立对象的目的不是为了完成一个步骤，而是为了描叙某个对象在整个解决问题的步骤中的属性和行为

>2. `c++`和`java`区别    
>
>- c++支持指针，而java没有指针的概念 java是引用传递
>- c是面向过程的语言  java是面向对象的语言
>- `java`和`c++`都是面向对象的语言，都支持封装、继承和多态
>- Java 不提供指针来直接访问内存，程序内存更加安全
>- Java 的类是单继承的，C++ 支持多重继承；虽然 Java 的类不可以多继承，但是接口可以多继承。
>- Java 有自动内存管理垃圾回收机制(GC)，不需要程序员手动释放无用内存。c++必须右程序主动释放内存资源
>- C ++同时支持方法重载和操作符重载，但是 Java 只支持方法重载（操作符重载增加了复杂性，这与 Java 最初的设计思想不符）。



## JVM、JRE和JDK的关系

>`JVM`
>`Java Virtual Machine`是`Java`虚拟机，`Java`程序需要运行在虚拟机上，不同的平台有自己的虚拟机，因此`Java`语言可以实现跨平台。
>
>JRE
>`Java Runtime Environment`包括`Java`虚拟机和`Java`程序所需的核心类库等。核心类库主要是`java.lang`包：包含了运行`Java`程序必不可少的系统类，如基本数据类型、基本数学函数、字符串处理、线程、异常处理类等，系统缺省加载这个包,如果想要运行一个开发好的`Java`程序，计算机中只需要安装JRE即可。
>
>`JDK`
>Java Development Kit是提供给Java开发人员使用的，其中包含了Java的开发工具，也包括了JRE。所以安装了JDK，就无需再单独安装JRE了。其中的开发工具：编译工具(javac.exe)，打包工具(jar.exe)等
>
>总结： JDK包括JRE、JVM     JRE包括JVM







## 为什么String类是不可变类

>不可变类定义：对象一旦被创建后，对象所有的状态及属性在其生命周期内不会发生任何变化， 可以这样认为：如果一个对象，在它创建完成之后，不能再改变它的状态，那么这个对象就是不可变的。不能改变状态的意思是，不能改变对象内的成员变量，包括基本数据类型的值不能改变，引用类型的变量不能指向其他的对象，引用类型指向的对象的状态也不能改变。
>
>- java8来判断String对象不可变
>
>```java
>private final char[] value;   //String类就是对字符数组的封装  value也只是一个引用，它指向一个真正的数组对象，并且属性value没有setValue()方法 
>
>//由于value数组是私有属性并且没有setVlue()方法 ，同时 replace， substring，toLowerCase等方法都是返回新的String对象 并没有对原来对象做改变所以String一旦创建对象 无法通过String类外部来改变value数组 则就是不可变对象  
>
>
>//final修饰引用数据类型，比如对象、数组，则该对象 数组本身可以修改，但指向该对象或数组的地址的引用不能修改 .value不能再指向其他数组对象.   同时 replace， substring，toLowerCase等方法都是返回新的String对象 并没有对原来对象做改变  value又指向新的字符数组  
>```
>
>- 但是String对象真的不可变么   **反射获取String对象中的value属性来改变字符数组的值**
>
>```java
>private final char[] value;  //value这是一个引用，并不是真正的对象 value是final修饰的 value不能再指向其他数组
>							//所以这里边就是可以通过反射来获取value这个变量 从而通过它来去改变数组里边的值
>
>		String s = "Hello World"; 
>		System.out.println("s = " + s);	//Hello World
>
>		//获取String类中的value字段属性 
>		Field valueFieldOfString = String.class.getDeclaredField("value");
>
>		//改变value属性的访问权限
>		valueFieldOfString.setAccessible(true);
>
>		//获取s对象上的value属性的值
>		char[] value = (char[]) valueFieldOfString.get(s);
>
>		//改变value所引用的数组中的第5个字符
>		value[5] = '_';
>
>		System.out.println("s = " + s);  //Hello_World
>```

## String 和 new String("abc")

>- String种hashCode()方法   ？相同对象哈希码要相同。同对象哈希码要不同。
>
>  `hashcode==h = 31 * h + val[i];` 为什么是31呢 ?
>
>1. 31 是一个素数，与素数相乘得到的结果比其他方式更容易产生唯一性。
>2. Java 中如果相乘的数字太大会导致内存溢出问题，从而导致数据丢失。
>
>------
>
>```java
>new String（"abc"）生成了几个对象
>
>String str1 = "abc";  // 在常量池中
>
>String str2 = new String("abc"); // 在堆上
>```
>
>当直接赋值时，字符串“abc”会被存储在常量池中，只有1份，此时的赋值操作等于是创建0个或1个对象。如果常量池中已经存在了“abc”，那么不会再创建对象，直接将引用赋值给str1；如果常量池中没有“abc”，那么创建一个对象，并将引用赋值给str1。
>
>那么，通过new String(“abc”);的形式又是如何呢？答案是1个或2个。
>
>当JVM遇到上述代码时，会先检索常量池中是否存在“abc”，如果不存在“abc”这个字符串，则会先在常量池中创建这个一个字符串。然后再执行new操作，会在堆内存中创建一个存储“abc”的String对象，对象的引用赋值给str2。此过程创建了2个对象。
>
>-------
>
>自定义String类会怎么样
>
>-----
>
>一般是： 自定义类加载器 >> 应用程序类加载器 >> 扩展类加载器 >> 启动类加载器
>
>再简单说下双亲委托机制：如果一个类加载器收到了类加载的请求，它首先不会自己尝试去加载这个类，而是把这个请求委派给父类加载器，每一个层次的类加载器都是加此，因此所有的加载请求最终到达顶层的启动类加载器，只有当父类加载器反馈自己无法完成加载请求时（指它的搜索范围没有找到所需的类），子类加载器才会尝试自己去加载。
>
>各个类加载器之间是组合关系，并非继承关系。
>
>当一个类加载器收到类加载的请求，它将这个加载请求委派给父类加载器进行加载，每一层加载器都是如此，最终，所有的请求都会传送到启动类加载器中。只有当父类加载器自己无法完成加载请求时，子类加载器才会尝试自己加载。
>
>双亲委派模型可以确保安全性，可以保证所有的Java类库都是由启动类加载器加载。如用户编写的java.lang.Object，加载请求传递到启动类加载器，启动类加载的是系统中的Object对象，而用户编写的java.lang.Object不会被加载。如用户编写的java.lang.virus类，加载请求传递到启动类加载器，启动类加载器发现virus类并不是核心Java类，无法进行加载，将会由具体的子类加载器进行加载，而经过不同加载器进行加载的类是无法访问彼此的。由不同加载器加载的类处于不同的运行时包。所有的访问权限都是基于同一个运行时包而言的。

## String StringBuilder StringBuffer

>String 类不可变类，内部维护的char[] 数组长度不可变，被final修饰，String类也是final修饰，不存在扩容。字符串拼接，截取，都会生成一个新的对象。频繁操作字符串效率低下，因为每次都会生成新的对象。
>
>StringBuilder 类内部维护可变长度char[] ， 初始化数组容量为16，存在扩容， 其append拼接字符串方法内部调用System的native方法，进行数组的拷贝，不会重新生成新的StringBuilder对象。非线程安全的字符串操作类， 其每次调用 toString方法而重新生成的String对象，不会共享StringBuilder对象内部的char[]，会进行一次char[]的copy操作。
>
>StringBuffer 类内部维护可变长度char[]， 基本上与StringBuilder一致，但其为线程安全的字符串操作类，大部分方法都采用了Synchronized关键字修改，以此来实现在多线程下的操作字符串的安全性。其toString方法而重新生成的String对象，会共享StringBuffer对象中的toStringCache属性（char[]），但是每次的StringBuffer对象修改，都会置null该属性值。·1
>
>**性能比较方面上： StringBuilder>StringBuffer>String   优先考虑StringBuilder性能比较高（在没有访问共享资源的前提下呗）**





## Java中变量存储的位置

>#### 静态变量
>
>存储位置：JDK8之前，静态成员变量确实存放在方法区；但JDK8之后就取消了“永久代”，取而代之的是“元空间”，永久代中的数据也进行了迁移，**静态成员变量迁移到了堆中（方法区是JVM的规范，永久代是方法区的具体实现）。**
>
>类变量是指类的static变量，用类名可以直接访问。
>生命周期从加载类开始，到销毁类结束。
>
>#### 局部变量
>
>- 局部变量是指定义在方法或代码块中的变量，局部变量必须初始化，在方法或代码块内有效，之外则无效，方法执行开始入栈时创建，执行完毕出栈时销毁。
>- 形式参数是局部变量，局部变量的数据存在于**栈**内存中。**栈内存中的局部变量随着方法的消失而消失**。
>
>#### 类成员变量
>
>- 成员变量就是方法外部，类的内部定义的变量
>- 其作用域受限定符限定，Private的只能在本类中使用，protected子类可用，public任何地方都可用。
> 生命周期从对象创建开始到对象销毁结束。
>  **成员变量存储在堆中的对象里面，由垃圾回收器负责回收**。
>
>#### 字符串
>
>对于字符串：其对象的引用都是存储在栈中的，如果是编译期已经创建好(直接用双引号定义的)的就存储在常量池中，如果是运行期（new出来的）才能确定的就存储在堆中。对于equals相等的字符串，在常量池中永远只有一份，在堆中有多份。
>
>
>
>```dart
>1.String s1 = "china";  
>2.String s2 = "china";  
>3.String s3 = "china";  
>4.String ss1 = new String("china");  
>5.String ss2 = new String("china");  
>6.String ss3 = new String("china");  
>```
>
>对于通过new产生一个字符串（假设为”china”）时，会先去常量池中查找是否已经有了”china”对象，如果没有则在常量池中创建一个此字符串对象，然后堆中再创建一个常量池中此”china”对象的拷贝对象。这也就是有道面试题：String s = new String(“xyz”);产生几个对象？一个或两个，如果常量池中原来没有”xyz”,就是两个。
>对于基础类型的变量和常量：**变量和引用存储在栈中，常量存储在常量池中。**
>
>所以就是还是使用这个呗





## ==与equals以及hashcode

>1. `==`和`equals`区别
>
>在JDK源码里边 equals方法就是用==来判断的 所以他俩基本上是一样的 
>
>如果是基本类型 就是比较值
>
>如果是引用类型 就是比较地址值
>
>但是有一些类重写equals方法 所以可能就是比较的是里边内容值
>
>-------
>
>2. `equals和hashcode`方法
>
>- **equals()其底层是使用了“==”来实现**，也就是说**通过比较两个对象的内存地址是否相同**判断是否是同一个对象。很明显，该方法就是用来判断两个对象是否是同一个对象
>
>- 默认的hashcode方法是根据对象的内存地址经哈希算法得来的
>
>
>
>1. 如果两个对象相同（即用equals比较返回true），那么它们的hashCode值一定要相同！！！！； 
>2. 如果两个对象不同（即用equals比较返回fase），那么它们的hashCode值可能相同也可能不同；
>3.  如果两个对象的hashCode相同（存在哈希冲突），那么它们可能相同也可能不同(即equals比较可能是false也可能是true) 
>4. 如果两个对象的hashCode不同，那么他们肯定不同(即用equals比较返回false)
>
>以`hashmap`来举例子，判断对象是否相同先是比较`hash`值 之后在用`equals比`较。 假如在这里不重写`hashcode` 那么比较内容就会出错
>
>------
>
>**既然equals已经能实现对比功能，为什么还需要hashcode呢？**
>
>因为重写的equals()里一般比较的比较全面比较复杂，这样效率就比较低，而利用hashCode()进行对比，则只要生成一个hash值进行比较就可以了，效率很高。
>
>-------
>
>**为什么hashcode效率高还需要重写equals呢？**
>
>因为hashCode()并不是完全可靠，有时候不同的对象他们生成的hashcode也会一样（生成hash值得公式可能存在的问题），所以hashCode()只能说是大部分时候可靠，并不是绝对可靠，









## 创建对象的方式 

>- **使用new关键字**
>
>首先在方法区的常量池中查看是否有new 后面参数（也就是类名）的符号引用，并检查是否有类的加载信息也就是是否被加载解析和初始化过。如果已经加载过了就不在加载，否则执行类的加载全过程,加载完类后，大致做了如下三件事：
>a、给实例分配内存
>b、调用构造函数，初始化成员字段  就只初始化类成员变量
>c、`use`r对象指向分配的内存空间
>注意：new操作不是原子操作，`b和c`的顺序可能会调换
>
>
>
>- **反射： **
>
>`source：		   Class.forname`("全类名")  将字节码文件加载到内存当中  返回`Class`对象  `clazz.newInstance`获取实例 
>`ClassLoader`: 	        类名`.class   `  通过类型得属性来获取`Class`对象 
>Runtime：  	             对象.`getClass`   是 Object方法
>
>在拿到类对象的`Clas`s后，就可以通过`Java`的反射机制来创建类对象的实例对象了,调用类对象的构造方法 `Consturctor.newInstance() `构造方法创建对象
>
>
>
>- 反序列化创建对象
>
>序列化是指将对象的状态信息转换为可以存储或传输的形式的过程。
>a)当你想把的内存中的对象状态保存到一个文件中或者数据库中时候;
>b)当你想用套接字在网络上传送对象的时候;   				 正常的输入输出流 感觉就可以
>c)当你想通过RMI（远程方法调用）传输对象的时候;	
>
>
>
>- `clone`         实现接口`implements Cloneable `才能调用`Object`方法 
>
>当我们调用一个对象的`clone`方法，`jvm`就会创建一个新的对象，将前面对象的内容全部拷贝进去。用`clone`方法创建对象并不会调用任何构造函数。因为`Object `类的` clone` 方法的 原理是从内存中（堆内存）以二进制流的方式进行拷贝，重新分配一个内存块，那构造函数没有被执行也是非常正常的了.
>
>
>
>- 动态代理   分`JDK CGLIB` ` JDK`代理的是接口  `CGLIB`代理的是子承夫类这种
>
>```xml
>    * Cglib 夫类动态代理 跟JDK接口动态代理区别就是
>
>    * Proxy.newInstance(ClassLoader classLoader,Interface[],InvocationHandler handler)
>    * JDK动态代理类 没有源文件 也即没有.class文件 没有.class文件也就无法创建通过类加载器创建java.lang.Class对象 重而就无法创建类实例
>    * 源码程序进行验证、优化、缓存、同步、生成字节码sun.misc.ProxyGenerator::generatorProoxyClass()方法来完成生成字节码的动作件 但是字节码有了 ，没有类加载器就无法将字节码文件加载进JVM当中 所以就需要借一个类加载器（随便那个都可以）
>    * JDK动态代理需要实现目标类实现的接口时Interface[] 例如UserService.getClass.getInterface();
>    * InvocationHandler 实现这个接口完成  public Object invoke(Object proxy, Method method, Object[] args)  来完成额外附加的方法
>    * proxy是目标类 method是目标方法 args是目标方法的参数   通过method.invoke(target,args);
>
>    * 而Cglib 基于代理是我们想代理某个类 而这个类又没有实现接口 所以Cglib是父子继承的动态代理
>    * Proxy.newInstance(ClassLoader classLoader,Interface[],InvocationHandler 实施invoke方法)
>    * Enhancer.setClassLoader();
>    * Enhance.setSupperClass()
>    * MethodInterceptor 实施interceptor方法
>    * Enhancer.create();
>cglib 没有接口也能实现动态代理，而且采用字节码增强技术，性能也不错。  由于CGLib由于是采用动态创建子类的方法，对于final方法，无法进行代理。
>JDK 动态代理是基于接口设计实现的，如果没有接口，会抛异常。
>```
>
>- 使用Unsafe 
>
>```xml
>sun.misc.Unsafe中提供allocateInstance方法，仅通过Class对象就可以创建此类的实例对象，而且不需要调用其构造函数、初始化代码、JVM安全检查等。它抑制修饰符检测，也就是即使构造器是private修饰的也能通过此方法实例化，只需提类对象即可创建相应的对象。由于这种特性，allocateInstance在java.lang.invoke、Objenesis（提供绕过类构造器的对象生成方式）、Gson（反序列化时用到）中都有相应的应用。
>```

>1. new 对象的过程
>2. 父类子类执行顺序
>3. Object object=new Object()在内存中占了多少字节
>4. 数字9在java中占用多少个字节
>5. 父类子类执行顺序



## java中Object方法

>- public Object()  默认无参的构造方法 
>- registerNatives()  注册本地函数
>
>- clone()方法 浅拷贝
>
>```xml
>new操作符的本意是分配内存。程序执行到new操作符时， 首先去看new操作符后面的类型，因为知道了类型，才能知道要分配多大的内存空间。分配完内存之后，再调用构造函数，填充对象的各个域，这一步叫做对象的初始化，构造方法返回后，一个对象创建完毕，可以把他的引用（地址）发布到外部，在外部就可以使用这个引用操纵这个对象。而clone在第一步是和new相似的， 都是分配内存，调用clone方法时，分配的内存和源对象（即调用clone方法的对象）相同，然后再使用原对象中对应的各个域，填充新对象的域， 填充完成之后，clone方法返回，一个新的相同的对象被创建，同样可以把这个新对象的引用发布到外部。  在堆中是存在两个对象的
>  private static class Person{
>      private int age;            Person p1=new Person();   Person p2=p1.clone();  
>      private Integer girl;  		//浅拷贝 基本类型是直接赋值  而对于引用类型的话 克隆出来的新对象中的引用对象还是指向原对象中的引用对象
>      private String name;	    //一个String对象所引用指向的地址是不会变得  所以这里边克隆出来得新对象对String操作 会实现深拷贝
>  }
>//针对于String类来说引用类型的变量不能指向其他的对象，是指String类中value属性的。value属性也是一个数组引用类型，用final修饰，因此不可指向其他对象
>```
>
>- getClass()  
>
>作为概念层次的类，其本身也具有某些共同的特性，如都具有类名称、由类加载器去加载，都具有包，具有父类，属性和方法等。于是，Java中有专门定义了一个类，Class，去描述其他类所具有的这些特性，因此，从此角度去看，类本身也都是属于Class类的对象。为与经常意义上的对象相区分，在此称之为"类对象"。
>
>```xml
>//首先拿到类对象Class 有三种方法
>source：		   Class.forname("全类名")  将字节码文件加载到内存当中  返回Class对象  clazz.newInstance获取实例 
>ClassLoader: 	类名.class     通过类型得属性来获取Class对象 
>Runtime：  	  对象.getClass   是 Object方法
>作为概念层次的类，其本身也具有某些共同的特性，如都具有类名称、由类加载器去加载，都具有包，具有父类，属性和方法等。于是，Java中有专门定义了一个类，Class，去描述其他类所具有的这些特性，因此，从此角度去看，类本身也都是属于Class类的对象。为与经常意义上的对象相区分，在此称之为"类对象"。
>在拿到类对象的Class后，就可以通过Java的反射机制来创建类对象的实例对象了，主要分为两种方式：
>Class.newInstance()
>调用类对象的构造方法 Consturctor.newInstance() 构造方法创建对象      
>```
>
>- equal()  判断地址值还是内容相等分情况而定被
>
>```java
>public boolean equals(Object obj) {      == 基本类型就是值  引用类型就是判断地址一不一样  equal()其实跟==定义是一样的
>   return (this == obj);
>}										//只不过有些类重写了equal()方法 例如String  HashMap  判断内容是不是相等
>```
>
>- hashCode()  6种计算hashCode方案被 在这里哈呢
>
>```xml
>6种计算 hash 值的方案，有自增序列，随机数，关联内存地址等多种方式，其中官方默认的是最后一种，即随机数生成。可以看出 hashCode 也许和内存地址有关系，但不是直接代表内存地址的，具体需要看虚拟机版本和设置。
>
>hashCode方法本质就是一个哈希函数，将对象的地址值映射为integer类型的哈希值。
>我们看到，hashCode方法注释中列了个列表，列表中有三条注释，当前需要理解的大致意思如下：
>1.一个对象多次调用它的hashCode方法，应当返回相同的integer（哈希值）。
>2.两个对象如果通过equals方法判定为相等，那么就应当返回相同integer。
>3.两个地址值不相等的对象调用hashCode方法不要求返回不相等的integer，但是要求拥有两个不相等integer的对象必须是不同对象。
>1.相同的对象必然导致相同的哈希值。
>2.不同的哈希值必然是由不同对象导致的。
>
>因为必须保证重写后的equals方法认定相同的两个对象拥有相同的哈希值”。同时我们顺便得出了一个结论：“hashCode方法的重写原则就是保证equals方法认定为相同的两个对象拥有相同的哈希值”。 重写了equals()方法后，需要重写hashCode()方法。
>```
>
>- toString()
>
>```java
>public String toString() {
>      return getClass().getName() + "@" + Integer.toHexString(hashCode());  //toString()是由对象的类型和其16进制哈希码唯一确定
>}   
>```
>
>- wait()
>
>```xml
>wait()：调用此方法所在的当前线程等待，直到在其他线程上调用此方法的主调（某一对象）的notify()/notifyAll()方法。才被唤醒
>```
>
>- notify()/notifyAll()  
>
>```xml
>唤醒在此对象监视器上等待的单个线程/所有线程。
>```
>
>- finalze()
>
>```xml
>finalize方法主要与Java垃圾回收机制有关,先，Object中定义finalize方法表明Java中每一个对象都将具有finalize这种行为，其具体调用时机在：JVM准备对此对形象所占用的内存空间进行垃圾回收前，将被调用。由此可以看出，此方法并不是由我们主动去调用的（虽然可以主动去调用，此时与其他自定义方法无异）。
>```
>
>- **为什么Object方法中会定义wait()和notify()**
>
>```xml
>monitor对象存在于每个Java对象的对象头中(存储的指针的指向)，synchronized锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因,wait()方法使持有锁的线程进入WaitSet等待队列中 并且只有notify来唤醒被
>```
>
>wait() notify() 底层了解过吗
>
>



## Object object=new Object()在内存中占了多少字节

>- 这个就是需要jvm知识 main方法--> object指针引用到 Object对象 在堆上
>
>![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy83MDE3MTQwLTgwMzc0ZTY1YzZiMjBjYmU)

>- mark wold 对象哈希码 指向锁记录的指针、指向重量级锁的指针、对象分带年龄    **8个字节**  对象头加起来就是12个字节
>
>- 类行指针： Object.class  Person.class   指针指向你属于哪一个类   **由于默认开启压缩指针 -->classPointer 4个字节  没有开启压缩就是8个**
>- 实例数据： 类成员变量   int 4  long 8
>- 对其：        能被8整除的



>```xml
>C:\Users\whig>java -XX:+PrintCommandLineFlags -version
>-XX:InitialHeapSize=399949120  	 初始化堆大小
>-XX:MaxHeapSize=6399185920 		 最大堆大小
>-XX:+UseCompressedClassPointers  jvm系统就是64位 8个字节 默认开启UseCompressedClassPointers  指向class指针4个字节
>-XX:+UseCompressedOops 			 orindaty object point 普通对象指针引用 String s=str;  默认是压缩指针     4个字节
>Java HotSpot(TM) 64-Bit Server VM (build 25.261-b12, mixed mode)
>```
>
>```java
>Object o=new Object();   在内存中占了几个字节  //new Object 就是16个字节   但是Object o还存在一个引用 也是占4个字节
>java.lang.Object object internals:
>OFFSET  SIZE   TYPE DESCRIPTION                               VALUE
>0     4        (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)
>4     4        (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)
> 8     4        (object header)                           e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243)
> 12     4        (loss due to the next object alignment)
> Instance size: 16 bytes
>//前八个字节就是mrakworld    8-12 就是类行指针4个字节    12-16 丢失就是8的倍数
>
>例如 new User(24,"whig");  //markworld-》8个字节  类行指针--》4个字节  int-->4个字节   str-->引用4个字节
>```



## 值传递or引用传递

>1. 基本数据类型传值，对形参的修改不会影响实参；
>2. 引用类型传引用，形参和实参指向同一个内存地址（同一个对象），所以对参数的修改会影响到实际的对象； **类、接口、数组 都为引用类型。**
>3. **String, Integer, Double等immutable的类型特殊处理，可以理解为传值，最后的操作不会修改实参对象。**

##  深拷贝、浅拷贝？

>浅拷贝是指源对象与拷贝对象共用一份实体，仅仅是引用的变量不同（名称不同）。对其中任何一个对象的改动都会影响另外一个对象。深拷贝是指源对象与拷贝对象互相独立，其中任何一个对象的改动都不会对另外一个对象造成影响。



## 说说迭代器

> `Iterator`模式是用于遍历集合类的标准访问方法。它可以把**访问逻辑从不同类型的集合类中抽象出来，从而避免向客户端暴露集合的内部结构。**例如在`java`集合当中`AbstractCollection`中有大部分方法`contains  remove  toArray`中大部分方法都是由迭代器来完成。
>
> - `ArrayList`底层是数组的数据结构，如果要是访问遍历的话，就是需要数组下标索引，而是用迭代器就可以访问遍历，不需要知道内部的数据结构
> - `LinkedList`底层是双向链表，遍历的话需话需要`while`来循环遍历呢 `while(e.next!=null)`
>
> -----------------
>
> `List`一族或者`Set`一族，都是实现了`Iterable`接口，但并不直接实现`Iterator`接口 ,因为`Iterator`接口的核心方法`next()`或者`hasNext() `是依赖于迭代器的当前迭代位置 
>
> ` Iterator`是做迭代的，而`Iterable`是提供迭代器的。



## 反射

>概念：JAVA反射机制是在**运行状态中**，对于任意一个类，都能够知道这个类的所有属性和方法；这种动态获取的信息以及动态调用对象的方法的功能称为 **java语言的反射机制**。
>
>一种在程序运行时，动态获取当前类对象的所有属性和方法的能力，可以动态执行方法，给属性赋值等操作的能力
>
>------
>
>原理：Java在编译之后会生成一个**class文件**，反射通过**字节码文件**找到其类中的方法和属性等
>
>-----
>
>功能：
>
>1. 反射自由创建对象
>2. 反射构建出无法直访问的类
>3. 调用不可访问的方法
>4. 在运行中分析类的能力
>
>------
>
>获取方法：
>
>- 通过字面量直接获取，例如XXX.class，不会触发类的初始化但XXX类已经被加载到方法区。
>- 通过Object类的getClass方法，例如Object.getClass()。触发类的初始化
>- 通过Class的静态方法，例如Class.forName()。触发类的初始化
>
>   (1）类名.class：JVM将使用类装载器，将类装入内存(前提是:类还没有装入内存)，不做类的初始化工作，返回Class的对象。
>
>（2）Class.forName(“类名字符串”)：装入类，并做类的静态初始化，返回Class的对象。
>
>（3）实例对象.getClass()：对类进行静态初始化、非静态初始化；返回引用运行时真正所指的对象(子对象的引用会赋给父对象的引用变量中)所属的类的Class的对象。
>
>-----
>
>构造方法、成员变量、字段、方法 都可以通过反射来拿到
>
>-----
>
>**优点**：
>
>通过反射，java可以动态的加载未知的外部配置对象，临时生成字节码进行加载使用，使代码更灵活，极大地提高应用的扩展性。
>
>------
>
>使用场景：
>
>jdbc:通过Class.forName()加载数据库的驱动程序 （通过反射加载，前提是引入相关了Jar包)
>
>spring:Spring 通过 XML 配置模式装载 Bean 的过程, 以及AOP代理模块的机制





## 动态代理



>利用反射机制在运行时创建代理类。接口、被代理类不变
>
>代理类主要负责为委托了（真实对象）预处理消息、过滤消息、传递消息给委托类，代理类不现实具体服务，而是利用委托类来完成服务，并将执行结果封装处理。
>
>```xml
> * Proxy.newInstance(ClassLoader classLoader,Interface[],InvocationHandler handler)
> * JDK动态代理类 没有源文件 也即没有.class文件 没有.class文件也就无法创建通过类加载器创建java.lang.Class对象 重而就无法创建类实例
> * 源码程序进行验证、优化、缓存、同步、生成字节码sun.misc.ProxyGenerator::generatorProoxyClass()方法来完成生成字节码的动作件 但是字节码有了 ，没有类加载器就无法将字节码文件加载进JVM当中 所以就需要借一个类加载器（随便那个都可以）
> * JDK动态代理需要实现目标类实现的接口时Interface[] 例如UserService.getClass.getInterface();
> * InvocationHandler 实现这个接口完成  public Object invoke(Object proxy, Method method, Object[] args)  来完成额外附加的方法
> * proxy是目标类 method是目标方法 args是目标方法的参数   通过method.invoke(target,args);
> 通过 ProxyGenerator.generateProxyClass 来生成字节码文件呗 
>-------------------------------------------------------------------------------------------------------------------
> * 而Cglib 基于代理是我们想代理某个类 而这个类又没有实现接口 所以Cglib是父子继承的动态代理
> * Proxy.newInstance(ClassLoader classLoader,Interface[],InvocationHandler 实施invoke方法)
> * Enhancer.setClassLoader();
> * Enhance.setSupperClass()
> * MethodInterceptor 实施interceptor方法
> * Enhancer.create();
>cglib 没有接口也能实现动态代理，而且采用字节码增强技术，性能也不错。  由于CGLib由于是采用动态创建子类的方法，对于final方法，无法进行代理。
>JDK 动态代理是基于接口设计实现的，如果没有接口，会抛异常。
>```
>
>## 动态代理底层实现
>
>动态代理具体步骤：
>
>1. 通过实现 InvocationHandler 接口创建自己的调用处理器；
>2. 通过为 Proxy 类指定 ClassLoader 对象和一组 interface 来创建动态代理类；
>3. 通过反射机制获得动态代理类的构造函数，其唯一参数类型是调用处理器接口类型；
>4. 通过构造函数创建动态代理类实例，构造时调用处理器对象作为参数被传入。
>
>通过` Proxy`类的静态方`newProxyInstance` 方法进行源码探查  一系列检查后，调用`ProxyGenerator.generateProxyClass`来生成字节码文件。字节码生成后，调用`defineClass0`来解析字节码，生成了Proxy的Class对象





## 注解

>https://juejin.cn/post/6844903636733001741
>
>注解的本质就是一个继承了 Annotation 接口的接口   注解其实也是一个接口呗 , 一个注解准确意义上来说，只不过是一种特殊的注释而已，如果没有解析它的代码，它可能连注释都不如。
>
>而当你通过反射，也就是我们这里的 `getAnnotation` 方法去获取一个注解类实例的时候，其实` JDK` 是通过动态代理机制生成一个实现我们注解（接口）的代理类。
>
>```xml
>AnnotationInvocationHandler
>private final Map<String, Object> memberValues;
>public Object invoke(Object var1, Method var2, Object[] var3) {}
>```
>
>1. 首先，我们通过键值对的形式可以为注解属性赋值，像这样：`@Hello（value = "hello"）。`
>
>2. 接着，你用注解修饰某个元素，编译器将在编译期扫描每个类或者方法上的注解，会做一个基本的检查，你的这个注解是否允许作用在当前位置，最后会将注解信息写入元素的属性表。
>
>3. 然后，当你进行反射的时候，虚拟机将所有生命周期在 `RUNTIME` 的注解取出来放到一个 `map` 中，并创建一个` AnnotationInvocationHandler` 实例，把这个` map `传递给它。
>
>4. 最后，虚拟机将采用 `JDK` 动态代理机制生成一个目标注解的代理类
>
>那么这样，一个注解的实例就创建出来了，它本质上就是一个代理类，应当去理解好` AnnotationInvocationHandler 中 invoke `方法的实现逻辑，这是核心。一句话概括就是，通过方法名返回注解属性值。



## Happen before了解吗 

>如果**一个操作执行的结果需要对另一个操作可见**，那么这两个操作之间必须存在happens-before关系。
>
> **happens-before不要求前一个操作和后一个操作的发生顺序, 仅仅要求前一个操作的执行完成并刷新回内存发生在后一个操作结果之前**
>
>------
>
>**为啥要强调完成并刷新回内存(对后操作可见)呢?**
>
>这个是因为JAVA内存模型有本地缓存的抽象概念, 指令执行完结果放在本地缓存其他线程是看不到的, 要刷新回主内存对其他线程才可见(大家看到内存的结果才知道这个指令执行完了) 



## Comparable 和 Comparator 

>`Comparable`是在集合内部定义的方法实现的排序，位于java.lang下。
>`Comparable `接口仅仅只包括一个函数，它的定义如下：`public int compareTo(T o);`
>
>自定义类要在加入list容器中后能够排序，也可以实现Comparable接口。
>
>在用`Collections类的sort`方法排序时若不指定那就以自然顺序排序。若一个类实现了comparable接口，则意味着该类支持排序。如String、Integer自己就实现了Comparable接口，可完成比较大小操作。
>
>一个已经实现comparable的类的对象或数据，可以通过Collections.sort(list) 或者Arrays.sort(arr)实现排序
>
>------
>
>**Comparator**
>
>Comparator是在集合外部实现的排序，位于java.util下。
>Comparator接口包含了两个函数。
>
>```java
>int compare(T o1, T o2);
>boolean equals(Object obj);
>```
>我们若需要控制某个类的次序,而该类本身不支持排序(即没有实现Comparable接口);那么，我们可以新建一个该类的比较器来进行排序。这个比较器只需要实现comparator即可。
>Comparator是一个专用的比较器，当这个对象不支持自比较或者自比较函数不能满足要求时，可写一个比较器来完成两个对象之间大小的比较。comparable相当于内部比较器。comparator相当于外部比较器。



## java8新特性、Lambda、接口、流

>https://www.cnblogs.com/kendoziyu/p/java8-stream.html
>
>**函数式接口**
>
>##### jdk8中关于Lambda表达式提供的4个基本的函数式接口：
>
>![img](https://image-static.segmentfault.com/684/556/684556003-5e889fd0a243b)
>
>**Lambda 表达式在 Java 8 中首先会生成一个私有的静态函数，这个私有的静态函数干的就是 Lambda 表达式里面的内容。**
>
>说明通过 `@FunctionalInterface` 标记的接口可以通过 Lambda 表达式创建实例。
>
>-------
>
>#### 接口
>
>1. 静态方法可以直接调用，不能被重写
>2. 默认方法需要通过实现类，重写后实例化后调用
>3. 使用 `default` 关键字向接口添加非抽象方法实现。 此功能也称为[虚拟扩展方法](http://stackoverflow.com/a/24102730)。
>
>-------
>
>##### 流表达式
>
>https://juejin.cn/post/6844903830254010381

## List去重 排序 分组 求和

>##### 去重复
>
>- `list.stream().distinct().collect(Collectors.toList());   `    distinct lambda去重复
>- 申请额外空间 利用set集合 或者遍历list集合比较在添加



## 逃逸分析 

>jvm里面的堆会分配指定的内存空间用来存储对象信息，但是当对象信息过多的时候，GC进行垃圾回收时，过多的对象需要进行回收，会导致效率的底下。
>
>**1.如何理解逃逸分析？**
>
> 所谓的逃逸分析是指方法创建对象之后，除了在方法体内被引用到之外，还在别处也被引用到了。由于GC进行对象回收的时候需要判断该对象是否有被引用，因此当相应方法执行完毕后，由于方法类对象还被外部程序引用，就会导致相应对象无法被GC回收处理，也就造成了内存逃逸现象。
>
>
>
> **2.什么是栈上分配？**
>
>在以往的java程序运行时候，对象的内存空间都是通过堆来进行分配的。方法体内的局部变量都是通过栈来进行内存空间分配的，因此如果我们能够控制一个对象的活动范围只在一个局部方法里面的话，并且控制该对象的空间分配就存在于栈里面。这样随着栈的出栈操作，对象就会被销毁，减少了对于GC的效率影响。
>
>
>
>**3.同步消除是什么？**
>
>当通过逃逸分析之后，发下某个对象在没有被外部线程所引用的时候，他的读写竞争也就不存在了，这个时候就可以消除他的同步操作。
>
>
>
>**4.标量替换**
>
>标量是指java虚拟机里面的原始数据（那些不可再去细化分隔的基本类型，例如int，float这些）。当某个数据可以被继续进行细化拆分的时候，我们称之为聚合量（例如我们常说的对象）。
>
>如果jvm的逃逸分析分析出来了某个对象不会被外部所引用。那么当jvm执行相应函数的时候也不会直接创建相应的对象，而是通过将对象里面的各个属性拆开单独创建，单独维护。这样做的好处在于可以将原本需要连续空间存储的对象给拆分开来，减少连续内存空间的占用。
>
>由于java的对象内存分配大多数情况下都是通过堆来进行分配，因此它的垃圾回收效率成为了java性能较慢的一个因素，这也是java语言被人吐槽的一个缺点。
>
>
>
>**5.逃逸分析总结**
>
>逃逸分析的原理理解起来很简单，但JVM在应用过程中，还是有诸多考虑。
>
>比如，逃逸分析不能在静态编译时进行，必须在**JIT**里完成。原因是，与java的动态性有冲突。因为你可以在运行时，通过动态代理改变一个类的行为，此时，逃逸分析是无法得知类已经变化了。逃逸分析另一个重要的优化 - 同步消除。如果你定义的类的方法上有同步锁，但在运行时，却只有一个线程在访问，此时逃逸分析后的机器码，会去掉同步锁运行。
>
>

## 闭包，闭包的原理

>所谓闭包，说明白一点就是可以在一个函数中引用另一个函数定义的变量，这个变量称为自由变量。Java8通过lambda表达式支持这一点，但是该变量必须声明为final，究其实现，就能理解这个final的用意了。



## ==Java 异常的体系==



>![img](https://upload-images.jianshu.io/upload_images/4107748-ae1c42e08bbd830d.png?imageMogr2/auto-orient/strip|imageView2/2/format/webp)
>
>分Error 和 检查异常、非检查异常
>
>##### 检查异常
>
>是编译器要求你必须处置的异常。写的某段代码，编译器要求你必须要对这段代码try...catch，或者throws exception 两种办法
>
>1. 继续抛出，消极的方法，一直可以抛到java虚拟机来处理，就是通过throws exception抛出。
>2. 用try...catch捕获
>
>除了RuntimeException与其子类，以及错误（Error），其他的都是检查异常（绝对的大家族）。
>
>------
>
>##### 非检查异常
>
>编译器不要求强制处置的异常，虽然你有可能出现错误，但是我不会在编译的时候检查，没必要，也不可能。
>
>How:对未检查的异常(unchecked exception )怎样处理? 捕获 继续抛出 不处理
>
>一般我们是不处理的，因为你很难判断会出什么问题，而且有些异常你也无法运行时处理，比如空指针，需要人手动的去查找。
>
>Why:为什么有非检查异常？
>你想想非检查异常都有哪些？`NullPointerException，IndexOutOfBoundsException，VirtualMachineError`等，这些异常你编译的时候检查吗？再说了，明明可以运行时检查，都在编译的时候检查，你写的代码还能看吗？而且有些异常只能在运行时才能检查出来，比如空指针，堆溢出等。
>
>Where:非检查异常有哪些？
>RuntimeException与其子类，以及错误（Error）
>
>------
>
>##### Error
>
>Error异常是系统异常(都是非检查异常)，主要包括虚拟机错误（virtualmachineError)栈内存溢出、线程死锁（threaddeth）。一旦出现Error异常就代表着程序崩溃了，可将其看作程序的终结者。
>
>----------
>
>##### Exception异常进行划分 运行时异常和非运行时异常
>
>What:什么是运行时异常?
>
>都是RuntimeException类及其子类异常，如NullPointerException(空指针异常)、IndexOutOfBoundsException(下标越界异常)等，这些异常是非检查异常，程序中可以选择捕获处理，也可以不处理。这些异常一般是由程序逻辑错误引起的，程序应该从逻辑角度尽可能避免这类异常的发生。
>
>运行时异常的特点是Java编译器不会检查它，也就是说，当程序中可能出现这类异常，即使没有用try-catch语句捕获它，也没有用throws子句声明抛出它，也会编译通过。
>
>What:什么是非运行时异常?
>
>是RuntimeException以外的异常，类型上都属于Exception类及其子类。从程序语法角度讲是必须进行处理的异常，如果不处理，程序就不能编译通过。如IOException、SQLException等以及用户自定义的Exception异常，一般情况下不要自定义检查异常。



>- ClassNotFoundException出现在哪些地方?
>
>对于`ClassNotFoundException`理解起来比较简单直接，就是在运行时调用诸如`Class.forName`等方法，将类的全限定名称作为参数，但是在运行时找不到这个名称的类。 例如加载JDBC驱动
>
>-------
>
>- `NoClassDefFoundError 和 ClassNotFoundException `区别？
>
>
>`NoClassDefFoundError不`是一个Exception而是一个致命`Error`。当Java虚拟机试图做如下操作的时候找不到类的定义：
>
>1. 通过new 关键字去实例化一个类
>
>2. 通过方法调用去加载一个类
>
>   进一步来说，这个错误出现在编译器可以成功编译类，但是在运行期无法定位到这个类文件。至于什么原因导致无法定位这个类文件，存在很多情况。一种常见的场景就是执行一段静态代码块或者初始化一个静态变量时抛出异常，导致类无法正常初始化。因为代码是静态的，所以编译是没有问题的，只是在运行时才会抛出异常，导致类无法实例化，最终导致NoClassDefFoundError。
>
>ClassNotFoundException与NoClassDefException核心区别是，**前者强调运行时无法匹配到指定参数名称的类，后者强调编译时没问题，运行时却无法实例化一个类**。
>
>------
>
>##### JVM 是如何处理异常的？
>
>在编译生成的字节码中，每个方法都附带一个异常表，异常表中的每一个条目代表一个异常处理器，并且由 form 指针，to 指针，target 指针以及所捕获的异常类型构成。这些指针的值是字节码索引，用来定位字节码。
>
>当程序处罚异常时，Java 虚拟机会从上至下遍历异常表中的所有条目。当触发异常的字节码索引值在某个异常表条目的监控范围内，Java 虚拟机再判断所抛出的异常和该条目想要捕获的异常是否匹配。如果匹配，Java 虚拟机会将控制流转移至该条目 target 指针指向的字节码。
>
>------
>
>##### throw 和 throws 的区别是什么？
>
>1、throws出现在方法函数头；而throw出现在函数体。
>2、throws表示出现异常的一种可能性，并不一定会发生这些异常；throw则是抛出了异常，执行throw则一定抛出了某种异常。
>3、两者都是消极处理异常的方式（这里的消极并不是说这种方式不好），只是抛出或者可能抛出异常，但是不会由函数去处理异常，真正的处理异常由函数的上层调用处理。



## 序列化

>对象序列化的最主要的用处就是在传递和保存对象的时候，保证对象的完整性和可传递性。序列化是把对象转换成有序字节流，以便在网络上传输或者保存在本地文件中。核心作用是对象状态的保存与重建
>
>### Java序列化与反序列化是什么？
>
>Java序列化是指把Java对象转换为字节序列的过程，而Java反序列化是指把字节序列恢复为Java对象的过程：
>
>- **序列化：**对象序列化的最主要的用处就是在传递和保存对象的时候，保证对象的完整性和可传递性。序列化是把对象转换成有序字节流，以便在网络上传输或者保存在本地文件中。核心作用是对象状态的保存与重建。
>- **反序列化：**客户端从文件中或网络上获得序列化后的对象字节流，根据字节流中所保存的对象状态及描述信息，通过反序列化重建对象。
>
>### 为什么需要序列化与反序列化？
>
>为什么要序列化，那就是说一下序列化的好处喽，序列化有什么什么优点，所以我们要序列化。
>
>**一：对象序列化可以实现分布式对象。**
>
>主要应用例如：RMI(即远程调用Remote Method Invocation)要利用对象序列化运行远程主机上的服务，就像在本地机上运行对象时一样。
>
>**二：java对象序列化不仅保留一个对象的数据，而且递归保存对象引用的每个对象的数据。**
>
>可以将整个对象层次写入字节流中，可以保存在文件中或在网络连接上传递。利用对象序列化可以进行对象的"深复制"，即复制对象本身及引用的对象本身。序列化一个对象可能得到整个对象序列。
>
>**三：序列化可以将内存中的类写入文件或数据库中。**
>
>比如：将某个类序列化后存为文件，下次读取时只需将文件中的数据反序列化就可以将原先的类还原到内存中。也可以将类序列化为流数据进行传输。
>
>总的来说就是将一个已经实例化的类转成文件存储，下次需要实例化的时候只要反序列化即可将类实例化到内存中并保留序列化时类中的所有变量和状态。
>
>**四：对象、文件、数据，有许多不同的格式，很难统一传输和保存。**
>
>序列化以后就都是字节流了，无论原来是什么东西，都能变成一样的东西，就可以进行通用的格式传输或保存，传输结束以后，要再次使用，就进行反序列化还原，这样对象还是对象，文件还是文件。
>
>### 如何实现Java序列化与反序列化
>
>首先我们要把准备要序列化类，实现 Serializabel接口
>
>例如：我们要Person类里的name和age都序列化





## java场景提



>1. （java）在垃圾回收时，无论内存是否充足，都会回收弱引用对象吗，WeakReference在消息机制中的怎么用的
>2.  java进程和go进程应该怎么通信
>3. 假设操作系统内存是4GB,其中有2.5GB被A进程占用了,操作系统本身占用0.5GB内存，这时候如果fork了这个进程，是否能成功,为什么？
>
>​      答:可以,答了copy on write
>
>3. 大数据量操作（在有限时间内完成、在有限空间内完成）
>4. Linux系统，运行Java程序是一个进程还是一个线程  我当时答错了，之后去了解了以下，是一个进程，后面面试官也说这个跟实战相关性比较大，我以为java运行一个main方法有共享内存和共享变量（JVM的堆和方法区），有共享资源，所以应该是线程。但其实不是的，因为进程之间的通信就有共享内存，而两个main方法之间如果是分开的（不在一个项目上），想要进行通信，无疑是只有两种办法，一是通过本地JVM中的对象通过反射机制获取，二通过网络通信，所以是一个进程。第一种方式我没有验证过😂。线程之间的通信就简单很多了。当时没想到这一层，，，
>5. 系统中死循环如何定位？如果是[项目](https://www.nowcoder.com/jump/super-jump/word?word=项目)运行中呢？进程、线程、协程？
>6. 为什么想到用LRU设计商品推荐？
>    LRU有什么缺点？
>    有了解过LFU吗？
>    点赞是如何设计的？

----------------------

接下来就是java容器部分的设计了呢

# ==--------------------------------------------------------------------------------集合==

><img src="https://img.gaomf.cn/Java%20Collections%20Framework2.png" alt="undefined" style="zoom:150%;" />

>| Interface |  Hash Table   | Resizable Array  | Balanced Tree |   Linked List    | Hash Table + Linked List |
>| :-------: | :-----------: | :--------------: | :-----------: | :--------------: | :----------------------: |
>|  **Set**  | **`HashSet`** |        -         | **`TreeSet`** |        -         |     `LinkedHashSet`      |
>| **List**  |       -       | **`ArrayList`**  |       -       | **`LinkedList`** |            -             |
>| **Deque** |       -       | **`ArrayDeque`** |       -       |   `LinkedList`   |            -             |
>|  **Map**  | **`HashMap`** |        -         | **`TreeMap`** |        -         |     `LinkedHashMap`      |
>
>##### HashSet
>
>- `HashSet`底层原理完全就是包装了一下`HashMap`,利用`HashMap`的`key`来存放元素` value`是一个静态`Object`对象
>- `HashSet`的唯一性保证是依赖与`hashCode()`和`equals()`两个方法，所以存入对象的时候一定要自己重写这两个方法来设置去重的规则。
>- 因为底层是`HashMap`，而存储的又是`key`，所以没有`get()`方法来直接获取，只能遍历获取。
>- 支持`null`元素(因为`hashMap`也支持`null`键和`null`值)
>
>-----
>
>##### ArrayDeque
>
>- 实现`Deque`接口是一个双端队列，`LinkedList`也实现该接口 底层是双向链表
>- 底层是数组 并且是2^n 为后续寻找下表做准备 `head = (head - 1) & (elements.length - 1)`  环形数组 以通过掩码运算来避免判断数组越界。
>- 扩容是2倍扩容，ArrayList是1.5倍扩容机制。扩容需要复制数组到新数组上 比较耗性能，不如双线链表
>
>------------
>
>##### ==TreeMap==
>
>- 底层是红黑树，插入、删除元素需要O(nlog) 相比于hash实现的底层要慢一下 类似hashmap
>- **存储的Key都是有序的，因为存放相关元素必须实现`comparator或者comparable`接口**
>- 线程不安全 可以使用`Collections.synchronizedMap()`
>
>----------
>
>##### LinkedHashMap
>
>https://www.jianshu.com/p/8f4f58b4b8ab  讲解非常详细
>
><img src="https://upload-images.jianshu.io/upload_images/4843132-23488d46581b87ea.png?imageMogr2/auto-orient/strip|imageView2/2/format/webp" alt="img" style="zoom:80%;" />
>
>```java
>    //双向链表的排序方法，false 插入顺序排序，true访问顺序排序
>    private final boolean accessOrder; 构造方法中默认是false
>```
>
>
>
>- LinkedHashMap是继承于hashmap  可以实现有序存储Key-Value
>- put操作不但要加入HashMap里边 还要加入双向链表里边
>- 扩容机制 HashMap是遍历旧table，之后重新计算hash值 在放到新table里边。LinkedHashMap是遍历双向链表 计算hash值存放到table里边。遍历双向链表是O(n) 而遍历table是O(n+table空余个数)
>- 支持排序，accessOrder==true是访问排序 在put时候更新Entry进行重排序，这里边排序跟HashMap存储无关，只是指在双向链表中的顺序。
>- 遍历操作：通过迭代器遍历最终会遍历双向链表 
>
>---------
>
>##### LinkedHashSet
>
>- 集成`HashSet`底层还是`LinkedHashMap`并无多大变化  只是存储不重复有序的Key而已



## 线程安全集合类

>-  `Vector`: Vector和ArrayList类似，是长度可变的数组，与ArrayList不同的是，Vector是线程安全的，它给几乎所有的public方法都加上了synchronized关键字。
>- HashTable: 不同点是HashTable是线程安全的，它给几乎所有public方法都加上了synchronized关键字，还有一个不同点是HashTable的K，V都不能是null，但HashMap可以，它现在也因为性能原因被弃用了
>- Collections包装类： 在原集合的基础上添加了锁对象，集合中的每个方法都通过这个锁对象实现同步。 也是synchronized实现
>- `ConcurrentHashMap`： `ConcurrentHashMap`和`HashTable`都是线程安全的集合，它们的不同主要是加锁粒度上的不同。`HashTable`的加锁方法是给每个方法加上`synchronized`关键字，这样锁住的是整个Table对象。而ConcurrentHashMap是更细粒度的加锁
>  在JDK1.8之前，ConcurrentHashMap加的是分段锁，也就是Segment锁，每个Segment含有整个table的一部分，这样不同分段之间的并发操作就互不影响
>   JDK1.8对此做了进一步的改进，它取消了Segment字段，直接在table元素上加锁，实现对每一行进行加锁，进一步减小了并发冲突的概率
>- `CopyOnWriteArrayList  ConcurrentSkipListMap、ConcurrentSkipListSet、ConcurrentLinkedQueue、ConcurrentLinkedDeque等`都是并发包下的一些集合安全类。

## 数组和链表区别

>1. 逻辑结构上： 都是属于线性表  
>2. 内存空间上： 数组占用的是一块连续的内存区，而链表在内存中，是分散的，所需需要保存下一个节点的指针。对于链表而言存储这个节点所消耗的资源就是比较多
>3. 访问： 数组支持随机访问 例如`ArrayList`实现`Access`接口 支持随机访问， 链表只能通过节点遍历来访问。**数组和链表时间复杂度分别是O(1)与O(n)，方式一种是“随机访问”，一种是“顺序访问”。**
>4. 增加和删除方面： 数组比较好性能，因为数组在内存中是连续存储的，要想在某个节点之前增加，且保持增加后数组的线性与完整性，必须要把此节点往后的元素依次后移。  链表只需要找到前驱节点和后继节点就可以实现增加和删除功能。
>5. **内存管理**： 除了访问、插入、删除的不同外，还有在操作系统**内存管理**方面也有不同。正因为数组与链表的物理存储结构不同，在内存预读方面，内存管理会将连续的存储空间提前读入缓存（局部性原理），所以数组往往会被都读入到缓存中，这样进一步提高了访问的效率，而链表由于在内存中分布是分散的，往往不会都读入到缓存中，这样本来访问效率就低，这样效率反而更低了。在实际应用中，因为链表带来的动态扩容的便利性，在做为算法的容器方面，用的更普遍一点。



https://www.xiaoheidiannao.com/221476.html    ArrayList和LinkedList区别

##   ArrayList和LinkedList区别

>**`ArrayList:`** 在接口和序列化操作上
>
>1. `ArrayLis`t实现了` Lis`t 接口，继承了 `AbstractList` 抽象类，底层是基于数组实现的，并且实现了动态扩容。是1.5倍的扩容。
>
>2. `ArrayList` 还实现了` RandomAccess` 接口 标记实现了这个接口的类支持快速随机访问。快速随机访问是什么意思呢？就是说不需要遍历，就可以通过下标直接访问到内存地址。
>
>3. `ArrayList `还实现了` Cloneable `接口，这表明` ArrayList `是支持拷贝  就是拷贝数组返回一个容器。
>
>4. `ArrayList `还实现了 `Serializable` 接口，同样是一个标记接口：将对象转换成以字节序列的形式来表示，这些字节序中包含了对象的字段和方法。序列化后的对象可以被写到数据库、写到文件，也可用于网络传输。
>
>  但是`transient Object[] elementData`防止被序列化存在矛盾。因为`ArrayList`中实现动态扩容，它不想像数组那样初始化长度就不能改变，它想能屈能伸。扩容是在原有的基础上扩容1.5倍，总会存在剩余空间，序列化的时候，如果把整个数组都序列化的话，是不是就多序列化了闲置空间。当存储的元素数量非常非常多的时候，闲置的空间就非常非常大，序列化耗费的时间就会非常非常多。
>
>于是，`ArrayList` 做了一个愉快而又聪明的决定，内部提供两个私有方法 `writeObject` 和 `readObject` 来完成序列化和反序列化。使用了 `ArrayList` 的实际大小` size` 而不是数组的长度（`elementData.length`）来作为元素的上限进行序列化。
>
>-------------
>
>**`LinkedList`：**
>
>1. `LinkedList` 是一个继承自 `AbstractSequentialList` 的双向链表，因此它也可以被当作堆栈、队列或双端队列进行操作。
>
>2. `LinkedList `内部定义了一个` Node` 节点，它包含 3 个部分：元素内容` item`，前引用 `prev` 和后引用 `next`。
>
>3. `LinkedList` 还实现了` Cloneable `接口，这表明 `LinkedList` 是支持拷贝的。
>
>4. `LinkedList `还实现了 `Serializable `接口，这表明` LinkedList` 是支持序列化的   ,但是 `size first last`都用`transient `修饰  又矛盾了
>
>  内部自己来实现序列化 `writeObject-->s.writeObject(x.item)` LinkedList 在序列化的时候只保留了元素的内容 item，并没有保留元素的前后引用。这样就节省了不少内存空间
>
>  在反序列化上 `readObject--->linkLast((E)s.readObject())`   `for` 循环中的 `linkLast()` 方法，它可以把链表重新链接起来，这样就恢复了链表序列化之前的顺序
>
>-------------------
>
>`ArrayList和LinkedList`添加元素谁快？
>
>`ArrayList` 新增元素有两种情况：
>
>1. 种是直接将元素添加到数组末尾，先判断是否需要扩容，然后直接通过索引将元素添加到末尾。
>2. 一种是将元素插入到指定位置，先检查插入的位置是否在合理的范围之内，然后判断是否需要扩容。之后进行元素赋值移动重后遍历，最后通过索引将元素添加到指定的位置，行能比较差 因为在这里就是对数组进行赋值移动。
>
>`LinkedList` 新增元素也有两种情况：
>
>1.  一种是直接将元素添加到队尾 如果 `last`尾节点 为` null`，说明是第一次添加，所以 `first` 为新的节点；否则将新的节点赋给之前 `last` 的` next。`
>2.  插入到指定位置 如果是尾部直接添加，如果插入的位置靠前前半段，就从队头开始往后找；否则从队尾往前找。也就是说，如果插入的位置越靠近 `LinkedList` 的中间位置，遍历所花费的时间就越多。
>
>总结：`ArrayList` 在添加元素的时候如果不涉及到扩容，性能在两种情况下（中间位置新增元素、尾部新增元素）比 `LinkedList `好很多，只有头部新增元素的时候比` LinkedList` 差，因为数组复制的原因。如果涉及到数组扩容的话，`ArrayList` 的性能就没那么可观了，因为扩容的时候也要复制数组
>
>---------------------------
>
>`ArrayList和LinkedList`删除元素谁快？
>
>`ArrayList`:一种是直接删除元素（`remove(Object)`），需要先遍历数组，找到元素对应的索引；一种是按照索引删除元素（`remove(int)`）。最后都会跳转到`fastRemove`方法当中  只要删除的不是最后一个元素，都需要数组重组。删除的元素位置越靠前，代价就越大。
>
>`LinkedList`：有四种删除方式 头尾删除  按照索引位置删除 按照元素进行删除 除了头尾删除速度比较快       按照索引删除可以进行优化，根据尺寸`size`可						  进行前半段删除 或者就是后半段删除  但是按照元素进行删除就是必须要重头开始遍历呢
>
>总结：`LinkedList` 在删除比较靠前和比较靠后的元素时，非常高效，但如果删除的是中间位置的元素，效率就比较低了。而`ArrayList`删除头部元素代价就是非常大。
>
>----------------
>
>`ArrayList和LinkedList`遍历元素谁快？
>
>遍历 `ArrayList` 找到某个元素的话 通常有两种形式：
>
>​        				 `get(int index)`  因为`ArrayList`实现了`RandomAccess`支持随机访问 可以通过下标直接访问到内存 所以时间复杂度使O(1)呢
>
>​						` indexOf(object)` 根据元素找索引 就是需要重头开始遍历数组呗 时间复杂度`O(n)`
>
>遍历 `LinkedList` 通常也是两种方法
>
>						`get(int index)`  找指定位置上的元素  这个就是需要前后段 进行遍历呢  时间复杂度`O(n/2)
>
>​						 `indexOf(obecjt)` 也是需要重头开始遍历 时间复杂度`O(n)`
>
>所以根据上述两个常用方法的话来遍历 `ArrayList`指定就是比`LinkedList`高效
>
>对集合遍历的时候，通常有两种做法，一种是使用` for` 循环，一种是使用迭代器`（Iterator）。`
>
>遍历 LinkedList 的时候，千万不要使用 for 循环，要使用迭代器。也就是说，for 循环遍历的时候，ArrayList 花费的时间远小于 LinkedList；迭代器遍历的时候，两者性能差不多。
>
>for循环和迭代器进行对比 https://blog.csdn.net/Jae_Wang/article/details/80526216

​					 

## ArrayList线程安全吗，说说你知道的线程安全的List    

>1. ArrayList线程安全吗，说说你知道的线程安全的List    
>
>多线程并发访问下，由于没有同步锁的保护，造成了 ArrayList 扩容不一致的问题。
>
>线程安全List:
>
>- `Vector ` 基本上不部分方法都加入`synchronized`  并且在扩容当中 如果在创建对象的时候没有指定扩容长度参数，则默认扩容2倍。    所以即使是线程安全的`Vector`也无法做到线程安全地遍历
>
>- ` SynchronizedList `        `Collections.synchronizedList(list) 返回的是 SynchronizedList `     其中大部分方法就是都添加了同步锁 
>
>- `CopyOnWriteArrayList`  `CopyOnWriteArrayList`使用了一种叫**写时复制**的方法，当有新元素添加到`CopyOnWriteArrayList`时，先从原有的数组中拷贝一份出来，然后在新的数组做写操作，写完之后，再将原来的数组引用指向到新数组。 `CopyOnWriteArrayList`的整个add操作都是在**锁**的保护下进行的。
>
>  由于所有的写操作都是在新数组进行的，这个时候如果有线程并发的写，则通过锁来控制，如果有线程并发的读，则分几种情况：
>  
>  1. 如果写操作未完成，那么直接读取原数组的数据；
>  
>  2. 如果写操作完成，但是引用还未指向新数组，那么也是读取原数组数据；
>  
>  3. 如果写操作完成，并且引用已经指向了新的数组，那么直接从新数组中读取数据。
>
>  可见，`CopyOnWriteArrayList`的读操作是可以不用加锁的。
>
>```java
>   final transient ReentrantLock lock = new ReentrantLock();	
>   private transient volatile Object[] array; 
>   final Object[] getArray() {return array;}
>   final void setArray(Object[] a) {array = a;}
>
>   public boolean add(E e) {
>       final ReentrantLock lock = this.lock;
>       lock.lock();
>       try {
>           Object[] elements = getArray();
>           int len = elements.length;
>           Object[] newElements = Arrays.copyOf(elements, len + 1);
>           newElements[len] = e;
>           setArray(newElements);
>           return true;
>       } finally {
>           lock.unlock();
>       }
>   }
>```
>
>回答顺序  `Vector > SynchronizedList > CopyOnWriteArrayList`



## PriorityQueue实现机制

>PriorityQueue是基于优先堆的一个无界队列，这个优先队列中的元素可以默认自然排序或者通过提供的Comparator（比较器）在队列实例化的时排序
>
><img src="https://img-blog.csdn.net/20171113155941004?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDg1MzI2MQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="img" style="zoom:71%;" />
>
>- 底层是数组来模拟一个完全二叉树 来模拟堆这种数据结构
>
>------
>
>- 添加操作  add和offer
>
>`add(E e)`和`offer(E e)`的语义相同，都是向优先队列中插入元素，只是`Queue`接口规定二者对插入失败时的处理不同，前者在插入失败时抛出异常，后则则会返回`false`。对于PriorityQueue这两个方法其实没什么差别。
>
>```java
>private void siftUpUsingComparator(int k, E x) {
>    while (k > 0) {
>        int parent = (k - 1) >>> 1;
>        Object e = queue[parent];
>        if (comparator.compare(x, (E) e) >= 0)
>            break;
>        queue[k] = e;
>        k = parent;
>    }
>    queue[k] = x;
>}
>```
>
>新加入的元素`x`可能会破坏小顶堆的性质，因此需要进行调整。调整的过程为：从`k`指定的位置开始，将`x`逐层与当前点的`parent`进行比较并交换，直到满足`x >= queue[parent]`为止。注意这里的比较可以是元素的自然顺序，也可以是依靠比较器的顺序。



## ==List中删除特定元素==

>1. `for循环正序遍历list`   删除的同时 list size大小也在变化  `for`循环删除 报并发修改异常
>2. `for` 循环倒叙遍历 删除元素呗
>3. `for`循环正序遍历删除元素 同时再删除的时候 下表-1 。
>4. 迭代器遍历删除元素 `iterator.remove` 



## 快速失败机制和安全失败机制

>##### 快速失败
>
>**现象**：在用迭代器遍历一个集合对象时，如果遍历过程中对集合对象的内容进行了增加、删除、修改操作，则会抛出ConcurrentModificationException。
>
>**原理**：迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量。集合在被遍历期间如果内容发生变化，就会改变modCount的值。每当迭代器使用hashNext()/next()遍历下一个元素之前，都会检测modCount变量是否为expectedmodCount值，是的话就返回遍历；否则抛出ConcurrentModificationException异常，终止遍历。
>
>**注意**：这里异常的抛出条件是检测到 modCount！=expectedmodCount 这个条件。如果集合发生变化时修改modCount值刚好又设置为了expectedmodCount值，则异常不会抛出。因此，不能依赖于这个异常是否抛出而进行并发操作的编程，这个异常只建议用于检测并发修改的bug。
>
>**场景**：java.util包下的集合类都是快速失败的，不能在多线程下发生并发修改（迭代过程中被修改）。
>
>-------
>
>
>##### 安全失败
>
>**现象**：采用失败安全机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。
>
>**原理**：由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发ConcurrentModificationException。
>
>**缺点**：基于拷贝内容的优点是避免了ConcurrentModificationException，但同样地，迭代器并不能访问到修改后的内容，即：迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的。这也就是他的缺点，同时，由于是需要拷贝的，所以比较吃内存。
>
>**场景**：java.util.concurrent包下的容器都是安全失败，可以在多线程下并发使用，并发修改。
>
>例如CopyOnWriteArrayList 在遍历的时候copy一份原始数据进行遍历  

>1. List 有哪些实现类，具体区别有哪些
>2. ArrayList 去重复 该怎么办   使用流表达式 distant这个流表达式
>4. 
>5. 一个list中的重复数据，说想到的方法         //采用流式表达式
>6. 介绍一下 Java 容器，底层[源码](https://www.nowcoder.com/jump/super-jump/word?word=源码)相关及扩容机制等
>7. collection和collections区别
>8. List如何删除元素
>9. PriorityQueue怎么实现的 
>10. java中还有那些线程安全的集合
>11. 什么是死信和延迟队列
> 12. 集合中为什么要用包装类？
>13. 快速失败机制和安全失败机制





## 红黑树

>### 为什么要有红黑树呢
>
>- 我们知道，二叉查找树会因为插入元素的顺序不同，可能会退化成链表，这个时候插入和查询复杂度都会变成O(log2(n))，出现这种情况的原因呢就是二叉查找树没有自平衡机制
>- 于是有了平衡二叉树，平衡二叉树保证了在最差的情况下，二叉树依然能够保持绝对的平衡，即左右两个子树的高度差的绝对值不超过1
>- 但是这又会带来一个问题，那就是平衡二叉树的定义过于严格，导致每次插入或者删除一个元素之后，都要去维护二叉树整体的平衡，这样产生额外的代价又太大了
>- 二叉搜索树可能退化成链表，而平衡二叉树维护平衡的代价开销又太大了，那怎么办呢？这就要谈到“中庸之道”的智慧了
>- 说白了就是把平衡的定义适当放宽，不那么严格，这样二叉树既不会退化成链表，维护平衡的开销也可以接受。没错，这就是我们要谈的红黑树了。
>
>### 红黑树特性
>
>红黑树是一种自平衡的二叉查找树，除了符合二叉查找树的基本特性之外，还具有以下特性：
>
>1. 节点是红色或者黑色的
>2. 根节点是黑色的
>3. 每个叶子节点都是黑色的空节点
>4. 每个红色节点的两个子节点都是黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点)
>5. 从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点
>
>### 红黑树的例子
>
>
>
>![image](https://user-gold-cdn.xitu.io/2020/3/30/1712904296372b37?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)
>
>
>
>### 索引的存储结构为什么不用红黑树呢？
>
>注意一点，红黑树是一种二叉树，这意味着，相同数量的节点，红黑树要比B/B+树更高，查询时的IO次数也就多，所以一般涉及到磁盘上查询的数据结构，用B+树

##  HashMap

https://tech.meituan.com/2016/06/24/java-hashmap.html   	美团技术博客

https://segmentfault.com/a/1190000024485062   					  resize扩容机制 

https://www.codenong.com/j5e9eeee0e51d4546fb2795f7/  	 HashMap不错的操作呗 主要就是后边的红黑树操作

>1. `hash`概念					
>2. 好的`hash`算法虑了哪些点     `Integer中的hashCode` 
>3. `hash`冲突的定义和解决方法
>4. `JDK 1.8 HashMap组成`
>5. `hashmap`为什么用数组      `LinkedHashMap`采用的是链表么？    `LRU`算法是什么设计的呢？
>6. `HashMap`为什么要用数组加链表的方式
>7. 除了拉链法，有几种解决冲突的方法
>8. 散列表初始长度
>9. `hashcode`计算方式
>10. 扩容阈值，扩容机制，扩容优化，抖动函数    
>11. rehash过程
>12. 集合大小为什么是2的幂，为什么阈值是8
>13. 扩容之后老数据怎么迁移
>14. `put`流程
>15. `get`流程
>16. `HashMap`中存储的数据是有序的么
>17. `hashmap` 线程安全还是不安全
>18. 让`hashmap`线程安全有几种方式
>19. `jdk1.8`为什么要引入红黑树 
>20. 链表加红黑树的组合方式之后解决了什么问题
>21. 链化之后为社么性能变低了
>22. 红黑树原则
>23. `hashmap 1.8` 改为红黑树底层存储 时间复杂度
>24. 链表转化成红黑树的阈值怎么算出来的?
>25. 红黑树缩回链表的阈值和进化的阈值不一样?
>26. 转红黑树时机，为什么是8 __,__7不退成链表
>27. 红黑树 写入操作
>28. 红黑树的平衡怎么做?
>29. 红黑树 左旋 右旋 
>30. 红黑树的扩容
>31. `AVL`树旋转调整原理，只需要分情况画图说明
>32. 红黑树，平衡树和各自的使用场景
>33. 二叉搜索树说一下？
>34. HashMap场景提
>35. ![preview](https://pic1.zhimg.com/v2-acb81d194c6f522f26e4e798e776bda4_r.jpg)

### 1.`hash`概念 优点 冲突

>1. hash概念  ： 任意长度的输入转化为固定长度的输出
>2. hash冲突： 理论上不可以避免 只能尽量避免
>3. 好的hash算法考虑的点： 1.效率高长文本也能计算出hash值   2.hash值不能逆推出原文 3.两次输入只要有一点不同 也要保证hash值不同
>
>----------
>
>1. 正向快速：给定明文和 `hash` 算法，在有限时间和有限资源内能计算出` hash` 值。		效率高
>2. 逆向困难：给定（若干） `hash `值，在有限时间内很难（基本不可能）逆推出明文。   通过`hash`值不能逆推出原文
>3. 输入敏感：原始输入信息修改一点信息，产生的 `hash `值看起来应该都有很大不同。
>4. 冲突避免：很难找到两段内容不同的明文，使得它们的 `hash` 值一致（发生冲突）。即对于任意两个不同的数据块，其`hash`值相同的可能性极小；对于      一个给定的数据块，找到和它hash值相同的数据块极为困难。
>
>-------
>
>**哈希冲突**：由于哈希算法被计算的数据是无限的，而计算后的结果范围有限，因此总会存在不同的数据经过计算后得到的值相同，这就是哈希冲突。
>
>​			       当两个不同的输入值，根据同一散列函数计算出相同的散列值的现象，我们就把它叫做碰撞（哈希碰撞）
>
>解决办法：拉链法  再哈希
>
>`HashMap`：1. 数组+链表：拥有相同哈希值的对象组织成一个链表放在`hash`值所对应的`bucke`t数组下标下，
>
>​			        2. 采用扰动函数 即 `hash`函数 `JDK1.8 hash`值高`16bit和低16bit`异或来简单处理减少碰撞
>
>​                    3.  红黑树转换 当链表长度大于阈值（默认为8）时且数组长度大于64 链表转红黑树 ？ 这个减少碰撞了么？



### ==解决hash冲突的方法==

>1.**开放地址方法**
>
>　　（1）线性探测 **`ThreadLocalMap中解决hash冲突的就是使用这个方法`**
>
>　　　按顺序决定值时，如果某数据的值已经存在，则在原来值的基础上往后加一个单位，直至不发生哈希冲突。　
>
>　　（2）再平方探测
>
>　　　按顺序决定值时，如果某数据的值已经存在，则在原来值的基础上先加1的平方个单位，若仍然存在则减1的平方个单位。随之是2的平方，3的平方等等。直至不发生哈希冲突。
>
>　　（3）伪随机探测
>
>　　　按顺序决定值时，如果某数据已经存在，通过随机函数随机生成一个数，在原来值的基础上加上随机数，直至不发生哈希冲突。
>
>**2.链式地址法（HashMap的哈希冲突解决方法）**
>
>　　对于相同的值，使用链表进行连接。使用数组存储每一个链表。
>
>　　优点：
>
>　　（1）拉链法处理冲突简单，且无堆积现象，即非同义词决不会发生冲突，因此平均查找长度较短；
>
>　　（2）由于拉链法中各链表上的结点空间是动态申请的，故它更适合于造表前无法确定表长的情况；
>
>　　（3）开放定址法为减少冲突，要求装填因子α较小，故当结点规模较大时会浪费很多空间。而拉链法中可取α≥1，且结点较大时，拉链法中增加的指针域可忽略不计，因此节省空间；
>
>　　（4）在用拉链法构造的散列表中，删除结点的操作易于实现。只要简单地删去链表上相应的结点即可。
>　　缺点：
>
>　　指针占用较大空间时，会造成空间浪费，若空间用于增大散列表规模进而提高开放地址法的效率。
>
>**3.建立公共溢出区**
>
>　　建立公共溢出区存储所有哈希冲突的数据。
>
>**4.再哈希法**
>
>　　对于冲突的哈希值再次进行哈希处理，直至没有哈希冲突。 redis中 就是再用rehash





### 2.`JDK 1.8 HashMap组成`

>数组+链表+红黑树 每个数据单元是一个Node结构 Node结构有`key value next hash`字段
>
>1. hashmap是我们几乎每天用到的集合类,它以键值对的形式存在。
>2. 在jdk1.7中：底层是数组加链表，1.8中采用的是数组加链表加红黑树，红黑树的引入是为了提高查询效率
>3. 1.7中hash碰撞采用头插法，头插法会形成循环链表 ，1.8尾插法
>4. hash算法1.8进行了简化 , 高低16位进行异或
>5. 最好传入一个二的次幂的初始化容量， put时，会初始化数组，容量为大于等于初始化容量的最近的二次幂，比如初始化容量为6，他初始化就是8。
>6. 树化，数组容量达到64,链表长度大于等于8，后才会进行树化，链表长度小于6就会解除树化



### 3.==`hashmap `解决冲突为什么选择红黑树==

>- 为什么不选择二叉平衡树 类似于AVL树 而要选择红黑树
>
>AVL树和红黑树都是平衡二叉树，支持删除、查找、插入时间复杂度都是O(logn) 其中N是叶子的数量。
>
>插入和删除对比：
>
>1. 插入和删除：AVL树速度较慢,需要更高的旋转次数才能平衡数据结构,RB树具有恒定的最大旋转次数，但AVL树可以将O(logn)次旋转视为最差。并且平均而言，RB树也具有较少的旋转次数，因此RB树更快。因此，在AVL树中查找通常更快，但这是以更多旋转操作导致更慢的插入和删除为代价的。
>2. 插入：AVL树更快，因为AVL树的深度较小。更多旋转操作导致更慢的插入和删除为代价的。
>
>数据结构差异：在AVL树中，从根到任何叶子的最短路径和最长路径之间的差异最多为1。在红黑树中，差异可以是2倍
>
>这两个都给O（log n）查找，但平衡AVL树可能需要O（log n）旋转，而红黑树将需要最多两次旋转使其达到平衡（尽管可能需要检查O（log n）节点以确定旋转的位置）。旋转本身是O(1)操作，因为你只是移动指针。

>--------------
>
>- **为什么在解决hash冲突的时候，不直接用红黑树?而选择先用链表，再转红黑树?   **
>
>因为红黑树需要进行左旋，右旋，变色这些操作来保持平衡，而单链表不需要。当元素小于 8 个的时候，此时做查询操作，链表结构已经能保证查询性能。当元素大于 8 个的时候， 红黑树搜索时间复杂度是 O(logn)，而链表是 O(n)，此时需要红黑树来加快查询速度，但是新增节点的效率变慢了。因此，如果一开始就用红黑树结构，元素太少，新增效率又比较慢，无疑这是浪费性能的。 最后就可以确定后红黑树的插入和删除节点的时间复杂度为`log(n))`
>
>我想这是内存占用与存储桶内查找复杂性之间的权衡。请记住，大多数哈希函数将产生非常少的冲突，因此为大小为3或4的桶维护树将是非常昂贵的，没有充分的理由。
>
>--------------
>
>- 我不用红黑树，用二叉查找树可以么?
>
>可以。但是二叉查找树在特殊情况下会变成一条线性结构（这就跟原来使用链表结构一样了，造成很深的问题），遍历查找会非常慢。
>
>----------------
>
>- 那为什么表树华成红黑树阀值是8呢?
>
>理想情况下使用随机的哈希码，容器中节点分布在 hash 桶中的频率遵循**[泊松分布](https://link.zhihu.com/?target=http%3A//en.wikipedia.org/wiki/Poisson_distribution)**，按照泊松分布的计算公式计算出了桶中元素个数和概率的对照表，可以看到链表中元素个数为 8 时的概率已经非常小
>
>- 当链表转为红黑树后，什么时候退化为链表?
>
>当Node节点个数少于6个时退化成链表
>
>-------------



### 4.负载因子、阈值

>默认负载因子是多少？为什么是 0.75，不是 0.6 或者 0.8 ？
>
>- 如果内存空间很多而又对时间效率要求很高，可以降低负载因子Load factor的值 。
>- 相反，如果内存空间紧张而对时间效率要求不高，可以增加负载因子loadFactor的值，这个值可以大于1。
>
>-------------------
>
>默认的负载因子0.75是对空间和时间效率的一个平衡选择，除非在时间和空间比较特殊的情况下，如果内存空间很多而又对时间效率要求很高，可以降低负载因子Load factor的值；相反，如果内存空间紧张而对时间效率要求不高，可以增加负载因子loadFactor的值，这个值可以大于1。



### 5.`hashcode` 扰动函数 计算方式

>```java
>  static final int hash(Object key) {
>        int h;
>        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);  
>  }
>
>  bucketIndex = indexFor(hash, table.length);  return hash&table.length-1;
>```
>
>- 扰动函数 调用自己的`Object`中的`hashCode`方法  并采用原高16位与`hashcode`做异或运算被
>- 为什么数组长度一定是2^n，因为数组长度-1正好相当于一个低位掩码 ，以16为例，与操作的结果就是高位为0，保留低位用于访问数组下标。但是只保留最后几位，即便散列值做的再好，碰撞也会很严重。这时候扰动函数的价值就是体现出来被。
>- 右移动16位，正好是32位的一半，**自己的高半区和自己的低半区做异或操作就是为了混合原始哈希码的高位和低位，依次来增加低位的随机性**。而且混合后的低位增加了高位的部分特征，这样高位的信息也就被变相保留了下来被

>![preview](https://pic4.zhimg.com/4acf898694b8fb53498542dc0c5f765a_r.jpg?source=1940ef5c)
>
>- 优化了高位运算的hash算法：h^(h>>>16)
>
>因为在JDK 1.7 中扰动了 4 次，计算 hash 值的性能会稍差一点点。 从速度、功效、质量来考虑，JDK1.8 优化了高位运算的算法，通过hashCode()的高16位异或低16位实现：(h = k.hashCode()) ^ (h >>> 16)。这么做可以在数组 table 的 length 比较小的时候，也能保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销。

### **6**.集合大小为什么是2^n的幂

>首先先看一下`HashMap`中的`putVal`方法(存值的)和`resize`方法(扩容的)，之所以`HashMap`扩容是`2的n`次幂和这两个方法有千丝万缕的联系。
>
>```java
>(slot = tab[i = (len - 1) & hash])    //put方法
>newTab[e.hash & (newCap - 1)] = e;	  //resize方法 
>```
>
>​      但是为什么时`2^n` 呢 因为经过扰动函数计算过`hash`值已经存有高位和低位的特性， 而数组长度-1变成二进制就是除了首位 剩下的都是1 ， 这样的话`hash&len-1` 计算之后可以使得添加的元素均匀分布在`HashMap`中的数组上，减少`hash`碰撞。 假如不是`2^n`  就是在二进制上不是`111111`存在的话，某些位就是`0`进行`&`运算都是0 ，这样就是增大`hash`冲突呗。
>
>经过rehash之后，元素的位置要么是在原位置，要么是在原位置再移动2次幂的
>
>---------
>
>在创建和扩容的时候都是2^n存在。并且计算对应的数组下标是通过`&`运算来获取的.   `table[i]=(n-1)&hash`  而`n-1`在二进制当中除了首位是0 剩下的位都是1  这样在经过与hash之运算就都保留了`hash`值低位的特性。减少`hash`冲突。





### 7.扩容机制，扩容优化

>扩容阈值 `threshold == capacity * load factor`
>
>扩容机制： `resize()`
>
>1. 第一次`put`操作也会触发扩容机制，懒加载；
>
>   -----指定初始化容量了：		`cap==threshold=2^n     threshold == capacity * load factor`
>
>   -----没有指定初始化容量：    `cap=16   threshold =12 =capacity * load factor`
>
>2. 当`put`操作时,`Node`节点个数`size>threshold==capacity * load factor`   `size`表示`K V`键值对 
>
>3. 当`put`操作 链表节点个数大于`8`个 判断是否可以树化的时候 并且 数组长度`len<64`个  这时候进行扩容
>
>------------------
>
>扩容优化
>
>1. `HashMap`不是第一次扩容。如果`HashMap`已经扩容过的话，那么每次`table`的容量以及`threshold`量为原有的两倍。

### **8**.扩容之后老数据怎么迁移 resize函数

>1. 第一次put的时候先进性扩容 懒加载形式 没给容量就是`16` 给容量了就是接近`2^n`   阈值：`DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY`
>
>   如果创建`map`的时候给初始化容量了 数组长度是接近于`2^n `在第一次`resize`中
>
>--------------------
>
>   `tab`数组长度`>0`  表示已经扩容过了 扩容后新数组长度和阈值变为`2`倍 
>
>2. 当`oldTab`只有一个节点 重新 `e.hash & (newCap - 1)` 计算数组下标插入即可  
>3. 如果是树化了，已经就是红黑树 我们直接将节点插入到红黑树当中就好
>4. 已经就是链化了 创建一个低位链表和一个高位链表 对当前数组下种的老链表进行分割 分割原则是 `e.hash & oldCap == 0 `进行随机分割并添加到两个新链表当中，最后低位链表在数组原始位置  高位链表在低位链表+原始数组长度的位置 （`oldTabLength`）

### 9.扩容对比 并发map redis中hash

>**redis扩容条件**：
>
>1. 子进程没有执行aof文件重写或者生成RDB文件（BGSAVE或BGREWRITEAOF命令）持久化命令，并且哈希表负载因子大于等于1，哈希表中保存的key数量超过了哈希表的大小，则会进行扩容。
>2. 当前紫禁城执行执行aof文件重写或者生成RDB文件（持久化命令），为了提高子进程使用效率，服务器会提高执行扩容操作所需的负载因子默认是5，就会进行强制扩容，从而尽可能避免在子进程存在期间进行哈希表扩展操作，这可以避免不必要的内存写入，最大限度的节约空间。
>
>缩容条件：
>
>1. **元素个数低于数组长度的 10%**，缩容不会考虑 Redis 是否在做 持久化操作。　
>
>---------
>
>**扩容机制**：单线程渐进式rehash里的单线程是指只有一个线程在扩容，而在扩容的同时其他的线程可以并发的进行读写。
>
>如果一次性将表0迁移到表1这种操作O(n) 级别的，作为单线程的 Redis 很难承受这样耗时的过程，所以 Redis 使用 **渐进式 rehash** 小步搬迁：是分多次、渐进式的完成的。目的：如果服务器中包含很多键值对，要一次性的将这些键值对全部rehash到ht[1]的话，庞大的计算量可能导致服务器在一段时间内停止服务于。
>
>　　1、为ht[1]分配空间，让字典同时持有ht[0]和ht[1]两个哈希表。表1的大小要取决去表0：h[1]大小==ht[0].used*2的2^n；
>
>　　2、在字典中维持一个索引计数器变量rehashidx，并将它置为0，表示rehash工作开始。
>
>　　3、在rehash进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定操作以外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]中，当rehash工作完成之后，程序将rehashidx属性的值+1。
>
>　　4、随着字典操作的不断进行，最终在某个时间点上，ht[0]的所有键值对都被rehash到ht[1]上，这时将rehashidx属性设为-1，表示rehash完成。
>
>　　**渐进式rehash** 的好处在于其采取分而治之的方式，将rehash键值对所需要的计算工作均摊到字典的每个添加、删除、查找和更新操作上，从而避免了集中式rehash而带来的庞大计算量。
>
>因为在渐进式rehash的过程中，字典会同时使用ht[0]和ht[1]两个哈希表，所以在渐进式rehash进行期间，字典的删除、查找、更新等操作都是在两个表上进行的。
>
>  　　1. 查找操作会先在ht[0]上进行，如果没找到再在ht[1]上进行。
>  　　2. 添加操作的键值对会一律保存到ht[1]中，这一措施保证ht[0]包含的键值对只会减少不会增加。
>
>---------
>
>**HashMap扩容机制：**
>
>扩容阈值 `threshold == capacity * load factor`
>
>扩容机制： `resize()`
>
>1. 第一次`put`操作也会触发扩容机制，懒加载；
>
>  -----指定初始化容量了：		`cap==threshold=2^n     threshold == capacity * load factor`
>
>  -----没有指定初始化容量：    `cap=16   threshold =12 =capacity * load factor`
>
>2. 当`put`操作时,`Node`节点个数`size>threshold`   `size`表示`K V`键值对 
>
>3. 当`put`操作 链表节点个数大于`8`个 判断是否可以树化的时候 并且 数组长度`len<64`个  这时候进行扩容
>
>扩容优化
>
>1. `HashMap`不是第一次扩容。如果`HashMap`已经扩容过的话，那么每次`table`的容量以及`threshold`量为原有的两倍。
>
>-----
>
>**ConcurrentHashMap扩容机制：**
>
>而ConcurrentHashMap采用的扩容策略为： “**多线程协同式rehash**“。这里的多线程指的是，有多个线程并发的把数据从旧的容器搬运到新的容器中。
>
>扩容时大致过程如下：ConcurrentHashMap 扩容是从数组队尾开始拷贝，拷贝槽点时会锁住槽点，拷贝完成后将槽点设置为转移节点。所以槽点拷贝完成后将新数组赋值给容器
>
>线程A在扩容把数据从oldTable搬到到newTable，这时其他线程
>
>1. 进行get操作：这个线程知道数据存放在oldTable或是newTable中，直接取即可。
>
>2. 进行写操作：如果要写的桶位，已经被线程A搬运到了newTable。那么这个线程知道正在扩容**，它也一起帮着扩容，扩容完成后才进行put操作**。
>
>3. 进行删除操作：与写一致。
>
>



### 10.`put get`流程

>`put`时候  1. `key`可以为`null` 放在数组下标0当中   2.`value`也可以为`Null`   3. `key`和`value`也可以同时为`null`
>
>**put流程**： 首先根据 `key` 的值计算 `hash` 值，找到该元素在数组中存储的下标； 这时候就是分四种情况    `key==null 放在第0个下标`
>
>1. 第一次`put` 数组还没有初始化，懒加载形式，则调用` resize `进行初始化，在计算数组的下标之后存放节点
>
>2.  `slot!=null` `get和put`操作总会检查对应数组下标中的第一个节点  并且判断`key`与`hash`值一样  就把里边的节点替换掉   ` always check first node`
>
>3. `slot!=null ` 冲突后且已经退化成红黑树  红黑树直接插键值对
>
>4. `slot!=null `已经处于链化状态：
>
>  ​												 1）：首先迭代查找`node` 判断链表上的`key`是否与当前传进来的`key`是否一样 ` key`一致就替换掉原来的`value`
>
>  ​											     2）：如果不一样，遍历到链表尾部，尾插法进行添加。 添加完之后并判断是否达到树华的标准  `size>8`
>
>-----------------------
>
>![img](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/d669d29c.png)
>
>---------------------
>
>get操作
>
>1. 如果数组table==null 直接返回null  或者查找通过 `hash&len-1`查找数组对应下标没有节点 直接返回null
>2. 总是检查数组中第一个元素 判断key是否一样  一样直接返回Node节点
>3. `e = first.next`检查下一个节点 判断是否树化  如果树化了去红黑树当中查找
>4. 处于链化状态，遍历链表去查找





### 11.你一般用什么作为HashMap的key?

>- 健可以为Null值么?                           
>
>  ​    key为null的时候，hash算法最后的值以0来计算，也就是放在数组的第一个位置。
>
>------------
>
>
>
>- 你一般用什么作为`HashMap`的`key`?    
>
>  一般用`Integer、String`这种不可变类当`HashMap`当`key`，而且`String`最为常用,
>
>  1..因为字符串是不可变的，所以在它创建的时候hashcode就被缓存了，不需要重新计算。这就使得字符串很适合作为Map中的键，字符串的处理速度要快过其它的键对象。这就是HashMap中的键往往都使用字符串。
>
>  2..因为获取对象的时候要用到equals()和hashCode()方法，那么键对象正确的重写这两个方法是非常重要的,这些类已经很规范的覆写了hashCode()以及equals()方法。
>
>----------
>
>
>
>- 我用可变类当HashMap的key有什么问题?
>
>  `hashcode`可能发生改变，导致`put`进去的值，无法`get`t出    重点在实现
>
>  
>
>------------
>
>
>
>- 如果让你实现一个自定义的class作为HashMap的key该如何实现？
>
>  1. 重写hashcode和equals方法注意什么?  ：  两个对象相等，hashcode一定相等 (2)两个对象不等，hashcode不一定不等 (3)hashcode相等，两个对象不一定相等 (4)hashcode不等，两个对象一定不等
>
>  2. 如何设计一个不变类  
>
>     (1)类添加final修饰符，保证类不被继承。 如果类可以被继承会破坏类的不可变性机制，只要继承类覆盖父类的方法并且继承类可以改变成员变量值，那么一旦子类以父类的形式出现时，不能保证当前类是否可变。
>
>     (2)保证所有成员变量必须私有，并且加上final修饰 通过这种方式保证成员变量不可改变。但只做到这一步还不够，因为如果是对象成员变量有可能再外部改变其值。所以第4点弥补这个不足。
>
>     (3)不提供改变成员变量的方法，包括setter 避免通过其他接口改变成员变量的值，破坏不可变特性。
>
>     (4)通过构造器初始化所有成员，进行深拷贝(deep copy) 如果构造器传入的对象直接赋值给成员变量，还是可以通过对传入对象的修改进而导致改变内部变量的值。
>
>     (5)在getter方法中，不要直接返回对象本身，而是克隆对象，并返回对象的拷贝 这种做法也是防止对象外泄，防止通过getter获得内部可变成员对象后对成员变量直接操作，导致成员变量发生改变。
>
>



### 12`HashMap`中存储的数据是有序的么

>`Map`是无序的，它的存储结构是哈希表键值对，`map`中插入元素是根据`key`计算出的哈希值来存储元素的，因此他不是按照元素的添加顺序来存储对象的，所以Map是无序的。它的实现类有：`HashMap、TableMap和TreeMap。`
>
>其中`LinkedHashMap`是有序的，`hashMap`用来保证存储的值键值对，`list`用来保证插入的顺序和存储的顺序一致。
>
>`Set`是无序的，并且`set`中的元素不能重复。`set`的底层实现其实是`Map`，它是计算`key`的哈希值来确定元素在数组中的存放位置，所以是无序的，应为在`Map`中`key`的值不能重复，所以`set`中的元素不能重复。它的实现类有：`haseSet、TreeSet`。
>
>其中`LinkedHashSe`t是有序的，其中`haseSet`用来保证数据唯一，`List`用来保证插入的顺序和存储的顺序一致。





### 13.`hashmap` 线程安全还是不安全

>- HashMap在并发编程环境下有什么问题啊?      (1)多线程扩容，引起的死循环问题(2)多线程put的时候可能导致元素丢失(3)put非null元素后get出来的却是null
>- 在jdk1.8中还有这些问题么?   在jdk1.8中，死循环问题已经解决。其他两个问题还是存在。
>- 你一般怎么解决这些问题的？ 比如ConcurrentHashmap，Hashtable等线程安全等集合类。



### 14.让`hashmap`线程安全有几种方式

>1. 替换成`Hashtable`，`Hashtable`通过对整个表上锁实现线程安全，因此效率比较低 因为`HashTable`加上了`synchronized`关键字了
>2. 使用`Collections`类的`synchronizedMap`方法包装一下。方法如下：`public static <K,V> Map<K,V> synchronizedMap(Map<K,V> m) ` 返回由指定映射支持的同步（线程安全的）
>3. 映射使用ConcurrentHashMap，它使用分段锁来保证线程安全



### 15.HashMap迭代方式的选择

>1. `forEach`循环遍历节点` for (Map.Entry<Integer, Integer> entry : map.entrySet())`
>2. `forEach`循环遍历`key` 或者` value  1.for (Integer key : map.keySet())  2.for (Integer value : map.values()) `
>3. 使用迭代器遍历 `Iterator<Map.Entry<Integer, Integer>> entries = map.entrySet().iterator()`
>4. `Java8 Lambda`: `map.forEach((k, v) -> System.out.println("key: " + k + " value:" + v));`



### 16.链表转化成红黑树的阈值怎么算出来的?

>**当链表长度大于或等于阈值（默认为 8）的时候，如果同时还满足容量大于或等于 MIN_TREEIFY_CAPACITY（默认为 64）的要求，就会把链表转换为红黑树。**
>
>**同样，后续如果由于删除或者其他原因调整了大小，当红黑树的节点小于或等于 6 个以后，又会恢复为链表形态。**
>
>通常如果 hash 算法正常的话，那么链表的长度也不会很长，那么红黑树也不会带来明显的查询时间上的优势，反而会增加空间负担。所以**通常情况下，并没有必要转为红黑树**，所以就选择了概率非常小，**小于千万分之一概率，也就是长度为 8 的概率，把长度 8 作为转化的默认阈值**。





>### 27.红黑树 写入操作
>
>>10. 先重TreeNode结构继承Node  找父节点跟二叉排序树就是很像 二分查找算法映射出来的数据结构 
>>
>>  ​															插入父节点的左子树或者右子树插入节点hash值跟父节点hash值做比较 插入打破平衡需要红黑树的平衡算法
>>
>>  ​															根节点向下的探测中 TreeNode key与当前key完全一致 替换操作
>>
>>
>
>### 28.红黑树的平衡怎么做?
>
>
>
>### 29.红黑树 左旋 右旋 
>
>### 30.红黑树的扩容
>
>
>
>### 32.红黑树，平衡树和各自的使用场景
>
>### 33.二叉搜索树说一下？

### 17.HashMap场景提

>1. HashMap put 里面已经有100000 个数据了,往里面 put 第 100001 个数据会不会扩容?
>
>
>1. 如果黑客往HashMap中注入大量key值不同但是HashCode是相同的键值对会怎么样
>2. 读很多写很少的情况怎么写一个加锁的hashmap



### **1000个元素插入HashMap 容量初始化为多大合适 **

>`size>cap*loadfactor` 所以cap=2048



### ==线程不安全体现在哪里==

>1. 在JDK1.7中，put操作会发生数据覆盖。get操作可能因为resize扩容而引起死循环。因为1.7版本采用链表头插法。1.8版本采用尾插法。
>
>2. 在JDK1.8中，在并发执行put操作时会发生数据覆盖的情况。
>
>假设A 、 B两个线程正在执行put操作，插入点的位置在这里也是一样的。当线程A获得CPU时间正在插入的时候CPU时间片耗尽导致挂起。线程B获得CPU时间片完成了正常插入。然后线程A获得CPU时间片，线程A再次被调度运行时，它依然持有过期的链表头但是它线程B的操作一无所知，如此依赖就覆盖了线程B的元素。这样线程B的插入就凭空消失了，会导致数据不一致问题。









# ==--------------------------------------------------------------------------JUC集合==

https://segmentfault.com/a/1190000015558984

>1. 怎么实现阻塞队列 
>2. Juc[源码]()看过吗？锁的实现原理是什么？ 
>3. copyonwriteArrayList的加锁时机
>4. cowArraylist用来解决什么问题
>5. copyonwriteArrayList写的时候读会读到空数据吗
>6. ArrayBlockingQueue与LinkedBlockingQueue区别



## ==ConncureentHashMap==

>1. 节点中的内部 val next 都是用 volatile来修饰  

>存储对象时，将key和vaule传给put()方法：
>
>- 如果没有初始化，就调用initTable()方法对数组进行初始化；
>- 如果没有hash冲突则直接通过CAS进行无锁插入；
>- 如果需要扩容，就先进行扩容，扩容为原来的两倍；
>- 如果存在hash冲突，就通过加锁的方式进行插入，从而保证线程安全。（如果是链表就按照尾插法插入，如果是红黑树就按照红黑树的数据结构进行插入）；
>- 如果达到链表转红黑树条件，就将链表转为红黑树；
>- 如果插入成功就调用addCount()方法进行计数并且检查是否需要扩容；
>
>注意：在并发情况下ConcurrentHashMap会调用多个工作线程一起帮助扩容，这样效率会更高。
>
>获取对象时，将key传给get()方法：
>
>- 计算hash值，定位table索引位置，如果头节点符合条件则直接返回key对应的value；
>- 如果遇到正在扩容，则调用标记正在扩容的节点，查找该节点，匹配就返回；
>- 以上条件都不符合，就继续向下遍历；
>
>注意：其实get()的流程跟HashMap基本是一样的。put()的流程只是比HashMap多了一些保证线程安全的操作而已



### 1.跟HashMap、HashTable区别

>在JDK1.7中ConcurrentHashMap底层采用分段数组+链表的方式实现。在JDK1.8中ConcurrentHashMap与JDK1.8中的HashMap底层数据结构一样，都是采用数组+链表或者数组+红黑树的方式实现。这二者底层数据结构都是以数组为主体的。
>
>线程安全：HashMap是线程不安全的，ConcurrentHashMap是线程安全的。
>
>------
>
>ConcurrentHashMap 和HashMap的扩容有什么不同？ ConcurrentHashMap 多了转移节点，主要用户保证扩容时的线程安全
>HashMap的扩容是创建一个新数组，将值直接放入新数组中，JDK7采用头链接法，会出现死循环，JDK8采用尾链接法，不会造成死循环
>ConcurrentHashMap 扩容是从数组队尾开始拷贝，拷贝槽点时会锁住当前槽点，拷贝完成后将槽点设置为转移节点。所以槽点拷贝完成后将新数组赋值给容器
>
>-----
>
>ConcurrentHashMap 是如何发现当前槽点正在扩容的？
>ConcurrentHashMap 新增了一个节点类型，叫做转移节点，当我们发现当前槽点是转移节点时（转移节点的 hash 值是 -1），即表示 Map 正在进行扩容.
>
>-------
>
>ConcurrentHashMap 和 Hashtable 的区别主要体现在实现线程安全的方式上不同。
>底层数据结构：
>JDK1.7的 ConcurrentHashMap 底层采用 分段的数组+链表 实现，JDK1.8 采用的数据结构跟HashMap1.8的结构一样，数组+链表/红黑二叉树。Hashtable是采用 数组+链表 的形式。
>实现线程安全的方式（重要）： ① 在JDK1.7的时候，ConcurrentHashMap（分段锁） 对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。 到了 JDK1.8 的时候已经摒弃了Segment的概念，而是直接用 Node 数组+链表+红黑树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作。② Hashtable(同一把锁) :使用 synchronized 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。
>
>

### 2.==ConcurentHashMap如何保证线程安全==

>JDK1.7采用分段锁机制 ：每个分段都有一个Segment分段锁（继承ReentrantLock分段锁），每个Segment分段锁只会锁住它锁守护的那一段数据，多线程访问不同数据段的数据，就不会存在竞争，从而提高了并发的访问率。
>
>---------
>
>JDK1.8  **ConcurrentHashMap 主要使用的是 CAS+自旋+synchronized+多重check 来保证在初始化，新增，和扩容的时候线程安全，读取数据的时候则使用了 volatitle 让元素节点 在多线程之间 可见，从而达到获取最新的值！**
>
>节点类型跟HashMap有区别
>
><img src="https://segmentfault.com/img/bVbhW1C?w=855&h=486/view" alt="preview" style="zoom:80%;" />
>
>- Node节点：默认链接到`table[i]`——桶上的结点就是Node结点。当出现hash冲突时，Node结点会首先以**链表**的形式链接到table上，当结点数量超过一定数目时，链表会转化为红黑树。因为链表查找的平均时间复杂度为`O(n)`，而红黑树是一种平衡二叉树，其平均时间复杂为`O(logn)`。
>- TreeNode结点：reeNode就是红黑树的结点，TreeNode不会直接链接到`table[i]`——桶上面，而是由TreeBin链接，TreeBin会指向红黑树的根结点。
>- TreeBin结点：TreeBin相当于TreeNode的代理结点。TreeBin会直接链接到`table[i]`——桶上面，该结点提供了一系列红黑树相关的操作，以及加锁、解锁操作。
>- ForwardingNode结点：forwardingNode结点仅仅在扩容时才会使用——关于扩容
>- ReservationNode结点:保留结点，ConcurrentHashMap中的一些特殊方法会专门用到该类结点。
>
>-------------------

### put操作 cas synchronized 双重检查机制

>自旋插入节点 直到成功：
>
>- **Case1:首次初始化table —— 懒加载**
>
>`While `判断`tab`是否完成初始化，也就是这个一个自旋处理，保证一定能初始化成功。
>
>**`synchronized`关键字来同步多个线程对该链表的访问**
>
>```java
>   private final Node<K,V>[] initTable() {
>       Node<K,V>[] tab; int sc;
>       while ((tab = table) == null || tab.length == 0) {		//自旋处理 保证了一定初始化成功
>           if ((sc = sizeCtl) < 0)													  //小于0 说明 有线程正在进行初始化  就让出CPU资源
>               Thread.yield(); // lost initialization race; just spin
>           else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
>               try {
>                   if ((tab = table) == null || tab.length == 0) {
>                       int n = (sc > 0) ? sc : DEFAULT_CAPACITY;
>                       @SuppressWarnings("unchecked")
>                       Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
>                       table = tab = nt;
>                       sc = n - (n >>> 2);
>                   }
>               } finally {
>                   sizeCtl = sc;
>               }
>               break;
>           }
>       }
>       return tab;
>   }
>```
>
>1. 首先判断`volatile` int sizeCtl属性如果小于0，其实就是等于-1，说明了此时有线程真在进行初始化。如果小于0让出cpu资源，调用`Thread.yield`方法。
>2. 如果 sizeCtl为0 那么就是CAS操作 比较并交换为1 如果成功了 再次进行Check，也就是双重检查机制  判断tab是否==null 进行初始化
>
>- 自旋 保证一定初始化完成  而且还不是空自旋 还做了及时让出CPU资源
>- CAS 保证同一时间 只有一个初始化数组线程
>- 二次check保证数组初始化的时候 table状态的对的
>
>---------
>
>- **Case2:table[i]对应的桶为null**
>
>最简单的情况，直接CAS操作占用桶`table[i]`即可。
>
>```java
>else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {    // CASE2: table[i]对应的桶为null
>// 注意下上面table[i]的索引i的计算方式：[ key的hash值 & (table.length-1) ]
>// 这也是table容量必须为2的幂次的原因，读者可以自己看下当table.length为2的幂次时，(table.length-1)的二进制形式的特点 —— 全是1
>// 配合这种索引计算方式可以实现key的均匀分布，减少hash冲突
>if (casTabAt(tab, i, null, new Node<K, V>(hash, key, value, null))) // CAS 插入一个链表结点
>                   break;
>```
>
>------
>
>- **CASE3: 发现ForwardingNode结点，说明此时table正在扩容，则尝试协助数据迁移**
>
>**ForwardingNode**结点是ConcurrentHashMap中的五类结点之一，相当于一个占位结点，表示当前table正在进行扩容，当前线程可以尝试协助数据迁移。
>
>```java
>else if ((fh = f.hash) == MOVED)         // CASE3: 发现ForwardingNode结点，说明此时table正在扩容，则尝试协助数据迁移
>   tab = helpTransfer(tab, f);
>```
>
>-------
>
>- **CASE4: 出现hash冲突,也就是table[i]桶中已经有了结点**  synchronized加锁
>
> 当两个不同key映射到同一个`table[i]`桶中时，就会出现这种情况：
>
>1. 当table[i]的结点类型为Node——链表结点时，就会将新结点以**“尾插法”**的形式插入链表的尾部。
>
>2. 当table[i]的结点类型为TreeBin——红黑树代理结点时，就会将新结点通过红黑树的插入方式插入。





### get操作

>跟`HashMap`操作差不多 只不过多了一个`ForwardingNode`节点查找 就是在扩容的时候在新的table上进行查找
>
>table数组以及 Node几点中value和next属性都被加入volatile关键字  是保证了多线程之间 内存的可见性 这个主要使用是内存屏障，缓存一致性等技术实现，我们在使用get方法的时候 就能在不加任何锁的情况下 得到最新的值，也就完成了多线程下的同步，保证了多线程下的安全。
>
>1. **如果table[i]的key和待查找key相同，那直接返回；**
>2. **如果table[i]对应的结点是特殊结点（hash值小于0），则通过`find`方法查找；特殊节点为红黑树节点或者就是扩容节点**
>3. **如果table[i]对应的结点是普通链表结点，则按链表方式查找。**
>
>------
>
>Find 操作 
>
>1. 普通Node节点查找  就是基于链表操作查找  直接遍历循环就可以
>
>**TreeBin 节点查找比较特殊**
>
>TreeBin的查找比较特殊，我们知道当槽`table[i]`被TreeBin结点占用时，说明链接的是一棵红黑树。由于红黑树的插入、删除会涉及整个结构的调整，所以通常存在读写并发操作的时候，是需要加锁的。ConcurrentHashMap采用了一种**类似读写锁**的方式：当线程持有写锁（修改红黑树）时，如果读线程需要查找，不会像传统的读写锁那样阻塞等待，而是转而以链表的形式进行查找（TreeBin本身时Node类型的子类，所有拥有Node的所有字段）
>
>```java
>/**
> * 从根结点开始遍历查找，找到“相等”的结点就返回它，没找到就返回null
> * 当存在写锁时，以链表方式进行查找
> */
>final Node<K, V> find(int h, Object k) {
>    if (k != null) {
>        for (Node<K, V> e = first; e != null; ) {
>            int s;
>            K ek;
>            /**
>             * 两种特殊情况下以链表的方式进行查找:
>             * 1. 有线程正持有写锁，这样做能够不阻塞读线程
>             * 2. 有线程等待获取写锁，不再继续加读锁，相当于“写优先”模式
>             */
>            if (((s = lockState) & (WAITER | WRITER)) != 0) {
>                if (e.hash == h &&
>                    ((ek = e.key) == k || (ek != null && k.equals(ek))))
>                    return e;
>                e = e.next;     // 链表形式
>            }
>
>            // 读线程数量加1，读状态进行累加
>            else if (U.compareAndSwapInt(this, LOCKSTATE, s, s + READER)) {
>                TreeNode<K, V> r, p;
>                try {
>                    p = ((r = root) == null ? null :
>                        r.findTreeNode(h, k, null));
>                } finally {
>                    Thread w;
>                    // 如果当前线程是最后一个读线程，且有写线程因为读锁而阻塞，则写线程，告诉它可以尝试获取写锁了
>                    if (U.getAndAddInt(this, LOCKSTATE, -READER) == (READER | WAITER) && (w = waiter) != null)
>                        LockSupport.unpark(w);
>                }
>                return p;
>            }
>        }
>    }
>    return null;
>}
>```
>
>---------
>
>**ForwardingNode**是一种临时结点，在扩容进行中才会出现，所以查找也在扩容的table上进行：
>
>---------
>
>5. 并发情况下，各线程中的数据可能不是最新的，那为什么 get 方法不需要加锁？
>     答：get操作全程不需要加锁是因为Node的成员val是用volatile修饰的，在多线程环境下线程A修改结点的val或者新增节点的时候是对线程B可见的。。

>JDK1.8：cas自旋  synchronized加锁

>1. ConcurrentHashMap具体实现，讲到jdk1.7,jkd1.8区别，分段锁，锁粒度 ，cas,自旋,synchronized加锁
>2. cocurrentHashMap 分段锁 1.8以后有没有了
>3. 线程安全集合，ConcurrentHashMap,具体实现，jdk1.7,jkd1.8区别，分段锁，锁粒度，好像答的不够多，然后又挤出来一个计数方法，1.8计数特别麻烦。
>4. 刚刚你说Segment是一种可重入锁，那他继承了什么？(ReentrantLock)
>5. jdk8中统计当前散列表中元素个数是怎么实现的？为什么没有使用`AtomicLong`
>6. 假设指定的桶位形成了红黑树，且当前的红黑树正在自平衡，那此时的读线程是阻塞还是等待、还是有其他方案
>7. 简单说一下 LastRun机制



### 扩容机制

>而ConcurrentHashMap采用的扩容策略为： “**多线程协同式rehash**“。这里的多线程指的是，有多个线程并发的把数据从旧的容器搬运到新的容器中。
>
>扩容时大致过程如下：ConcurrentHashMap 扩容是从数组队尾开始拷贝，拷贝槽点时会锁住槽点，拷贝完成后将槽点设置为转移节点。所以槽点拷贝完成后将新数组赋值给容器
>
>线程A在扩容把数据从oldTable搬到到newTable，这时其他线程
>
>1. 进行get操作：这个线程知道数据存放在oldTable或是newTable中，直接取即可。
>
>2. 进行写操作：如果要写的桶位，已经被线程A搬运到了newTable。那么这个线程知道正在扩容**，它也一起帮着扩容，扩容完成后才进行put操作**。
>
>3. 进行删除操作：与写一致。
>
>-------
>
>

>- **正在迁移的hash桶遇到 get 操作会发生什么**
>
>在扩容过程期间形成链 是使用的类似于复制引用的方式，也就是说 ln 和 hn 链是复制出来的，而非原来的链表迁移过去的，所以原来 hash 桶上的链表并没有受到影响，因此如果当前节点有数据，还没迁移完成，此时不影响读，能够正常进行。如果当前链表已经迁移完成，那么头节点会被设置成fwd节点，此时get线程会帮助扩容。
>
>-----
>
>- **正在迁移的hash桶遇到 put/remove 操作会发生什么？**
>
>如果当前链表已经迁移完成，那么头节点会被设置成fwd节点，此时写线程会帮助扩容，如果扩容没有完成，当前链表的头节点会被锁住，所以写线程会被阻塞，直到扩容完成。
>
>----
>
>- **扩容期间在未迁移到的hash桶插入数据会发生什么？**
>
>要插入的位置扩容线程还未迁移到，就可以插入，当迁移到该插入的位置时，就会阻塞等待插入操作完成再继续迁
>
>------
>
>- **如果 lastRun 节点正好在一条全部都为高位或者全部都为低位的链表上，会不会形成死循环？**
>
>在数组长度为64之前会导致一直扩容，但是到了64或者以上后就会转换为红黑树，因此不会一直死循环 。
>
>-----
>
>- **ConcurrentHashMap 和HashMap的扩容有什么不同？**
>
>HashMap的扩容是创建一个新数组，将值直接放入新数组中，JDK7采用头链接法，会出现死循环，JDK8采用尾链接法，不会造成死循环
>ConcurrentHashMap 扩容是从数组队尾开始拷贝，拷贝槽点时会锁住槽点，拷贝完成后将槽点设置为转移节点。所以槽点拷贝完成后将新数组赋值给容器
>
>------
>
>- **ConcurrentHashMap 是如何发现当前槽点正在扩容的？**
>
>ConcurrentHashMap 新增了一个节点类型，叫做转移节点，当我们发现当前槽点是转移节点时（转移节点的 hash 值是 -1），即表示 Map 正在进行扩容.



### 描述 CAS 算法在 ConcurrentHashMap 中的应用

>CAS是一种乐观锁，在执行操作时会判断内存中的值是否和准备修改前获取的值相同，如果相同，把新值赋值给对象，否则赋值失败，整个过程都是原子性操作，无线程安全问题
>ConcurrentHashMap 的put操作是结合自旋用到了CAS，如果hash计算出的位置的槽点值为空，就采用CAS+自旋进行赋值，如果赋值是检查值为空，就赋值，如果不为空说明有其他线程先赋值了，放弃本次操作，进入下一轮循环.。 以及初始化数组懒加载形式，CAS 保证同一时间 只有一个初始化数组线程。在put操作流程当中





### 统计元素个数，为什么不用`AtomicLong`

>- AtomicLong 和 LongAdder 区别 粒度更小
>
>AtomicLong是利用了底层的`CAS`操作来提供并发性的，比如addAndGet方法：
>
>```java
>public final long addAndGet(long delta) {
>       return unsafe.getAndAddLong(this, valueOffset, delta) + delta;
>}
>```
>
>上述方法调用了**Unsafe**类的**getAndAddLong**方法，`getAndAddLong并`非`native`，只是在自旋调用本身的`compareAndSwapLong`方法时 ，`compareAndSwapLong`才是`native`的，它的逻辑是采用自旋的方式不断更新目标值，直到更新成功。在并发量较低的环境下，线程冲突的概率比较小，自旋的次数不会很多。但是，高并发环境下，N个线程同时进行自旋操作，会出现大量失败并不断自旋的情况，此时AtomicLong的自旋会成为瓶颈。
>
>这就是**LongAdder**引入的初衷——解决高并发环境下**AtomicLong**的自旋瓶颈问题。高并发的思想基本都是化整为零，然后在合并，让操作更加细粒度，最大效果提高并发执行效果
>
>**AtomicLong**是多个线程针对单个热点值value进行原子操作。而**LongAdder**是每个线程拥有自己的槽，各个线程一般只对自己槽中的那个值进行CAS操作。类似于JDK1.7 concurrentHashMap分段锁的设计。这种设计就是用空间来换时间
>
>但是对于**LongAdder**来说，内部有一个`base`变量，一个`Cell[]`数组。
>`base`变量：非竞态条件下，直接累加到该变量上
>`Cell[]`数组：竞态条件下，累加个各个线程自己的槽`Cell[i]`中
>
>-------
>
>
>
>ConcurrentHashMap的计数其实延用了LongAdder分段计数的思路，只不过ConcurrentHashMap并没有在内部直接使用LongAdder，而是差不多copy了一份和LongAdder类似的代码：
>
>计数基值,当没有线程竞争时，计数将加到该变量上。类似于LongAdder的base变量
>计数数组，出现并发冲突时使用。类似于LongAdder的cells数组



## [ConcurrentSkipListMap](https://segmentfault.com/a/1190000016168566)

>![preview](https://segmentfault.com/img/bVbf4hX?w=2777&h=492/view)
>
>1. 跳表由很多层组成；
>2. 每一层都是一个有序链表；
>3. 对于每一层的任意结点，不仅有指向下一个结点的指针，也有指向其下一层的指针。
>
>是一种空间换时间的一种算法设计，在redis当中也运用到。



## [CopyOnWriteArrayList](https://segmentfault.com/a/1190000016214572)

>`ArrayList`是一种“列表”数据机构，其底层是通过**数组**来实现元素的**随机访问**。如果想要在并发环境下使用“列表”，一般有以下3种方式：
>
>1. 使用**Vector**类
>2. 使用`Collections.synchronizedList`返回一个同步代理类；
>
>这两种方式都是加入synchronized关键字 锁粒度比较大
>
>------
>
>大多数场景都是读多写少 ，CopyOnWriteArrayList，运用了一种**“写时复制”**的思想，通俗的理解就是当我们需要修改（增/删/改）列表中的元素时，不直接进行修改，而是先将列表Copy，然后在新的副本上进行修改，修改完成之后，再将引用从原列表指向新列表。
>
>这样做的好处是**读/写是不会冲突**的，可以并发进行，读操作还是在原列表，写操作在新列表。仅仅当有多个线程同时进行写操作时，才会进行同步。
>
>```java
>    final transient ReentrantLock lock = new ReentrantLock();  //排它锁, 用于同步修改操作
>    private transient volatile Object[] array;                 //内部数组  用volatile修饰
>
>    final Object[] getArray() {
>        return array;
>    }
>    final void setArray(Object[] a) {
>        array = a;
>    }
>```
>
>----------------
>
>**add操作**
>
>**add**方法首先会进行加锁，保证只有一个线程能进行修改；然后会创建一个新数组（大小为`n+1`），并将原数组的值复制到新数组，新元素插入到新数组的最后；最后，将字段`array`指向新数组。
>
>![preview](https://segmentfault.com/img/bVbgci5?w=649&h=232/view)
>
>**CopyOnWriteArrayList**：它适用于处理**“读多写少”**的并发场景。
>
>**1. 内存的使用**
>由于CopyOnWriteArrayList使用了“写时复制”，所以在进行写操作的时候，内存里会同时存在两个array数组，如果数组内存占用的太大，那么可能会造成频繁GC,所以CopyOnWriteArrayList并不适合大数据量的场景。
>
>**2. 数据一致性**
>CopyOnWriteArrayList只能保证数据的最终一致性，不能保证数据的实时一致性——读操作读到的数据只是一份快照。所以如果希望写入的数据可以立刻被读到，那CopyOnWriteArrayList并不适合。



## ArrayBlockingQueue

>
>
>1. 队列的容量一旦在构造时指定，后续不能改变；
>2. 插入元素时，在队尾进行；删除元素时，在队首进行；
>3. 队列满时，调用特定方法插入元素会阻塞线程；队列空时，删除元素也会阻塞线程；
>4. 支持公平/非公平策略，默认为非公平策略。
>
>这里的公平策略，是指当线程从阻塞到唤醒后，以最初请求的顺序（`FIFO`）来添加或删除元素；非公平策略指线程被唤醒后，谁先抢占到锁，谁就能往队列中添加/删除顺序，是随机的。
>
>**`ArrayBlockingQueue`在构造时就指定了内部数组的大小，并通过`ReentrantLock`来保证并发环境下的线程安全。**
>
>--------
>
>底层数据结构：
>
>ArrayBlockingQueue的内部数组其实是一种环形结构。ArrayDeque底层也是环形数组 
>
>ArrayBlockingQueue利用了ReentrantLock来保证线程的安全性，针对队列的修改都需要加全局锁。在一般的应用场景下已经足够。对于超高并发的环境，由于生产者-消息者共用一把锁，可能出现性能瓶颈。
>
>另外，由于`ArrayBlockingQueue`是有界的，且在初始时指定队列大小，所以如果初始时需要限定消息队列的大小，则`ArrayBlockingQueue `比较合适。后续，我们会介绍另一种基于单链表实现的阻塞队列——**LinkedBlockingQueue**，该队列的最大特点是使用了“两把锁”，以提升吞吐量。



## LinkedBlockingQueue

>LinkedBlockingQueue是一种**近似有界阻塞队列**，为什么说近似？因为LinkedBlockingQueue既可以在初始构造时就指定队列的容量，也可以不指定，如果不指定，那么它的容量大小默认为`Integer.MAX_VALUE`。
>
>**LinkedBlockingQueue除了底层数据结构（单链表）与ArrayBlockingQueue不同外，另外一个特点就是：**
>**它维护了两把锁——`takeLock`和`putLock`。 都是ReentrantLock**
>**takeLock用于控制出队的并发，putLock用于入队的并发。这也就意味着，同一时刻，只能只有一个线程能执行入队/出队操作，其余入队/出队线程会被阻塞；但是，入队和出队之间可以并发执行，即同一时刻，可以同时有一个线程进行入队，另一个线程进行出队，这样就可以提升吞吐量**。
>
>-----
>
>在ArrayBlockingQueue章节中，我们说过，ArrayBlockingQueue维护了一把全局锁，无论是出队还是入队，都共用这把锁，这就导致任一时间点只有一个线程能够执行。那么对于“生产者-消费者”模式来说，意味着生产者和消费者不能并发执行。
>
>-------
>
>##### LinkedBlockingQueue 对比 ArrayBlockingQueue
>
>归纳一下，**LinkedBlockingQueue**和**ArrayBlockingQueue**比较主要有以下区别：
>
>1. 队列大小不同。ArrayBlockingQueue初始构造时必须指定大小，而LinkedBlockingQueue构造时既可以指定大小，也可以不指定（默认为`Integer.MAX_VALUE`，近似于无界）；
>2. 底层数据结构不同。ArrayBlockingQueue底层采用**数组**作为数据存储容器，而LinkedBlockingQueue底层采用**单链表**作为数据存储容器；
>3. 两者的加锁机制不同。ArrayBlockingQueue使用一把**全局锁**，即入队和出队使用同一个ReentrantLock锁；而LinkedBlockingQueue进行了**锁分离**，入队使用一个ReentrantLock锁（putLock），出队使用另一个ReentrantLock锁（takeLock）；
>4. LinkedBlockingQueue不能指定公平/非公平策略（默认都是非公平），而ArrayBlockingQueue可以指定策略。





# 多线程

## 线程

>1. `Java` 创建线程的方式?  实际项目中运用过多线程吗？用来干什么？
>2. 继承`Thread`和实现`Runnable`接口的区别	`Future/FutureTask ` 
>3. 为什么要用`start()`方法启动线程而不用`run()`启动                                                    考点：线程是怎么创建的
>4. 一个线程两次调用`start()`方法会发生什么？                                                                考点：线程的声明周期
>5. 什么时候会出现线程不安全   多线程安全问题怎么解决？实际项目中怎么解决的，场景和解决方式
>6. 如何构造线程安全的类
>7. 为什么要有并发 、引入多线程有什么问题、什么是共享变量，内存模型了解吗 
>
>-----------------------
>
>
>
>1. 线程的状态转换  线程的停止 
>2. java多线程实现方式   每种实现方式的使用场景说一下  实现线程的方式及区别
>3. 线程的同步机制有哪些？ 线程的通讯方式有哪些？  多线程协作方式，除了锁还有什么吗？ 信号量解释一下，干什么用的
>4. 了解多线程吗?怎么实现，有没有用到代理模式？
>5. wait()/notify()与sleep()的异同  , 为什么线程通信的方法wait()/notify()定义在Object类，而sleep()定义在Thread类
>6. 有一个线程要等待其他线程执行完再执行?有一个线程要等待其他线程都就绪再执行?
>7. 某个线程奔溃了会影响所在进程么,那以进程存在的形式比如nginx,某个进程挂掉了,会影响整个nginx么
>8. 线程和进程的关系？一个进程多个线程，一个线程崩溃会有什么问题？



### 线程不安全原因

>1. 线程是抢占执行的。
>2. 有的操作不是原子的。当 cpu 执行一个线程过程时，调度器可能调走CPU，去执行另一个线程，此线程的操作可能还没有结束；（通过锁来解决
>3. 多个线程尝试修改同一个变量（一对一修改、多对一读取、多对不同变量修改，是安全的）
>4. 内存可变性
>5. 指令重排序：java的编译器在编译代码时，会针对指令进行优化，调整指令的先后顺序，保证原有逻辑不变的情况下，来提高程序的运行效率。





### 进程和线程

>进程是执行着的应用程序，而线程是进程内部的一个执行序列，一个进程可以有多个线程。线程有叫做轻量级进程
>
>进程是资源分配的单位，线程是执行单元
>
>进程间切换代价大，线程见切换代价小
>
>进行拥有资源多 线程拥有资源少
>
>进程间不会相互影响，一个线程挂掉将导致整个进程挂掉
>
>----------
>
>#### 什么是上下文切换?
>
>概括来说就是：当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。**任务从保存到再加载的过程就是一次上下文切换**。



### `Java` 创建线程的方式?  

>`Java` 创建线程的方式?  实际项目中运用过多线程吗？用来干什么？
>
>解析：  `Runnable`中的run()方法是线程的执行单元 
>
>1.  继承`Thread`类并重写`run`方法  这个`run`方法最终还是  Thread成员变量 `private Runnable target`;    执行`target.run()`
>
>2. 实现`Runnable`接口创建线程  创建`Thread`对象 并把`Runnable`接口的实现类作为`Thread`的构造参数  给成员变量 `private Runnable target`赋值
>
>3. 使用`Callable`和`Future`创建线程 
>
>   1】创建`Callable`接口的实现类，并实现`call()`方法，然后创建该实现类的实例
>
>   2】使用`FutureTas`k类来包装`Callable`对象，该`FutureTask`对象封装了Callable对象的call()方法的返回值
>
>   3】使用`FutureTask`对象作为`Thread`对象的`target`创建并启动线程（**因为FutureTask实现了Runnable接口**）
>
>   4】调用`FutureTask`对象的`get()`方法来获得子线程执行结束后的返回值
>
>4. 使用线程池例如用`Executor`框架
>
>   ​     实际项目大多数都是采用线程池 单独的创建线程来完成多线程的任务有点少

-----------

### 继承`Thread`和实现`Runnable`接口的区别

>如果一个类继承Thread，则不适合资源共享。但是如果实现了Runable接口的话，则很容易的实现资源共享。实现Runnable接口比继承Thread类所具有的优势：
>
>**1）：适合多个相同的程序代码的线程去处理同一个资源**
>
>**2）：可以避免java中的单继承的限制**
>
>**3）：增加程序的健壮性，代码可以被多个线程共享，代码和数据独立**

-------

### `start()`方法启动线程而不用`run()`启动         

>为什么要用`start()`方法启动线程而不用`run()`启动 ，一个线程两次调用`start()`方法会发生什么？  这个题就是非常重要了被
>
>- 直接执行` run()` 方法，会把 `run `方法当成一个` main `线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。
>- 调用`start()`方法  其实最核心的部分是`start0()` 这个本地方法 `private  native void start0();`  c++根据当前`jvm`版本编写不同的操作系统函数去申请线程资源，在`windows`平台会申请一个线程，在`linux`平台上会申请一个轻量级的进程。在开始执行这个线程时，`jvm`会调用该线程的`run()`方法。换言之，`run()`方法时被`JNI`（java本地方法）方法`start0()`调用的.
>- `new` 一个 `Thread`，线程进入了新建状态,创  建了一个`java`对象。调用 `start() `方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 `start() `会执行线程的相应准备工作，然后自动执行` run() `方法的内容，这是真正的多线程工作。

----

### 一个线程两次调用`start()`方法会发生什么？   

>首先需要判断线程的生命周期  只有处于`new Thread`之后才能执行`start()`方法，执行完`start()`方法线程就是到`Runnable`可就绪状态，当年再次调用`start()`时侯，线程可能处于其他状态，不是处于新建的状态   而且线程`Thread`内部存在一个成员变量 `private volatile int threadStatus = 0;` 标志来判断 ` Thread`被构造出`new`状态` threadStatus `内部属性为0  ,再次调用start()方法 该标志位就是不可能为0被  所以就是抛出异常了。
>
>```java
>if (threadStatus != 0)
>    throw new IllegalThreadStateException();   
>```
>
>```java
>public enum State {
>    NEW,      			 // 线程还没有被启动的时候的状态
>    
>    RUNNABLE,   		 // 表示调用了“start()”方法，这里还可以细分为“ready”和“running”状态
>    
>    BLOCKED,    		 // 线程等待进入到synchronized方法或者等待进入synchronized块
>    
>    WAITING,    		 // 表示线程进入等待状态，比如调用了“wait()”、“join()”等
>
>    TIMED_WAITING, 	     // 带有超时时间的
>    
>    TERMINATED;  	     // 线程正常结束，或者强制停止，或者遇到异常终止之后的状态
>}
>```



### 线程周期



>![110415_7MST_2653226.png](http://static.oschina.net/uploads/space/2016/0805/110415_7MST_2653226.png)
>
>```java
>runnable--->running 一旦cpu通过轮询或者其他方式从可执行列中中选中了线程 那么此时才能正真的执行自己的逻辑代码
>    
>runnable<--->waiting :
>*      1.  synchronized(obj) 调用obj.wait()方法 重runnable--->waiting   进入wait set线程休息室  wait pool 
>*          synchronized(obj) 调用obj.notify()方法 竞争锁成功重 waiting--->runnable   竞争锁失败 waiting--->block in 阻塞队列
>*
>    *      2.  join()方法 例如主线程调用线程t  t.join() 会使主线程重runnable--->waiting 主线程等待t线程结束才会运行  主线程在t线程的监视器上等待
>    *
>    runnable<---->time_waiting
>    *      1. t 线程用 synchronized(obj) 获取了对象锁后 调用 obj.wait(long n) 方法时，t 线程从 RUNNABLE --> TIMED_WAITING
>    *         t 线程等待时间超过了 n 毫秒，或调用 obj.notify() ， obj.notifyAll() ， t.interrupt() 时
>    *                                                                          竞争锁成功，t 线程从 TIMED_WAITING --> RUNNABLE
>    *                                                                          竞争锁失败，t 线程从 TIMED_WAITING --> BLOCKED
>*      2. 当前线程调用 t.join(long n) 方法时，当前线程从 RUNNABLE --> TIMED_WAITING 注意是当前线程在t 线程对象的监视器上等待.
>    *        当前线程调用 Thread.sleep(long n) ，当前线程从 RUNNABLE --> TIMED_WAITING 当前线程等待时间超过了 n 毫秒，当前线程从 tw->r
>    *
>    runnable --> blocked
>*       1.t 线程用 synchronized(obj) 获取了对象锁时如果竞争失败，从 RUNNABLE --> BLOCKED 持 obj 锁线程的同步代码块执行完毕，
>*       2.会唤醒该对象上所有 BLOCKED 的线程重新竞争，如果其中 t 线程竞争 成功，从 BLOCKED --> RUNNABLE ，其它失败的线程仍然 BLOCKED
>
>runnable-terminated 
>   	1.线程运行正常结束，结束生命周期
>   	2.线程运行出错 意外结束
>
>*      * 一旦线程调用wait方法 就会重偏向锁--->轻量锁--->重量锁
>*      * wait 方法是object方法 sleep是thread的静态方法
>*      * wait 必须拥有该对象的monitor 才可以被进入wait set队列当中 当被唤醒是又会进入阻塞队列 等待枪锁
>*      * 而thread.sleep在同步代码块中不会放弃monitor的owner权力
>*      *
>*      * notify()和 wait()必须持有对象锁  否则的话就会抛出异常 current thread is not owner
>*      * notify() 在同步代码块中通知wait()退出等待 只能通知一个
>*      * notifyAll() 通知所有的  线程里边最好用while()循环判断一下条件 是否满足该线程执行条件
>```

-----------

### yield和wait、sleep区别

>##### yield  
>
>`yield()`方法只是提出申请释放CPU资源，不会释放锁，线程依然处于RUNNABLE状态。至于能否成功释放由JVM决定。
>
>`yield()`方法调用后线程只是暂时的将调度权让给别人，但立刻可以回到竞争线程锁的状态。
>
>调用了`yield()`方法后，线程依然处于`RUNNABLE`状态，线程不会进入堵塞状态。
>
>##### sleep
>
>`sleep()`方法可以使线程进入`WAITING`状态，而且不会占用CPU资源，也不会释放锁，直到过了规定的时间后再执行后续代码，休眠期间如果被中断，会抛出异常，并会清空中断状态标记。
>
>##### wait
>
>`wait `必须拥有该对象的`monitor `才可以被进入`wait set`队列当中 当被唤醒是又会进入阻塞队列 等待枪锁
>
>`wait()`方法调用后会释放锁，`yield``sleep()`方法调用后不会释放锁。会进入等待队列当中
>
>.`wait()`、`notify()`方法必须写在同步方法中，是为了防止死锁和永久等待，使线程更安全，而`sleep()`方法不需要有这个限制。
>
>两个方法所属类不同，`sleep()`方法属于`Thread`类；`wait()`属于`Object`类中，放在`Object`类中是因为`Java`中每个类都可以是一把锁。

### 什么时候会出现线程不安全

>https://www.cnblogs.com/jimoer/p/13308699.html
>
>https://segmentfault.com/a/1190000038320670 	
>
>什么时候会出现线程不安全   多线程安全问题怎么解决？实际项目中怎么解决的，场景和解决方式
>
>- 线程安全的定义可以理解为：当多个线程同时访问一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获得正确的结果，那就称这个对象是线程安全的。
>- 线程不安全：操作并非原子。多个线程执行某段代码，如果这段代码产生的结果受不同线程之间的执行时序影响，而产生非预期的结果，即发生了竞态条件，就会出现线程不安全;
>
>-------------



### 多线程安全问题怎么解决  



>- **互斥同步悲观策略**：同步是指多**个线程并发访问共享数据时，保证共享数据在同一时刻只被一条线程使用**。互斥是指**实现同步的一种手段，临界区（Critical Section）、互斥量（Mutex）和信号量（Semaphore）都是常见的互斥实现方式**。 java中具体的实现方式就是`synchronized Reentrant`
>- **非同步阻塞乐观策略**：互斥同步面临的主要问题时进行线程阻塞和唤醒所带来的性能开销，因此这种同步也被称为阻塞同步（Block Synchronized）。从解决问题的角度来看，互斥同步是一种悲观的并发策略，无论共享的数据是否真的会出现竞争，都会进行加锁。随着硬件指令集的发展，出现了另一种选择，基于冲突检测的乐观并发策略，通俗地说就是不管风险，先进行操作，发生了冲突，在进行补偿，最常用的补偿就是不断重试，直到出现没有竞争的数据为止。使用这种乐观并发策略不再需要线程阻塞挂起，因此这种同步操作被称为非阻塞同步（Non-Blocking Synchronized）。CAS操作
>- **无同步方案**：不依赖全局变量、存储在堆上的数据和公用的系统资源，用到的状态量都由参数传入，不调用非可重入的方法等。简单来说就是一个原则：如果一个方法的返回结果是可以预测的，只要输入了相同的数据，就能返回相同的结果，那它就满足可重入性的要求，当然也就是线程安全的。
>**线程本地存储（Thread Local Storage）**：**如果一段代码中所需的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能，就可以把共享数据的可见范围限制在同一个线程内，这样无须同步也能保证线程之间不出现数据争用的问题**。如大部分使用消费队列的架构模式，都会将产品的消费过程限制在一个线程中消费完，最经典一个实例就是Web交互模式中的“一个请求对应一个服务器线程”的处理方式，这种处理方式的广泛应用使得很多Web服务端应用都可以使用线程本地存储来解决线程安全问题。



### 线程同步机制

>互斥量(互斥锁/mutex)：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。互斥对象和临界区(代码的一个区间)对象非常相似，只是其允许在进程间使用，而临界区只限制于同一进程的各个线程之间使用，但是更节省资源，更有效率。
>信号量/semaphore：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。Mutex互斥量可以说是semaphore在仅取值0/1时的特例
>事件（信号）：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。比如在某些网络应用程序中，一个线程如A负责侦听通信端口，另外一个线程B负责更新用户数据，利用事件机制，则线程A可以通知线程B何时更新用户数据。





## 线程池

>https://www.cnblogs.com/thisiswhy/p/12690630.html
>
>https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html
>
>https://github.com/yinjihuan/kitty     项目
>
>1.技术点 实现阻塞队列：生产者消费者模式  动态参数技术 还有生命周期（At）

>1. 知道`JDK Executors`线程池 提供了哪些默认的实现么？     0.是线程池的作用 为什么采用线程池
>2. 看过阿里巴巴`java`开发手册么？知道为啥不允许使用默认的实现么？
>3. 你们没有用默认的吧？那来介绍一下你们自定义线程池的几个常用参数
>4. 你这几个参数的值是怎么得来的呀？算出来的？怎么算出来的？ 重点 其中参考美团文章 实现动态线程池了
>5. 线程池里边的任务是`IO`密集型的还是`cpu`密集型的呢？ 【说了一个常规的压测方法】
>6. 自定义一个线程池，来说一下你这个线程池的工作流程
>7. 线程池生命周期管理   答到`AtomicInteger ` 两个变量共享一个`AtomicInteger ` 数  重点答到这里呗
>8. 那你这个线程池满了该怎么办？拒绝？咋拒绝？有哪些拒绝策略呢？
>9. 线程池为什么有一个阻塞队列，为什么一定要是阻塞的
>10. 线程池被创建后里面有线程吗？如果没有的话，你知道有什么方法对线程池进行预热吗？
>11. 核心线程数会被回收吗？需要什么设置？                                                                                                                                                                                          回到开始说的阿里巴巴`java`开发手册不允许使用默认实现，可能会引起`OOM`，那我们来聊聊`jvm`吧 
>12. 线程池异常处理
>13. 线程池优化策略 重点
>14. **线程池中 submit()和 execute()方法有什么区别？**
>15. 如果你自己实现一个阻塞队列，你会怎么设计，为什么
>
>------------------------------------上述是连环炮问-------------------------

>21. 哪些方法可以创建线程池                                   7中`Executors`中的静态方法  一种`ThreadPoolExecutor`
>22. 单线程线程池的应用场景                                   适用于串行执行任务的场景，一个任务一个任务地执行。可以保证先进先出的执行顺序

----

###  0.是线程池的作用 为什么采用线程池

>**线程池的作用以及解决了什么问题**
>
>线程过多会带来额外的开销，其中包括创建销毁线程的开销、调度线程的开销等等，同时也降低了计算机的整体性能。线程池维护多个线程，等待监督管理者分配可并发执行的任务。这种做法，一方面避免了处理任务时创建销毁线程开销的代价，另一方面避免了线程数量膨胀导致的过分调度问题，保证了对内核的充分利用。
>
>当然，使用线程池可以带来一系列好处：
>
>- **降低资源消耗**：通过池化技术重复利用已创建的线程，降低线程创建和销毁造成的损耗。
>- **提高响应速度**：任务到达时，无需等待线程创建即可立即执行。
>- **提高线程的可管理性**：线程是稀缺资源，如果无限制创建，不仅会消耗系统资源，还会因为线程的不合理分布导致资源调度失衡，降低系统的稳定性。使用线程池可以进行统一的分配、调优和监控。
>- **提供更多更强大的功能**：线程池具备可拓展性，允许开发人员向其中增加更多的功能。比如延时定时线程池ScheduledThreadPoolExecutor，就允许任务延期执行或定期执行。

------------------------

### 1.知道`JDK `线程池 提供了哪些默认的实现么？

>- `Executors.newFixedThreadPool`l (固定数目线程的线程池)  核心线程数和最大线程数一样 阻塞队列为无界队列`LinkedBlockingQueue`
>- `Executors.newCachedThreadPool`  (缓存线程池)核心线程数为0  最大线程数为`Integer.MAX_VALUE`  阻塞队列是`SynchronousQueue`                                               使用场景:用于并发执行大量短期的小任务
>- `Executors.newSingleThreadExecutor`（单个线程的线程池） 核心线程数为1  最大线程数也为1  阻塞队列是`LinkedBlockingQueue`队列长度为`Integer.MAX_VALUE`  `keepAliveTime`为0   使用场景：适用于串行执行任务的场景，一个任务一个任务地执行。可以保证先进先出的执行顺序
>- `Executors.newScheduledThreadPooll` （执行延迟任务的线程池）最大线程数为`Integer.MAX_VALUE` 阻塞队列是`DelayedWorkQueue`  任务延迟执行 
>- `Executors.newSingleThreadScheduledExecutor`创建一个单线程的可以执行延迟任务的线程池；
>- `Executors.newWorkStealingPool`创建一个抢占式执行的线程池（任务执行顺序不确定）【JDK 1.8 添加】。

------------------------------------

### **2**.为啥不允许使用默认的实现么？java开发手册

>1） `FixedThreadPool` 和 `SingleThreadPool`
>
>允许的请求队列`LinkedBlockingQueue`长度为 `Integer.MAX_VALUE`，可能会堆积大量的请求，从而导致 OOM。 
>
>2） `CachedThreadPool`
>
>允许的创建线程数量为` Integer.MAX_VALUE`，可能会创建大量的线程，从而导致 OOM。但是队列是`SynchronousQueue`    
>
>3）`newScheduledThreadPool`
>
>最大线程数为`Integer.MAX_VALUE`  可能会创建大量的线程，从而导致 OOM  队列是`DelayedWorkQueue`   初始化容量是16	
>
>**自定义使用线程池在这里 我们就是使用ThreadPoolExecutor 这种线程池自己来定义参数呗**

--------------------------

### **3.** 介绍一下你们自定义线程池的几个常用参数

>1.**corePoolSize**：核心线程数大小：不管它们创建以后是不是空闲的。线程池需要保持 corePoolSize 数量的线程，除非设置了 allowCoreThreadTimeOut。）
>
>2.**maximumPoolSize**：最大线程数：线程池中最多允许创建 maximumPoolSize 个线程。
>
>3.**keepAliveTime**：存活时间：如果经过 keepAliveTime 时间后，超过核心线程数的线程还没有接受到新的任务，那就回收。
>
>4.**unit**：keepAliveTime 的时间单位。
>
>5.**workQueue**：存放待执行任务的队列：当提交的任务数超过核心线程数大小后，再提交的任务就存放在这里。它仅仅用来存放被 execute 方法提交的 Runnable 任务。所以这里就不要翻译为工作队列了，好吗？不要自己给自己挖坑。
>
>6.**threadFactory**：线程工程：用来创建线程工厂。比如这里面可以自定义线程名称，当进行虚拟机栈分析时，看着名字就知道这个线程是哪里来的，不会懵逼。
>
>7.**handler** ：拒绝策略：当队列里面放满了任务、最大线程数的线程都在工作时，这时继续提交的任务线程池就处理不了，应该执行怎么样的拒绝策略。
>
>线程池构造参数有8个，但是最核心的是3个：`corePoolSize`、`maximumPoolSize`，`workQueue`，它们最大程度地决定了线程池的任务分配和线程分配策略。考虑到在实际应用中我们获取并发性的场景主要是两种：
>
>（1）并行执行子任务，提高响应速度。这种情况下，应该使用同步队列，没有什么任务应该被缓存下来，而是应该立即执行。
>
>（2）并行执行大批次任务，提升吞吐量。这种情况下，应该使用有界队列，使用队列去缓冲大批量的任务，队列容量必须声明，防止任务无限制堆积。所以   		  线程池只需要提供这三个关键参数的配置，并且提供两种队列的选择，就可以满足绝大多数的业务需求，Less is More。

---------------------------

### **4.这几个几个参数的值是怎么得来的呀**

>1. 第一个方案：`cpu密集型-->核心线程数=cpu核心数+1`  但是和实际业务场景有所偏离。
>2. 设置为` 2*CPU `核心数，有点像是把任务都当做` IO `密集型去处理了。而且一个项目里面一般来说不止一个自定义线程池吧？比如有专门处理数据上送的线程池，有专门处理查询请求的线程池，这样去做一个简单的线程隔离。但是如果都用这样的参数配置的话，显然是不合理的。
>3. 理想状态。流量是不可能这么均衡的，就拿美团来说，下午3，4点的流量，能和 12 点左右午饭时的流量比吗？  

--------------------------------------

**动态实现线程池参数 **

>所以虽然上边自己写参数 ，但是我们还是需要根实际的业务需求来调整线程池的参数，偶然见我看到一篇美团技术博客讨论的线程池技术，动态修改线程池参数，根据它的文章描述 自己实现了一个动态线程池。 可以动态的修改参数，而且JDK源码也是允许我们这样做的。
>
>1. 在运行期线程池使用方调用此方法设置`corePoolSize`之后，线程池会直接覆盖原来的`corePoolSize`值，并且基于当前值和原始值的比较结果采取不同的处理策略。
>2. 对于当前值小于当前工作线程数的情况，说明有多余的`worker`线程，此时会向当前idle的worker线程发起中断请求以实现回收，多余的worker在下次idel的时候也会被回收；
>3. 对于当前值大于原始值且当前队列中有待执行任务，则线程池会创建新的`worker`线程来执行队列任务，`setCorePoolSize`具体流程如下
>
>4. setMaximumPoolSize ()源码分析  判断工作线程是否是大于最大线程数，如果大于，则对空闲线程发起中断请求。
>
>----------------------------------------------------------------------------------------------------------------------
>
>动态修改线程池参数注意事项：
>
>1. 核心线程数 大于 最大线程数  真正的活动线程数其实还是最大线程数  
>
> 2. 设置核心线程数的时候，同时设置最大线程数即可。其实可以把二者设置为相同的值 
>
> 3. 如何指定队列长度？：源码当中队列长度 `private final int capacity` 初始化容量利用`final`修饰 所以没有后续改变的set方法  
>
>    ​								       解决办法 自定义阻塞队列 其中`private int capacity`不用加`final`修饰就可以了 并提供set方法

-------------

### **5**.任务是`IO`密集型的还是`cpu`密集型的呢

>- 什么是是`IO`密集型的还是`cpu`密集型 
>
>   `CPU`密集型也是指计算密集型，大部分时间用来做计算逻辑判断等`CPU`动作的程序称为`CPU`密集型任务。该类型的任务需要进行大量的计算，主要消耗`CPU`资源。这种计算密集型任务虽然也可以用多任务完成，但是任务越多，花在任务切换的时间就越多，`CPU`执行任务的效率就越低，所以，要最高效地利用`CPU`，计算密集型任务同时进行的数量应当等于`CPU的核心数+1`。 为什么要+1呢 ，即使当计算`CPU`密集型的线程偶尔由于页缺失故障或者其他原因而暂停时，这个“额外”的线程也能确保 `CPU `的时钟周期不会被浪费，反正把它理解为一个备份的线程就行了。 **核心线程数=cpu核心数+1**
>
>  ` IO`密集型任务指任务需要执行大量的IO操作，涉及到网络、磁盘IO操作，对CPU消耗较少。 **核心线程数=2*cpu核心数**
>
>
>
>- 本机测试
>
>​    例如我的`CPU`核心数6个   但是`cpu`线程数是12个    `IO`我会创建12个 `cpu`我会创建6个
>
>1.  单个cpu线程在同一时刻只能执行单一指令，也就是一个线程。
>2. 线程是操作系统最小的调度单位，进程是资源（比如：内存）分配的最小单位。
>3. `Java`中的所有线程在`JVM`进程中,CPU调度的是进程中的线程。
>4. `JVM`是一份本地化的程序，本质上是可执行的文件，是静态的概念。程序运行起来成为进程，是动态的概念。` java`程序是跑在`JVM`上的，严格来讲，是跑在`JVM`实例上的，一个`JVM`实例其实就是`JVM`跑起来的进程，二者合起来称之为一个`JAVA`进程。各个`JVM`实例之间是相互隔离的。
>5. 默认情况下，`Java`中每创建一个线程，操作系统会分配1M的栈空间
>
>
>
>-  那么java多进程，每个进程又多线程，cpu是如何调度的呢？
>
>
>个人理解：操作系统并不是单纯均匀的分配cpu执行不同的进程，因为线程是调度的最小单位，所以会根据不同进程中的线程个数进行时间分片，均匀的执行每个线程，也就是说A进程中有10个线程，而B进程中有2个线程，那么cpu分给进程的执行时间理论上应该是5:1才合理。

--------

### 6.==线程池的工作流程 举例子==

>![img](https://user-gold-cdn.xitu.io/2020/4/13/17171b849819affe?w=584&h=525&f=png&s=49127)
>
>

>- 任务的执行有两种可能：一种是任务直接由新创建的线程执行。另一种是线程从任务队列中获取任务然后执行，执行完任务的空闲线程会再次去从队列中申请任务再去执行。第一种情况仅出现在线程初始创建的时候，第二种是线程获取任务绝大多数的情况。
>
>  
>
>问题：1.如果这个线程池接受到了 30 个比较耗时的任务，这个时候线程池的状态（或者说数据）是怎样的？
>
>​			2.在前面 30 个比较耗时的任务还没执行完成的情况下，再来多少个任务会触发拒绝策略？
>
>-------------------------------------------------------------------------------------------------------------------------------------------------
>
>解答：其实这个问题就是把线程池提交任务的流程说一下  注意最大线程数的参数 在满足什么条件之后才可以开始执行
>
>​			1.当接收到了 30 个比较耗时的任务时，10 个核心线程数都在工作，剩下的 20 个去队列里面排队。这个时候和最大线程数是没有关系的，所以和线程存活时间也就没有关系。
>
>​			2.上面的线程池中最多接受 1000（队列长度） + 30（最大线程数） = 1030 个任务。所以当已经接收了30个任务的情况下，再来980个任务时队列满了，并且10个核心线程数也在工作，再来20个线程（前提是任务没有执行完毕）我们会创建新的线程到最大线程数。 因此，在前面 30 个比较耗时的任务还没执行完成的情况下，再来 1001 个任务，第 1001 个任务就会触发线程池的拒绝策略了。

-----

### 7.线程池生命周期管理

>线程池运行的状态，并不是用户显式设置的，而是伴随着线程池的运行，由内部来维护。线程池内部使用一个变量维护两个值：运行状态(runState)和线程数量 (workerCount)。在具体实现中，线程池将运行状态(runState)、线程数量 (workerCount)两个关键参数的维护放在了一起，如下代码所示：
>
>```Java
>private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));
>```
>
>`ctl`这个AtomicInteger类型，是对线程池的运行状态和线程池中有效线程的数量进行控制的一个字段， 它同时包含两部分的信息：线程池的运行状态 (runState) 和线程池内有效线程的数量 (workerCount)，高3位保存runState，低29位保存workerCount，两个变量之间互不干扰。用一个变量去存储两个值，可避免在做相关决策时，出现不一致的情况，不必为了维护两者的一致，而占用锁资源。通过阅读线程池源代码也可以发现，经常出现要同时判断线程池运行状态和线程数量的情况。线程池也提供了若干方法去供用户获得线程池当前的运行状态、线程个数。这里都使用的是位运算的方式，相比于基本运算，速度也会快很多。
>
>关于内部封装的获取生命周期状态、获取线程池线程数量的计算方法如以下代码所示：
>
>```Java
>private static int runStateOf(int c)     { return c & ~CAPACITY; } //计算当前运行状态
>private static int workerCountOf(int c)  { return c & CAPACITY; }  //计算当前线程数量
>private static int ctlOf(int rs, int wc) { return rs | wc; }   //通过状态和线程数生成ctl
>```
>
><img src="https://p0.meituan.net/travelcube/62853fa44bfa47d63143babe3b5a4c6e82532.png" alt="img" style="zoom:67%;" />
>
>![图3 线程池生命周期](https://p0.meituan.net/travelcube/582d1606d57ff99aa0e5f8fc59c7819329028.png)

### 8.线程池==拒绝策略==

>任务拒绝模块是线程池的保护部分，线程池有一个最大的容量，当线程池的任务缓存队列已满，并且线程池中的线程数目达到maximumPoolSize时，就需要拒绝掉该任务，采取任务拒绝策略，保护线程池。
>
>拒绝策略是一个接口，其设计如下：
>
>```Java
>public interface RejectedExecutionHandler {
>    void rejectedExecution(Runnable r, ThreadPoolExecutor executor);
>}
>```
>
>用户可以通过实现这个接口去定制拒绝策略，也可以选择JDK提供的四种已有拒绝策略，其特点如下：
>
>![img](https://p0.meituan.net/travelcube/9ffb64cc4c64c0cb8d38dac01c89c905178456.png)

----------

### 9.线程池为什么有一个阻塞队列

>重点答：生产者消费者模式
>
>任务缓冲模块是线程池能够管理任务的核心部分。线程池的本质是对任务和线程的管理，而做到这一点最关键的思想就是将任务和线程两者解耦，不让两者直接关联，才可以做后续的分配工作。线程池中是以生产者消费者模式，通过一个阻塞队列来实现的。阻塞队列缓存任务，工作线程从阻塞队列中获取任务。
>
>阻塞队列(BlockingQueue)是一个支持两个附加操作的队列。这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。
>
><img src="https://p0.meituan.net/travelcube/725a3db5114d95675f2098c12dc331c3316963.png" alt="img" style="zoom:80%;" />

-----

### 10线程池被创建后里面有线程吗

>线程池被创建后如果没有任务过来，里面是不会有线程的。如果需要预热的话可以调用下面的两
>
>开启一个核心线程采用方法`preStartCoreThread`
>
>开启所有的核心线程方法`ppreStartAllCoreThreads`

-----

### 11核心线程数会被回收吗？

>核心线程数默认是不会被回收的，如果需要回收核心线程数，需要调用下面的方法：
>
>`allowCoreThreadTimeOut(true)` 表示收回核心线程 默认是false

### 11.1 线程池为什么不一开始就创建线程

>1. 线程获取不到task会阻塞在队列上，不会浪费cpu。
>2.  核心线程不会自己退出，阻塞队列为空线程也只是会阻塞在队列上，等待有数据，除非设置了allowCoreThreadTimeOut参数，而这个参数默认是false。
>3. 所以说浪费CPU性能  以及 上下文切换这个说不通   推测可能是内存消耗上
>
>

-----

### 12线程池异常处理

>1. 直接try/catch，个人 基本都是用这种方式
>2. 线程直接重写整个方法:
>3. 也可以直接重写`protected void afterExecute(Runnable r, Throwable t) { }`方法
>
>https://github.com/aCoder2013/blog/issues/3

-----

### 13线程池优化策略 重点

>线程池优化策略：1.非核心线程创建的时机   2. 排队任务调度策略            
>
>存在问题：
>
>1. 非核心线程在队列满时触发创建，在瞬时冲高情况下，队列被占满，但新创建的线程来不及消费等待队列中的任务，新任务被拒绝。
>2. 非核心线程在队列满时触发创建，并执行当前的任务，但队列中的任务依旧处于排队状态。就是非核心线程执行（插入队列失败即将要被丢弃）的任务。
>
>解决方案：
>
>1. Java线程池调度策略一直等到任务队列满才开始创建新线程，这个不是我希望看到的。我们希望的是：可以给等待队列设置一个阈值，一旦触及这个阈值马上创建新的线程，防止任务出现过度堆积。
>2. 换句话说，未达到阈值时，我们认定核心线程有能力消化全部任务；超过阈值时，我们认定核心线程已经无法满足当前的任务请求现状，必须立即创建新的线程消化当前的任务。另外，这个阈值应当是可配置的。
>
>https://www.jianshu.com/p/896b8e18501b



### 14.默认工作行为

>- 不会初始化 corePoolSize 个线程，有任务来了才创建工作线程；
>- 当核心线程满了之后不会立即扩容线程池，而是把任务堆积到工作队列中；
>- 当工作队列满了后扩容线程池，一直到线程个数达到 maximumPoolSize 为止；
>- 如果队列已满且达到了最大线程后还有任务进来，按照拒绝策略处理
>- 当线程数大于核心线程数时，线程等待 keepAliveTime 后还是没有任务需要处理的话，收缩线程到核心线程数。
>
>



# JUC 锁框架

https://segmentfault.com/a/1190000015558984

>![image-20210711173530603](/Users/whig/Library/Application Support/typora-user-images/image-20210711173530603.png)
>
>　1. Condition为接口类型，它将 Object 监视器方法（wait、notify 和 notifyAll）分解成截然不同的对象，以便通过将这些对象与任意 Lock 实现组合使用，为每个对象提供多个等待 set （wait-set）。其中，Lock 替代了 synchronized 方法和语句的使用，Condition 替代了 Object 监视器方法的使用。可以通过await(),signal()来休眠/唤醒线程。
>
>2. Lock为接口类型，Lock``实现提供了比使用synchronized``方法和语句可获得的更广泛的锁定操作。此实现允许更灵活的结构，可以具有差别很大的属性，可以支持多个相关的Condition对象。
>3. ReadWriteLock为接口类型， 维护了一对相关的锁，一个用于只读操作，另一个用于写入操作。只要没有 writer，读取锁可以由多个 reader 线程同时保持。写入锁是独占的。
>4. AbstractQueuedSynchonizer为抽象类，其为实现依赖于先进先出 (FIFO) 等待队列的阻塞锁和相关同步器（信号量、事件，等等）提供一个框架。此类的设计目标是成为依靠单个原子 int 值来表示状态的大多数同步器的一个有用基础。 
>5. LockSupport为常用类，用来创建锁和其他同步类的基本线程阻塞原语。LockSupport的功能和"Thread中的 Thread.suspend()和Thread.resume()有点类似"，LockSupport中的park() 和 unpark() 的作用分别是阻塞线程和解除阻塞线程。但是park()和unpark()不会遇到“Thread.suspend 和 Thread.resume所可能引发的死锁”问题。
>6. Semaphore为常用类，其是一个计数信号量，从概念上讲，信号量维护了一个许可集。如有必要，在许可可用前会阻塞每一个 acquire()，然后再获取该许可。每个 release() 添加一个许可，从而可能释放一个正在阻塞的获取者。但是，不使用实际的许可对象，Semaphore 只对可用许可的号码进行计数，并采取相应的行动。通常用于限制可以访问某些资源（物理或逻辑的）的线程数目。
>7. 　ReentrantLock为常用类，它是一个可重入的互斥锁 Lock，它具有与使用 synchronized 方法和语句所访问的隐式监视器锁相同的一些基本行为和语义，但功能更强大。
>8. ReentrantReadWriteLock是读写锁接口ReadWriteLock的实现类，它包括Lock子类ReadLock和WriteLock。ReadLock是共享锁，WriteLock是独占锁。



# AQS

>java中AQS是AbstractQueuedSynchronizer类，AQS依赖FIFO队列来提供一个框架，这个框架用于实现锁以及锁相关的同步器，比如信号量、事件等。
>
>在AQS中，主要有两部分功能，一部分是操作state变量，第二部分是实现排队和阻塞机制。AQS并没有实现任何同步接口，它只是提供了类似acquireInterruptible的方法，调用这些方法可以实现锁和同步器。
>
>https://www.yisu.com/zixun/457731.html
>
>https://tech.meituan.com/2019/12/05/aqs-theory-and-apply.html

>**抽象队列同步器框架。是一个用来构建锁和同步器的框架,可以说一下里面的一些实现类，自己用到过哪些！**
>Q：某个线程获取锁失败的后续流程是什么呢？

>A：存在某种排队等候机制，线程继续等待，仍然保留获取锁的可能，获取锁流程仍在继续。
>
>Q：既然说到了排队等候机制，那么就一定会有某种队列形成，这样的队列是什么数据结构呢？
>
>A：是CLH变体的FIFO双端队列。
>
>Q：处于排队等候机制中的线程，什么时候可以有机会获取锁呢？
>
>A：可以详细看下2.3.1.3小节。
>
>Q：如果处于排队等候机制中的线程一直无法获取锁，需要一直等待么？还是有别的策略来解决这一问题？
>
>A：线程所在节点的状态会变成取消状态，取消状态的节点会从队列中释放，具体可见2.3.2小节。
>
>Q：Lock函数通过Acquire方法进行加锁，但是具体是如何加锁的呢？
>
>A：AQS的Acquire会调用tryAcquire方法，tryAcquire由各个自定义同步器实现，通过tryAcquire完成加锁过程。





## 公平锁和非公平锁的实现

>总结：公平锁和非公平锁只有两处不同：
>
>线程状态变量： state是否等于0
>
>1. 非公平锁在调用 lock 后，首先就会调用 CAS 进行一次抢锁，如果这个时候恰巧锁没有被占用，那么直接就获取到锁返回了。如果被占有了 那么就是会到队列当中乖乖排队。
>2. 非公平锁在 CAS 失败后，和公平锁一样都会进入到 tryAcquire 方法，在 tryAcquire 方法中，如果发现锁这个时候被释放了（state == 0），非公平锁会直接 CAS 抢锁，但是公平锁会判断等待队列是否有线程处于等待状态，如果有则不去抢锁，乖乖排到后面。
>
>队列是双向链表的阻塞队列
>
>公平锁和非公平锁就这两点区别，如果这两次 CAS 都不成功，那么后面非公平锁和公平锁是一样的，都要进入到阻塞队列等待唤醒。
>
>相对来说，非公平锁会有更好的性能，因为它的吞吐量比较大。当然，非公平锁让获取锁的时间变得更加不确定，可能会导致在阻塞队列中的线程长期处于饥饿状态。





## Lock

>4.Lock锁底层实现
>5.两者区别
>6.Condition底层实现，怎么唤醒等待队列中线程



# synchronized

>1.  jvm层面 :monitorenter moniterexit
>2. 执行过程种锁自动升级
>3. 执行到汇编指令的时候 **lock comxchg   lock保证原子性 comxchg比较并交换不保证原子性**
>
>**synchronized保证原子性、有序性、可见性但是不能禁止指令重排**
>
>**volatile关键字： 保证可见行、但是可以禁止指令重排   不保证原子性** 



## 原子性、可见性、有序性 概念

>**1、原子性**
>
>**即一个操作或者多个操作，要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。原子性就像数据库里面的事务一样，他们是一个团队，同生共死。**
>
>
>
>**2、可见性**
>
>**可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。**
>
>
>
>**3、有序性**
>
>**即程序执行的顺序按照代码的先后顺序执行**。可能会发生**指令重排序**。 一般来说，处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。
>
>------
>
>**在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。**
>
>在Java里面，可以通过volatile关键字来保证一定的“有序性”。**另外可以通过synchronized和Lock来保证有序性**，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。另外，Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before 原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。
>
>下面就来具体介绍下happens-before原则（先行发生原则）：
>
>1. 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作。
>
>2. 锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作。
>
>3. volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作。
>
>4. 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C。
>
>5. 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作。
>
>6. 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生。
>
>7. 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行。
>
>8. 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始。

## synchronized 怎么保证原子性

>java内存模型定义 了一下8中操作来完成 java虚拟机实现时必须保证下面提及的每一种操作都是原子性的、不可在分割的
>
>由原子性变量操作`read,load,use,assign,store,write，`可以**大致认为基本数据类型的访问读写具备原子性**（例外就是long和double的非原子性协定）
>
>上面一共有八条原子操作，其中六条可以满足基本数据类型的访问读写具备原子性，还剩下`lock和unlock`两条原子操作。如果我们需要更大范围的原子性操作就可以使用`lock和unlock`原子操作。尽管jvm没有把lock和unlock开放给我们使用，但jvm以更高层次的指令`monitorenter和monitorexit`指令开放给我们使用，反应到java代码中就是---synchronized关键字，也就是说**synchronized满足原子性**。



## synchronized 修饰方法作用域

>- 修饰实例方法，作用于当前实例加锁，进入同步代码前要获得当前实例的锁   this
>
>- 修饰静态方法，作用于当前类对象加锁，进入同步代码前要获得当前类对象的锁    Object.class
>
>- 修饰代码块，指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。还可以在一类中 synchronized(this)  锁主的是次类实例对象





## ==synchronized jvm层级底层实现==

>1. 同步用的最多的地方可能是被 synchronized 修饰的同步方法。同步代码块 并不是由 monitorenter 和 monitorexit 指令来实现同步的，而是由方法调用指令读取运行时常量池中方法的 **ACC_SYNCHRONIZED **标志来隐式实现的
>
>2. 当方法调用时，调用指令将会 检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，进入同步代码前要获得当前实例的锁 执行线程将先持有当前实例monitor（虚拟机规范中用的是管程一词）， 然后再执行方法，最后再方法完成(无论是正常完成还是非正常完成)时释放monitor。在方法执行期间，执行线程持有了monitor，其他任何线程都无法再获得同一个monitor。如果一个同步方法执行期间抛 出了异常，并且在方法内部无法处理此异常，那这个同步方法所持有的monitor将在异常抛到同步方法之外时自动释放
>
>3. monitor是由ObjectMonitor(c++)实现的，两个特别重要的队列 一个是**等待队列** 一个是**同步队列 **。每个等待锁的线程都会被封装成ObjectWaiter对象，当多个线程同时访问一段同步代码时，首先会进入 同步队列，当线程获取到对象的monitor 后进入 _Owner 区域并把monitor中的owner变量设置为当前线程，同时monitor中的计数器count加1，若线程调用 wait() 方法，将释放当前持有的monitor，owner变量恢复为null，count自减1，同时该线程进入 WaitSe t集合中等待被唤醒。若当前线程执行完毕也将释放monitor(锁)并复位变量的值，以便其他线程进入获取monitor(锁)。
>
>4. monitor对象存在于每个Java对象的对象头中(存储的指针的指向)，synchronized锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因



## synchronized 四种锁升级状态

https://www.nowcoder.com/discuss/604631?type=5&channel=1009&source_id=discuss_center_discuss_jinghua_nctrack

><img src="https://img-blog.csdnimg.cn/20200603161323889.png" alt="在这里插入图片描述" style="zoom:80%;" />
>
>锁对比  使用场景
>
>| 锁       | 优点                                                         | 缺点                                           | 适用场景                           |
>| -------- | ------------------------------------------------------------ | ---------------------------------------------- | ---------------------------------- |
>| 偏向锁   | 加锁和解锁不需要额外的消耗，和执行非同步方法相比仅存在纳秒级的差距 | 如果线程间存在锁竞争，会带来额外的锁撤销的消耗 | 适用于只有一个线程访问同步块场景   |
>| 轻量级锁 | 竞争的线程不会阻塞，提高了程序的响应速度                     | 如果始终得不到索竞争的线程，使用自旋会消耗CPU  | 追求响应速度，同步块执行速度非常快 |
>| 重量级锁 | 线程竞争不使用自旋，不会消耗CPU                              | 线程阻塞，响应时间缓慢                         | 追求吞吐量，同步块执行速度较慢     |
>
>----
>
>1. 无锁：无锁是指没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。无锁的特点是修改操作会在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。
>2. 偏向锁：**锁不仅不存在多线程竞争，而且总是由同一线程多次获得**。初次执行到synchronized代码块的时候，锁对象变成偏向锁（通过CAS修改对象头里的锁标志位）。执行完同步代码块后，线程并不会主动释放偏向锁。当第二次到达同步代码块时，线程会判断此时持有锁的线程是否就是自己（持有锁的线程ID也在对象头里）因此为了减少同一线程获取锁(会涉及到一些CAS操作,耗时)的代价而引入偏向锁             
>
>3. 轻量级锁）：**轻量级锁是指当锁是偏向锁的时候，却被另外的线程所访问，此时偏向锁就会升级为轻量级锁**。在轻量级锁状态下继续锁竞争，**轻量级锁 CAS 失败并不会自旋而是直接膨胀成重量级锁**。  
>4. 重量级锁： 线程如果没有争抢到锁，会进行一段自旋等待锁的释放。 如果锁竞争情况严重，某个达到最大自旋次数的线程（默认是十次），当后续线程尝试获取锁时，发现被占用的锁是重量级锁，则直接将自己挂起（而不是忙等），等待将来被唤醒。重量级锁是指当有一个线程获取锁之后，其余所有等待获取该锁的线程都会处于阻塞状态。简言之，就是所有的控制权都交给了操作系统，由操作系统来负责线程间的调度和线程的状态变更。而这样会出现频繁地对线程运行状态的切换，线程的挂起和唤醒，从而消耗大量的系统资
>
>![img](https://img-blog.csdnimg.cn/20200606113746579.png)



## synchronized 可重入吗，怎么实现的 

>可重入：
>
>1. 每个锁关联一个线程持有者（onwer变量设置当前线程）和一个计数器（monitior）。
>2. 当计数器为0时表示该锁没有被任何线程持有，那么任何线程都都可能获得该锁而调用相应方法。当一个线程请求成功后，JVM会记下持有锁的线程，并将计数器计为1。此时其他线程请求该锁，则必须等待。
>3. 而该持有锁的线程如果再次请求这个锁，就可以再次拿到这个锁，同时计数器会递增。当线程退出一个synchronized方法/块时，计数器会递减，如果计数器为0则释放该锁。





## synchronized 锁字符串

>首先字符串操作
>
>```java
>String a=”abc”;  //先在常量池中查找是否有”abc”对象，如果有则创建对象a并指向这个对象，如果没有则先在常量池中创建”abc”对象，然后创建对象a并指向这个对象。
>```
>
>```java
>String a=new String("abc");//先在常量池中查找是否有”abc”对象，如果有则把常量池中的对象复制一份，然后创建对象a并指向复制出来的这个对象，如果没有则先在常量池中创建”abc”对象，然后复制一份，然后创建对象a并指向复制出来的这个对象。
>//最终a不是指向常量池的。而且在第一次使用该字符串时，内存里存了两个这个字符串的对象，一个在堆里一个在常量池里。
>```
>
>如果在常量池中那么就是指定的唯一对象 不会出现异步状态。
>
>如果出现在堆中 可以出现异步状态  `s.intern()`方法来把这个字符串放到常量池当中



## ==synchronized 和 volatile 的区别是什么？==

> synchronized 表示只有一个线程可以获取作用对象的锁，执行代码，阻塞其他线程。
>
> volatile 表示变量在 CPU 的寄存器中是不确定的，必须从主存中读取。保证多线程环境下变量的可见性；禁止指令重排序。
>
> **区别**
>
> - volatile 是变量修饰符；synchronized 可以修饰类、方法、变量。
> - volatile 仅能实现变量的修改可见性，不能保证原子性；而 synchronized 则可以保证变量的修改可见性和原子性。
> - volatile 不会造成线程的阻塞；synchronized 可能会造成线程的阻塞。
> - volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化。
> - **volatile关键字**是线程同步的**轻量级实现**，所以**volatile性能肯定比synchronized关键字要好**。但是**volatile关键字只能用于变量而synchronized关键字可以修饰方法以及代码块**。synchronized关键字在JavaSE1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其它各种优化之后执行效率有了显著提升，**实际开发中使用 synchronized 关键字的场景还是更多一些**。



## ==Synchronized和Lock的区别==

>**Synchronized和Lock的区别：Synchronized编码更简单，锁机制由JVM维护，在竞争不激烈的情况下性能更好。Lock功能更强大更灵活，竞争激烈时性能较好。**
>
>1. 性能不一样：资源竞争激励的情况下，lock性能会比synchronize好，竞争不激励的情况下，synchronize比lock性能好，synchronize会根据锁的竞争情况，从偏向锁-->轻量级锁-->重量级锁升级，而且编程更简单。
>2. 锁机制不一样：synchronize是在JVM层面实现的，系统会监控锁的释放与否。lock是JDK代码实现的，需要手动释放，在finally块中释放。可以采用非阻塞的方式获取锁。
>3. Synchronized的编程更简洁，lock的功能更多更灵活，缺点是一定要在finally里面 unlock()资源才行。
>4. 用法不一样：synchronize可以用在代码块上，方法上。lock只能写在代码里，不能直接修改方法。
>
>-------
>
>**Lock支持的功能:**
>
>- 公平锁：Synchronized是非公平锁，Lock支持公平锁，默认非公平锁
>- 可中断锁：ReentrantLock提供了lockInterruptibly（）的功能，可以中断争夺锁的操作，抢锁的时候会check是否被中断，中断直接抛出异常，退出抢锁。而Synchronized只有抢锁的过程，不可干预，直到抢到锁以后，才可以编码控制锁的释放。
>- 快速反馈锁：ReentrantLock提供了trylock（）  和 trylock（tryTimes）的功能，不等待或者限定时间等待获取锁，更灵活。可以避免死锁的发生。
>- 读写锁：ReentrantReadWriteLock类实现了读写锁的功能，类似于Mysql，锁自身维护一个计数器，读锁可以并发的获取，写锁只能独占。而synchronized全是独占锁
>- Condition：ReentrantLock提供了比Sync更精准的线程调度工具，Condition，一个lock可以有多个Condition，比如在生产消费的业务下，一个锁通过控制生产Condition和消费Condition精准控制。

# volatile 

>`volatile` 关键字来保证**可见性和禁止指令重排**。 `volatile `提供 `happens-before `的保证，确保一个线程的修改能对其他线程是可见的。当一个共享变量被 `volatile` 修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。
>
>从实践角度而言，volatile 的一个重要作用就是和 CAS 结合，保证了原子性.





## Volatile是怎么实现可见性、禁止指令重排 

>**虚拟机层方面**：
>
>字节码： `ACC_VOLATILE`   **volatile修饰成员变量 保证线程的可见性、禁止指令重排优化**
>
>**虚拟机规范指令**：1.  LoadLoad屏障   Load1,LoadLoad,Load2   读取操作屏障 保证Load1读取完之后Load2才能够读取被就是
>						 	  2.  StoreStore屏障 Store1,StoreoStore,Store2 在Store2及后续写入操作之前 保证Store1的写入操作对其他处理器可见
>			 				  3.  LoadStore屏障  Load1,LoadStore,Store2    在Store2及后续写入操作被删除钱，保证Load1的去读操作完毕
>			  				 4.  StoreLoad屏障  Store1,LoadStore,Load     在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见
>
>- **可见性 内存屏障来实现的**
>
>**写屏障（sfence）保证在该屏障之前的，对共享变量的改动，都同步到主存当中 并通知其他线程**
>
>**而读屏障（lfence）保证在该屏障之后，对共享变量的读取，加载的是主存中最新数据**
>
>- 有序性
>
>写屏障会确保指令重排序时，不会将写屏障之前的代码排在写屏障之后
>
>读屏障会确保指令重排序时，不会将读屏障之后的代码排在读屏障之前
>
>----
>
>**底层操作系统方面：**
>
>volatile保证了修饰的共享变量在转换为汇编语言时，会加上一个以lock为前缀的指令，当CPU发现这个指令时，立即会做两件事情：
>
>1. 将当前内核高速缓存行的数据立刻回写到内存；
>2. 使在其他内核里缓存了该内存地址的数据无效。

## Volatile为什么不能保证原子性

>简单的说，修改volatile变量分为四步：
>
>1. 读取volatile变量到local   主内存到工作内存
>2. 修改变量值
>3. local值写回工作内存
>4. 插入内存屏障，即lock指令，让其他线程可见
>
>这样就很容易看出来，前三步都是不安全的，取值和写回之间，不能保证没有其他线程修改。原子性需要锁来保证。



>1. volatile 的特性?
>2. 一个 volatile 变量,一个线程写,多个线程读会不会出现线程不安全的问题?
>3. VOLATILE机制，可见性是什么，get操作需不需要加锁和synchronized底层实现原理及锁优化
>4. 讲讲volatile(可见性怎么保证，有序性怎么保证，内存屏障LL，LR，RR，RL，CPU缓存行，lock汇编指令)
>5. Volatile是怎么实现可见性的 
>6. volitle关键字什么作用，一般什么时候用，用了就线程安全嘛？







# CAS

>　　在Java中，悲观锁的实现方式就是各种锁；而乐观锁则是通过CAS实现的。
>
>　　CAS（Compare And Swap，比较交换）：CAS有三个操作数，内存值V、预期值A、要修改的新值B，当且仅当A和V相等时才会将V修改为B，否则什么都不做。Java中CAS操作通过JNI本地方法实现，在JVM中程序会根据当前处理器的类型来决定是否为cmpxchg指令添加lock前缀。如果程序是在多处理器上运行，就为cmpxchg指令加上lock前缀（Lock Cmpxchg）；反之，如果程序是在单处理器上运行，就省略lock前缀。
>
>　　Intel的手册对lock前缀的说明如下：
>
>　　确保对内存的读-改-写操作原子执行。之前采用锁定总线的方式，但开销很大；后来改用缓存锁定来保证指令执行的原子性。
>　　禁止该指令与之前和之后的读和写指令重排序。
>　　把写缓冲区中的所有数据刷新到内存中。
>　　CAS同时具有volatile读和volatile写的内存语义。
>
>　　不过CAS操作也存在一些缺点：1. 存在ABA问题，其解决思路是使用版本号；2. 循环时间长，开销大；3. 只能保证一个共享变量的原子操作。
>
>> 你在上面提到CAS是什么？自旋又是什么？
>
>CAS 是乐观锁的一种实现方式，是一种轻量级锁，JUC 中很多工具类的实现就是基于 CAS 的。
>
>CAS 操作的流程如下图所示，线程在读取数据时不进行加锁，在准备写回数据时，比较原值是否修改，若未被其他线程修改则写回，若已被修改，则重新执行读取流程。
>
>这是一种乐观策略，认为并发操作并不总会发生。
>
>> CAS就一定能保证数据没被别的线程修改过么？
>
>并不是的，比如很经典的ABA问题，CAS就无法判断了。



## 什么是ABA？那怎么解决ABA问题？

>- 什么是ABA？
>
>就是说来了一个线程把值改回了B，又来了一个线程把值又改回了A，对于这个时候判断的线程，就发现他的值还是A，所以他就不知道这个值到底有没有被人改过，其实很多场景如果只追求最后结果正确，这是没关系的。
>
>但是实际过程中还是需要记录修改过程的，比如资金修改什么的，你每次修改的都应该有记录，方便回溯。
>
>> 那怎么解决ABA问题？ 版本号
>
>用版本号去保证就好了，就比如说，我在修改前去查询他原来的值的时候再带一个版本号，每次判断就连值和版本号一起判断，判断成功就给版本号加1。 类似于MVVC
>
>```sql
>update a set value = newValue ，vision = vision + 1 where value = #{oldValue} and vision = #{vision} // 判断原来的值和版本号是否匹配，中间有别的线程修改，值可能相等，但是版本号100%不一样
>复制代码
>```
>
>> 除了版本号还有别的方法保证么？ 时间戳方法
>
>其实有很多方式，比如时间戳也可以，查询的时候把时间戳一起查出来，对的上才修改并且更新值的时候一起修改更新时间，这样也能保证，方法很多但是跟版本号都是异曲同工之妙，看场景大家想怎么设计吧。



# Java中锁类型

## 公平锁/非公平锁

>公平锁是指多个线程按照申请锁的顺序来获取锁。
>非公平锁是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁。有可能，会造成优先级反转或者饥饿现象。
>对于Java `ReentrantLock`而言，通过构造函数指定该锁是否是公平锁，默认是非公平锁。非公平锁的优点在于吞吐量比公平锁大。
>对于`Synchronized`而言，也是一种非公平锁。由于其并不像`ReentrantLock`是通过AQS的来实现线程调度，所以并没有任何办法使其变成公平锁。



## 可重入锁

>可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁。说的有点抽象，下面会有一个代码的示例。
>对于Java `ReentrantLock`而言, 他的名字就可以看出是一个可重入锁，其名字是`Re entrant Lock`重新进入锁。
>对于`Synchronized`而言,也是一个可重入锁。可重入锁的一个好处是可一定程度避免死锁。



## 独享锁/共享锁

>独享锁是指该锁一次只能被一个线程所持有。
>共享锁是指该锁可被多个线程所持有。
>
>对于Java `ReentrantLock`而言，其是独享锁。但是对于Lock的另一个实现类`ReadWriteLock`，其读锁是共享锁，其写锁是独享锁。
>读锁的共享锁可保证并发读是非常高效的，读写，写读 ，写写的过程是互斥的。
>独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。
>对于`Synchronized`而言，当然是独享锁。



## ==乐观锁/悲观锁==

>1. 乐观锁与悲观锁不是指具体的什么类型的锁，而是指看待并发同步的角度。
>2. 悲观锁认为对于同一个数据的并发操作，一定是会发生修改的，哪怕没有修改，也会认为修改。因此对于同一个数据的并发操作，悲观锁采取加锁的形式。悲观的认为，不加锁的并发操作一定会出问题。**适用于写多读少的场景**
>3. 乐观锁则认为对于同一个数据的并发操作，是不会发生修改的。在更新数据的时候，会采用尝试更新，不断重新的方式更新数据。乐观的认为，不加锁的并发操作是没有事情的，**适用于读多写少的场景**
>
>从上面的描述我们可以看出，悲观锁适合写操作非常多的场景，乐观锁适合读操作非常多的场景，不加锁会带来大量的性能提升。
>悲观锁在Java中的使用，就是利用各种锁。
>乐观锁在Java中的使用，是无锁编程，常常采用的是CAS算法，典型的例子就是原子类，通过CAS自旋实现原子操作的更新。



## 分段锁

>分段锁其实是一种锁的设计，并不是具体的一种锁，对于`ConcurrentHashMap`而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。
>我们以`ConcurrentHashMap`来说一下分段锁的含义以及设计思想，`ConcurrentHashMap`中的分段锁称为Segment，它即类似于HashMap（JDK7与JDK8中HashMap的实现）的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是一个ReentrantLock（Segment继承了ReentrantLock)。
>当需要put元素的时候，并不是对整个hashmap进行加锁，而是先通过hashcode来知道他要放在那一个分段中，然后对这个分段进行加锁，所以当多线程put的时候，只要不是放在一个分段中，就实现了真正的并行的插入。
>但是，在统计size的时候，可就是获取hashmap全局信息的时候，就需要获取所有的分段锁才能统计。
>分段锁的设计目的是细化锁的粒度，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作。



## 偏向锁/轻量级锁/重量级锁

>这三种锁是指锁的状态，并且是针对`Synchronized`。在Java 5通过引入锁升级的机制来实现高效`Synchronized`。这三种锁的状态是通过对象监视器在对象头中的字段来表明的。
>偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。降低获取锁的代价。
>轻量级锁是指当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。
>重量级锁是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取到锁，就会进入阻塞，该锁膨胀为重量级锁。重量级锁会让其他申请的线程进入阻塞，性能降低。



## 自旋锁

>在Java中，自旋锁是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU。





## 死锁

>死锁是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。竞争的资源可以是：锁、网络连接、磁盘共享变量等一切可以称作是 【资源】的东西。
>
>解决方案：
>
>1. 该指令可以生成虚拟机当前时刻的线程快照。线程快照是当前每一条线程正在执行的方法对战的集合，主要目的是定位线程出现长时间停顿的原因，比如 `线程间死锁`、`死循环`、`请求外部资源导致的长时间等待`等。
>2. 超时放弃：当线程获取锁超时了则放弃，这样就避免了出现死锁获取的情况。当使用synchronized关键词提供的内置锁时，只要线程没有获得锁，那么就会永远等待下去，然而Lock接口提供了`boolean tryLock(long time, TimeUnit unit) throws InterruptedException`方法，该方法可以按照固定时长等待锁，因此线程可以在获取锁超时以后，主动释放之前已经获得的所有的锁。通过这种方式，也可以很有效地避免死锁。





# Threadlocal 机制

## Threadlocal原理

>![preview](https://pic2.zhimg.com/v2-45affd67cf3dfb5637878d8f46ea5061_r.jpg)
>
>`ThreadLocal`的实现是这样的：每个`Thread` 维护一个 `ThreadLocalMap` 映射表，这个映射表的 `key`是 `ThreadLocal` 实例本身，`value` 是真正需要存储的 `Object`。
>
>也就是说 `ThreadLocal` 本身并不存储值，它只是作为一个 `key` 来让线程从 `ThreadLocalMap` 获取 `value`。值得注意的是图中的虚线，表示 `ThreadLocalMap` 是使用 `ThreadLocal` 的弱引用作为 `Key`的，弱引用的对象在 GC 时会被回收。

## ==`ThreadLocal` 使用弱引用 为什么还会内存泄漏==

>1. 只有 `key Threadlocal`是弱引用 例如`Entry节点`和 `value`本身还是强引用 。如果引用没有释放 还是可能造成内存泄漏。
>
>`ThreadLocalMap`使用`ThreadLocal`的弱引用作为`key`，如果一个`ThreadLocal`没有外部强引用来引用它，那么系统 GC 的时候，这个`ThreadLocal`势必会被回收，这样一来，`ThreadLocalMap`中就会出现`key`为`null`的`Entry`，就没有办法访问这些`key`为`null`的`Entry`的`value`，如果当前线程再迟迟不结束的话，这些`key`为`null`的`Entry`的`value`就会一直存在一条强引用链：`Thread Ref -> Thread -> ThreaLocalMap -> Entry -> value`永远无法回收，造成内存泄漏。
>
>内部源码上也加上了一些防护措施：在`ThreadLocal`的`get()`,`set()`,`remove()`的时候都会清除线程`ThreadLocalMap`里所有`key`为`null`的`value`。
>
>但是这些被动的预防措施并不能保证不会内存泄漏：
>
>- 使用`static`的`ThreadLocal`，延长了`ThreadLocal`的生命周期，可能导致的内存泄漏
>- 分配使用了`ThreadLocal`又不再调用`get()`,`set()`,`remove()`方法，那么就会导致内存泄漏。



## 为什么key使用弱引用

>下面我们分两种情况讨论：
>
>- **key 使用强引用**：引用的`ThreadLocal`的对象被回收了，但是`ThreadLocalMap`还持有`ThreadLocal`的强引用，如果没有手动删除，`ThreadLocal`不会被回收，导致`Entry`内存泄漏。
>- **key 使用弱引用**：引用的`ThreadLocal`的对象被回收了，由于`ThreadLocalMap`持有`ThreadLocal`的弱引用，即使没有手动删除，`ThreadLocal`也会被回收。`value`在下一次`ThreadLocalMap`调用`set`,`get`，`remove`的时候会被清除。
>
>由于`ThreadLocalMap`的生命周期跟`Thread`一样长，如果都没有手动删除对应`key`，都会导致内存泄漏，但是使用弱引用可以多一层保障：**弱引用`ThreadLocal`不会内存泄漏，对应的`value`在下一次`ThreadLocalMap`调用`set`,`get`,`remove`的时候会被清除**。
>
>因此，`ThreadLocal`内存泄漏的根源是：由于`ThreadLocalMap`的生命周期跟`Thread`一样长，如果没有手动删除对应`key`就会导致内存泄漏，而不是因为弱引用。



## 为什么 Entry和 Value 不使用弱引用

>**value 不设置为弱引用，是因为不清楚这个`Value`除了`map`的引用还是否还存在其他引用，如果不存在其他引用，当`GC`的时候就会直接将这个Value干掉了，而此时我们的`ThreadLocal`还处于使用期间，就会造成Value为null的错误，所以将其设置为强引用。」**
>
>而为了解决这个强引用的问题，它提供了一种机制就是上面我们说的将`Key`为`Null`的`Entity`直接清除

## 怎么实现每个线程变量隔离的

>ThreadLocal通过包装这个ThreadLocalMap，为线程开辟一块变量存放区的功能，实现了变量在线程间隔离
>
>因为get方法的第一步就是从`Thread.currentThread()`中获取该线程的ThreadLocalMap，再从ThreadLocalMap中获取value的，隔离性显然是可以保证的

## ThreadLocalMap 与 HashMap区别

>1. ThreadLocalMap对象保存在对应的线程即Thread对象，根据Java内存模型，每个线程有自己对应的工作内存，线程无法访问其他线程的工作内存
>
>2. ThreadLocalMap结构类似HashMap，有一个Entry数组，也会在threshold扩容，也有哈希碰撞和解决方案
>
>3. 与HashMap最大的不同是，这个Map的Entry并非常规的包含key和value两个属性
>
>- Entry继承`WeakReference<ThreadLocal<?>>`即弱引用，将弱引用的真正引用对象即ThreadLocal对象当作普通Entry中的key，也就是说使用时通过`entry.get()即获取弱引用指向的对象，并计算equals的结果
>- Entry包含一个`Object value`属性，保存对应的变量
>
>4. **哈希算法 ： ** `HashMap`中采用的是高16位和低16位进行异或 把高位的特性保留在了低位当中。  `ThreadLocalMap`  hash算法是对数组取模操作
>5. **hash冲突**： `HashMap` 采用数组加红黑树的方式 链式解决hash冲突     `ThreadLocalMap`  采用开放地址方当中的线性探测。



## ==4种引用==

>- **强引用(StrongReference)**
>
>强引用不会被GC回收，例如Object  obj=new Object()    这里的obj引用便是一个强引用，不会被GC垃圾回收。
>
>- **软引用(SoftReference)**
>
>被软引用的对象，如果内存空间足够，垃圾回收期是不会回收他的，如果内存空间不足，垃圾回收期就回收这些对象占用的内存空间。软引用对象的是
>
>ava.lang.ref.SoftReference类，一个对象如果需要软引用，只需将其参数传入构造SoftReference类的构造函数当中就即可.
>
>**软引用在JVM报告内存不足的时候才会被GC回收，否则不回收，正是由于这种特性，软引用在caching中用处广泛**
>
>- **弱引用 WeakReference**
>
>弱引用用来描述那些非必须对象，比软引用的强度还更弱一些，当垃圾回收器开始工作时候，无论当前内存是否足够，都会回收有关弱引用的对象
>
>- **虚引用**
>
>**虚引用唯一目的：为了能在这个对象被收集器回收的时候收到系统通知被**
>
>1. 例如：**DirectByteBuffer**   直接内存也称为堆外内存 例如NIO提供了一种直接内存管理 ，  jvm堆上要管理操作系统的内存，这时候就不用重操作系内存中拷贝一边到jvm 堆上  称之为**ZeroCopy**      heap堆上会有一个对象来代表那块直接内存。
>
>2. **jdk1.4 NIO类，引入了一种基于通道(Channel)与缓冲区（Buffer）的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过在java堆里边存储一个DirectByteBuffer对象作为这块内存的引用进行操作，当回收时：在垃圾回收器里边有一个垃圾线程专门监听堆外内存的对象，在DirectByteBuffer上加一个虚引用，当这个对象不需要时进行回收的时候，通过虚引用，将这个对象的某一个信息会加入到队列当中，垃圾回收监听这个队列，如果存在信息，就说明某一个DirectByteBuffer对象就被回收了，然后清理堆外内存  。  假如这里DirectByteBuffer直接交给jvm垃圾回收器管理  直接内存和跟外部不存在虚引用 当垃圾回收的时候就会发生内存泄漏 **
>
>3. 所以虚引用就是关键目的就是为了清理堆外内存 DirectByteBuffer  管理堆外内存



## ThreadLocal应用场景

>- **场景一：代替参数的显式传递**
>
>当我们在写API接口的时候，通常Controller层会接受来自前端的入参，当这个接口功能比较复杂的时候，可能我们调用的Service层内部还调用了 很多其他的很多方法，通常情况下，我们会在每个调用的方法上加上需要传递的参数。
>
>但是如果我们将参数存入ThreadLocal中，那么就不用显式的传递参数了，而是只需要ThreadLocal中获取即可。
>
>这个场景其实使用的比较少，一方面显式传参比较容易理解，另一方面我们可以将多个参数封装为对象去传递。
>
>- **场景二：全局存储用户信息**
>
>在现在的系统设计中，前后端分离已基本成为常态，分离之后如何获取用户信息就成了一件麻烦事，通常在用户登录后， 用户信息会保存在Session或者Token中。这个时候，我们如果使用常规的手段去获取用户信息会很费劲，拿Session来说，我们要在接口参数中加上HttpServletRequest对象，然后调用 getSession方法，且每一个需要用户信息的接口都要加上这个参数，才能获取Session，这样实现就很麻烦了。
>
>在实际的系统设计中，我们肯定不会采用上面所说的这种方式，而是使用ThreadLocal，我们会选择在拦截器的业务中， 获取到保存的用户信息，然后存入ThreadLocal，那么当前线程在任何地方如果需要拿到用户信息都可以使用ThreadLocal的get()方法 (异步程序中ThreadLocal是不可靠的)
>
>对于笔者而言，这个场景使用的比较多，当用户登录后，会将用户信息存入Token中返回前端，当用户调用需要授权的接口时，需要在header中携带 Token，然后拦截器中解析Token，获取用户信息，调用自定义的类(AuthNHolder)存入ThreadLocal中，当请求结束的时候，将ThreadLocal存储数据清空， 中间的过程无需在关注如何获取用户信息，只需要使用工具类的get方法即可。
>
>-------
>
>
>
>- **场景三：解决线程安全问题**
>
>1. web容器本身就是**多线程**的，**每一个HTTP请求都会产生一个独立的线程**（或者从线程池中取得创建好的线程）；
>2. Spring中的bean（用@Repository、@Service、@Component和@Controller注册的bean）都是**单例**的，即整个程序、所有线程**共享一个实例**；但是在这里我们就是可以使用@Scope("proptype")来实现机制
>
>在Spring的Web项目中，我们通常会将业务分为Controller层，Service层，Dao层， 我们都知道@Autowired注解默认使用单例模式，那么不同请求线程进来之后，由于Dao层使用单例，那么负责数据库连接的Connection也只有一个， 如果每个请求线程都去连接数据库，那么就会造成线程不安全的问题？
>
>其解决方案就是采用ThreadLocal方法，当每个请求线程使用Connection的时候， 都会从ThreadLocal获取一次，如果为null，说明没有进行过数据库连接，连接后存入ThreadLocal中，如此一来，每一个请求线程都保存有一份 自己的Connection。于是便解决了线程安全问题
>
>ThreadLocal在设计之初就是为解决并发问题而提供一种方案，每个线程维护一份自己的数据，达到线程隔离的效果。



## Java中会出现内存泄露吗？

>内存泄漏是指不再被使用的对象或者变量一直被占据在内存中。
>虽然java中有垃圾回收机制，它能够将不再被使用的对象，自动从内存中清除。即使这样，java中也存在着内存泄漏的情况：
>
>1. 当长生命周期的对象持有短生命周期的对象的引用，就很可能发生内存泄漏。尽管短生命周期的对象已经不再需要，但是长生命周期的对象一直持有它的引用导致其无法被回收。例如，缓存系统；加载一个对象放在缓存系统中，一直不去使用这个对象，但是它一直被缓存引用，所以不会被回收导致缓存泄漏。
>2. 各种连接
>     比如数据库连接（dataSourse.getConnection()），网络连接(socket)和io连接，除非其显式的调用了其close（）方法将其连接关闭，否则是不会自动被GC 回收的。对于Resultset 和Statement 对象可以不进行显式回收，但Connection 一定要显式回收，因为Connection 在任何时候都无法自动回收，而Connection一旦回收，Resultset 和Statement 对象就会立即为NULL。但是如果使用连接池，情况就不一样了，除了要显式地关闭连接，还必须显式地关闭Resultset Statement 对象（关闭其中一个，另外一个也会关闭），否则就会造成大量的Statement 对象无法释放，从而引起内存泄漏。这种情况下一般都会在try里面去的连接，在finally里面释放连接
>3. 特别注意一些像HashMap、ArrayList的集合对象，它们经常会引发内存泄漏。当它们被声明为static时，它们的生命周期就会和应用程序一样长。
>     如果单例对象持有外部对象的引用，那么这个外部对象将不能被jvm正常回收，导致内存泄露。



# IO

## 同步、异步

>一个IO操作其实分成了两个步骤：**发起IO请求和实际的IO操作。 **  **阻塞和非阻塞对应用程序来说 阻塞：调用一个程序没有结果就一直等待  这段期间不能做其他任务   非阻塞：这段区间可以返回做其他任务**   **同步异步：对操作系统来说 同步把这个事（读取文件）做完告诉程序   异步就是我开始做了 **
>
>**同步IO和异步IO的区别就在于第二个步骤是否阻塞，如果实际的IO读写阻塞请求进程，那么就是同步IO。 **
>**阻塞IO和非阻塞IO的区别在于第一步，发起IO请求是否会被阻塞，如果阻塞直到完成那么就是传统的阻塞IO，如果不阻塞，那么就是非阻塞IO。** 
>
>同步和异步是针对应用程序和内核的交互而言的，同步指的是用户进程触发IO操作并等待或者轮询的去查看IO操作是否就绪，而异步是指用户进程触发IO操作以后便开始做自己的事情，而当IO操作已经完成的时候会得到IO完成的通知。而阻塞和非阻塞是针对于进程在访问数据的时候，根据IO操作的就绪状态来采取的不同方式，说白了是一种读取或者写入操作函数的实现方式，阻塞方式下读取或者写入函数将一直等待，而非阻塞方式下，读取或者写入函数会立即返回一个状态值。 
>所以,IO操作可以分为3类：同步阻塞（即早期的BIO操作）、同步非阻塞（NIO）、异步非阻塞（AIO）。 
>
>- 同步阻塞(BIO)： **阻塞式、面向流、线程多、性能差**  
>  在此种方式下，用户进程在发起一个IO操作以后，必须等待IO操作的完成，只有当真正完成了IO操作以后，用户进程才能运行。JAVA传统的IO模型属于此种方式。 **影响BIIO，客户端延时，网络延时，服务器延时**
>
>- 同步非阻塞(NIO)：**非阻塞式、面向管道、线程少、性能高**
>  在此种方式下，用户进程发起一个IO操作以后便可返回做其它事情，但是用户进程需要时不时的询问IO操作是否就绪，这就要求用户进程不停的去询问，从而引入不必要的CPU资源浪费。其中目前JAVA的NIO就属于同步非阻塞IO。 **影响NIO，服务器延时**
>- 异步非阻塞(AIO)：
>
>​      此种方式下是指应用发起一个IO操作以后，不等待内核IO操作的完成，等内核完成IO操作以后会通知应用程序。





## BIO NIO AIO

>#### BIO
>
>BIO全称是Blocking IO，是JDK1.4之前的传统IO模型，本身是同步阻塞模式。 **线程发起IO请求后，一直阻塞IO，直到缓冲区数据就绪后，再进入下一步操作。针对网络通信都是一请求一应答的方式,一个请求、一个线程**，虽然简化了上层的应用开发，但在性能和可靠性方面存在着巨大瓶颈，试想一下如果每个请求都需要新建一个线程来专门处理，那么在高并发的场景下，机器资源很快就会被耗尽。  
>
>#### NIO
>
>NIO也叫Non-Blocking IO 是同步非阻塞的IO模型。线程发起io请求后，立即返回（非阻塞io）。同步指的是必须等待IO缓冲区内的数据就绪，而非阻塞指的是，用户线程不原地等待IO缓冲区，可以先做一些其他操作，但是要定时轮询检查IO缓冲区数据是否就绪。Java中的NIO 是new IO的意思。其实是NIO加上IO多路复用技术。普通的NIO是线程轮询查看一个IO缓冲区是否就绪，而Java中的new IO指的是线程轮询地去查看一堆IO缓冲区中哪些就绪，这是一种IO多路复用的思想。IO多路复用模型中，将检查IO数据是否就绪的任务，交给系统级别的select或epoll模型，由系统进行监控，减轻用户线程负担。
>
>NIO主要有buffer、channel、selector三种技术的整合，通过零拷贝的buffer取得数据，每一个客户端通过channel在selector（多路复用器）上进行注册。服务端不断轮询channel来获取客户端的信息。channel上有connect,accept（阻塞）、read（可读）、write(可写)四种状态标识。根据标识来进行后续操作。所以一个服务端可接收无限多的channel。不需要新开一个线程。大大提升了性能。**多个请求一个线程**
>
>#### AIO
>
>AIO是真正意义上的异步非阻塞IO模型。 上述NIO实现中，需要用户线程定时轮询，去检查IO缓冲区数据是否就绪，占用应用程序线程资源，其实轮询相当于还是阻塞的，并非真正解放当前线程，因为它还是需要去查询哪些IO就绪。而真正的理想的异步非阻塞IO应该让内核系统完成，用户线程只需要告诉内核，当缓冲区就绪后，通知我或者执行我交给你的回调函数。
>
>AIO可以做到真正的异步的操作，但实现起来比较复杂，支持纯异步IO的操作系统非常少，目前也就windows是IOCP技术实现了，而在Linux上，底层还是是使用的epoll实现的。



## JAVA NIO 实现

>基于通道和缓冲区的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆DirectByteBuffer对象作为这块内存的引用进行操作，避免了在Java堆和Native堆中来回复制数据。
>
>NIO是一种同步非阻塞的IO模型,所以也可以叫NON-BLOCKINGIO。同步是指线程不断轮询IO事件是否就绪，非阻塞是指线程在等待IO的时候，可以同时做其他任务。同步的核心就Selector,Selector代替了线程本身轮询IO事件，避免了阻塞同时减少了不必要的线程消耗；非阻塞的核心就是通道和缓冲区，当IO事件就绪时，可以通过写到缓冲区，保证IO的成功，而无需线程阻塞式地等待。
>
>### 1.2 Java NIO的原理
>
>由一个专门的线程处理所有IO事件，并负责分发。事件驱动机制，事件到来的时候触发操作，不需要阻塞的监视事件。线程之前通过wait,notify通信，减少线程切换。
>
>NIO主要有三大核心部分：Channel(通道)，Buffer(缓冲区), Selector。传统IO基于字节流和字符流进行操作，而NIO基于Channel和Buffer(缓冲区)进行操作，数据总是从通道读取到缓冲区中，或者从缓冲区写入到通道中。Selector(选择区)用于监听多个通道的事件（比如：连接打开，数据到达）。因此，单个线程可以监听多个数据通道。
>
>![img](https://pic2.zhimg.com/80/v2-14ca3291172dfc52421ecef8d4096221_1440w.jpg)
>
>https://zhuanlan.zhihu.com/p/93903230   详细解读



## ==IO 多路复用选择器 select poll epoll  recato模式==

>-  **Select uninx网络变成环境**
>
><img src="https://img-blog.csdnimg.cn/20210124201118898.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1h1ZXlpbkd1bw==,size_16,color_FFFFFF,t_70" alt="img" style="zoom:67%;" />
>
>通过一次系统调用，把文件描述符fds，传递给内核，内核通过读取bitmap读、写、异常的标志位，内核进行遍历，在遍历过程中判断fds是否有数据，如果没有数据进行阻塞，有数据则对有数据的dfs进行置位，并返回给用户态进行操作。 内核来帮我们监听数据。
>
>缺点：
>
>1.  bitmap默认大小是1024  （bitmap）是表示fd的集合。
>2. 内核态在在对有数据的fds上，置位了bitmap，再次重新进行遍历的时候导致bitmap不可重用了。
>3. 用户态到内核态仍有一个开销
>4. 重内核态对bitmap标志有数据的fds，在返回给用户态 用户态还需要再次遍历一遍来查看哪里有数据 还需要O(n)时间复杂度
>
>------
>
>- **poll **
>
>poll其实跟select差不多，区别就是select使用bitmap来表示文件描述符。 而poll不是构建一个描述符集，而是构造一个pollfd的数组，每个数组的元素制定一个描述符编号**（结构体中的fd）**以及我们对该描述符感兴趣的条件**（short events）**。 `int fd \ short event  \ short revents`
>
>1. 在内核进行遍历的时候 对有数据的fds只需要修改 `short revenets`字段   。 当用户态读取完数据之后会把`revebts`字段置位0 达到复用。
>2. `pollfd`是数组 没有像select 中Bitmap1024大小的限制
>
>-----
>
>- **epoll**
>
>epoll有三个函数
>
>epoll_create:  会在内核常见红黑树和就绪链表
>
>Epoll_ctl:        对红黑树进行操作，添加所有socket节点
>
>Epoll_wait:    阻塞线程，内核中查找红黑树已经准备好的`socket` 并放入到就绪链表当中。就绪链表中的内容复制到events事件中。用户态可以直接进行访问，也就是`epoll`相当于事件通知，只把准备好的告诉你
>
>优点：
>
>1.  在文件描述符`fds`状态感知的情况下，`epoll`是事件通知的形式  时间复杂度为O(1)
>2. 文件描述符的数量没有限制
>3. 不需要对原数据进行重置
>
>缺点：
>
>1. Epoll 并没有完全解决用户态和内核态之间的复制，只是减少了频繁操作而已。

>**BIO模式下**：一个用户请求 创建一个线程去处理被  因为这里`ServerSocket.accept() `接受客户端的连接方法 必须有客户端连接过来才会解阻塞被
>
>**NIO模式**： 优势：规避多线程的问题  弊端： 假设有一万个连接请求 只有一个发来数据 每循环一次 必须向系统内核发送一万次recv的调用，那么这里有9999					次是无意义的，浪费的 消耗事件和资源的 用户空间向内核空间的循环遍历，复杂度在系统调用上
>
>**select poll 时间复杂度O(n)**：
>
>优势：通过一次系统调用，把fds，传递给内核，内核进行遍历，这种遍历减少了系统调用的次数！
>
>select的几大缺点：
>
>- 每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大
>- 同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大
>- select支持的文件描述符数量太小了，默认是102。poll没有文件描述符大小限制在这里哈呢。。。
>
>--------------
>
>**epool 时间复杂度O(1)**：  内核空间创建了一块内存 用红黑树存放 fd7
>
>epoll既然是对select和poll的改进，就应该能避免上述的三个缺点。epoll和select和poll的调用接口上的不同，select和poll都只提供了一个函数——select或者poll函数。
>
>而epoll提供了三个函数，**epoll_create,epoll_ctl和epoll_wait，epoll_create**是创建一个epoll句柄；epoll_ctl是注册要监听的事件类型；epoll_wait则是等待事件的产生。
>
>- 对于第一个缺点，epoll的解决方案在epoll_ctl函数中。每次注册新的事件到epoll句柄中时（在epoll_ctl中指定EPOLL_CTL_ADD），会把所有的fd拷贝进内核，而不是在epoll_wait的时候重复拷贝。epoll保证了每个fd在整个过程中只会拷贝一次。
>- 对于第二个缺点，epoll的解决方案不像select或poll一样每次都把current轮流加入fd对应的设备等待队列中，而只在epoll_ctl时把current挂一遍（这一遍必不可少）并为每个fd指定一个回调函数，当设备就绪，唤醒等待队列上的等待者时，就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪链表）。epoll_wait的工作实际上就是在这个就绪链表中查看有没有就绪的fd（利用schedule_timeout()实现睡一会，判断一会的效果，和select实现中的第7步是类似的）。
>- 对于第三个缺点，epoll没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。
>
>--------------
>
>**总结：**
>
>**1）select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。**
>
>**2）select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少的开销。**
>
>![image-20210809235634489](/Users/whig/Library/Application Support/typora-user-images/image-20210809235634489.png)





# 设计模式

## 设计模式7大原则

>| 标记 | 设计模式原则名称  | 简单定义                                               |
>| :--- | :---------------- | :----------------------------------------------------- |
>| OCP  | 开闭原则          | 类或者模块： 对扩展开放，对修改关闭                    |
>| SRP  | 单一职责原则      | 一个类只负责一个功能领域中的相应职责                   |
>| LSP  | 里氏代换原则      | 所有引用基类或者父类的地方必须能透明地使用其子类的对象 |
>| DIP  | 依赖倒转原则      | 依赖于抽象，不能依赖于具体实现                         |
>| ISP  | 接口隔离原则      | 类之间的依赖关系应该建立在最小的接口上                 |
>| CARP | 合成/聚合复用原则 | 尽量使用合成/聚合，而不是通过继承达到复用的目的        |
>| LOD  | 迪米特法则        | 一个软件实体应当尽可能少的与其他实体发生相互作用       |
>
>**1、开闭原则（Open Close Principle）**
>
>开闭原则的意思是：**对扩展开放，对修改关闭**。在程序需要进行拓展的时候，不能去修改原有的代码。简言之，是为了使程序的扩展性好，易于维护和升级。想要达到这样的效果，我们需要使用接口和抽象类，后面的具体设计中我们会提到这点。
>
>**2、里氏代换原则（Liskov Substitution Principle）**
>
>里氏代换原则是面向对象设计的基本原则之一。 里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。LSP 是继承复用的基石，只有当派生类可以替换掉基类，且软件单位的功能不受到影响时，基类才能真正被复用，而派生类也能够在基类的基础上增加新的行为。里氏代换原则是对开闭原则的补充。实现开闭原则的关键步骤就是抽象化，而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。
>
>**3、依赖倒转原则（Dependence Inversion Principle）**
>
>程序要依赖于抽象接口，不要依赖于具体实现。简单的说就是要求对抽象进行编程，不要对实现进行编程，这样就降低了客户与实现模块间的耦合。
>
>**4、接口隔离原则（Interface Segregation Principle）**
>
>这个原则的意思是：使用多个隔离的接口，比使用单个接口要好。它还有另外一个意思是：降低类之间的耦合度。由此可见，其实设计模式就是从大型软件架构出发、便于升级和维护的软件设计思想，它强调降低依赖，降低耦合。
>
>**5、迪米特法则，又称最少知道原则（Demeter Principle）**
>
>最少知道原则是指：一个实体应当尽量少地与其他实体之间发生相互作用，使得系统功能模块相对独立。
>
>**6、合成复用原则（Composite Reuse Principle）**
>
>合成复用原则是指：尽量使用合成/聚合的方式，而不是使用继承。





## [23种设计模式](https://www.runoob.com/design-pattern/design-pattern-tutorial.html)



>https://www.runoob.com/design-pattern/design-pattern-tutorial.html







## 代理模式和装饰者模式区别

>对装饰器模式来说，装饰者（decorator）和被装饰者（decoratee）都实现同一个 接口。对代理模式来说，代理类（proxy class）和真实处理的类（real class）都实现同一个接口。他们之间的边界确实比较模糊，两者都是对类的方法进行扩展，具体区别如下：
>
>1. **装饰器模式强调的是增强自身，在被装饰之后你能够在被增强的类上使用增强后的功能**。增强后你还是你，只不过能力更强了而已；
>
>2. 代理模式强调要让别人帮你去做一些本身与你业务没有太多关系的职责（记录日志、设置缓存）。代理模式是为了实现对象的控制，因为被代理的对象往往难以直接获得或者是其内部不想暴露出来。
>3. 装饰模式是为装饰的对象增强功能；而代理模式对代理的对象施加控制，但不对对象本身的功能进行增强；





## 继承跟装饰者模式的区别

>装饰器模式是在不改变核心功能的基础上去新增一些新的功能，和代理模式非常地相似
>
>### 优点
>
>1. 装饰器模式是继承的一种替代方式，通过组合的方式完成继承的功能，但却避免了继承的侵入性。
>2. 降低类间的耦合。被装饰类和装饰类都可以独立发展，不会相互影响。
>3. 符合开放封闭原则。



## 观察者模式和发布订阅模式区别

>观察者模式： 是 观察者和被被观察者直接对接
>
>发布订阅模式： 发布者和订阅者是独立的 通过中间的调度器来进行
>
><img src="https://pic2.zhimg.com/v2-540a78ba3127b0c6882adc668e7a3535_r.jpg" alt="preview" style="zoom:50%;" />
>
>- 观察者模式里，只有两个角色 —— 观察者 + 被观察者
>- 而发布订阅模式里，却不仅仅只有发布者和订阅者两个角色，还有一个经常被我们忽略的 —— 经纪人Broker

## java语言使用哪几种设计模式



>##### 结构型模式：
>
>###### 适配器模式：
>
>用来把一个接口转化成另一个接口。
>
>- java.util.Arrays#asList()
>- javax.swing.JTable(TableModel)
>- java.io.InputStreamReader(InputStream)
>- java.io.OutputStreamWriter(OutputStream)
>- javax.xml.bind.annotation.adapters.XmlAdapter#marshal()
>- javax.xml.bind.annotation.adapters.XmlAdapter#unmarshal()
>
>###### 桥接模式：
>
>这个模式将抽象和抽象操作的实现进行了解耦，这样使得抽象和实现可以独立地变化。
>
>- AWT (It provides an abstraction layer which maps onto the native OS the windowing support.)
>- JDBC
>
>###### 组合模式
>
>使得客户端看来单个对象和对象的组合是同等的。换句话说，某个类型的方法同时也接受自身类型作为参数。
>
>- - javax.swing.JComponent#add(Component)
> - java.awt.Container#add(Component)
> - java.util.Map#putAll(Map)
> - java.util.List#addAll(Collection)
> - java.util.Set#addAll(Collection)
>
>###### 装饰者模式：
>
>动态的给一个对象附加额外的功能，这也是子类的一种替代方式。可以看到，在创建一个类型的时候，同时也传入同一类型的对象。这在JDK里随处可见，你会发现它无处不在，所以下面这个列表只是一小部分。
>
>- - - java.io.BufferedInputStream(InputStream)
>   - java.io.DataInputStream(InputStream)
>   - java.io.BufferedOutputStream(OutputStream)
>   - java.util.zip.ZipOutputStream(OutputStream)
>   - java.util.Collections#checked[List|Map|Set|SortedSet|SortedMap](http://it.deepinmind.com/设计模式/2014/03/10/细数JDK里的设计模式.html)
>
>###### 门面模式：
>
>给一组组件，接口，抽象，或者子系统提供一个简单的接口。
>
>- - - java.lang.Class
>   - javax.faces.webapp.FacesServlet
>
>###### 享元模式
>
>使用缓存来加速大量小对象的访问时间。
>
>- - - java.lang.Integer#valueOf(int)
>   - java.lang.Boolean#valueOf(boolean)
>   - java.lang.Byte#valueOf(byte)
>   - java.lang.Character#valueOf(char)
>
>###### 代理模式
>
>代理模式是用一个简单的对象来代替一个复杂的或者创建耗时的对象。
>
>- - - java.lang.reflect.Proxy
>   - RMI



>##### 创建模式
>
>###### 抽象工厂模式
>
>抽象工厂模式提供了一个协议来生成一系列的相关或者独立的对象，而不用指定具体对象的类型。它使得应用程序能够和使用的框架的具体实现进行解耦。这在JDK或者许多框架比如Spring中都随处可见。它们也很容易识别，一个创建新对象的方法，返回的却是接口或者抽象类的，就是抽象工厂模式了。
>
>- - - java.util.Calendar#getInstance()
>   - java.util.Arrays#asList()
>   - java.util.ResourceBundle#getBundle()
>   - java.sql.DriverManager#getConnection()
>   - java.sql.Connection#createStatement()
>   - java.sql.Statement#executeQuery()
>   - java.text.NumberFormat#getInstance()
>   - javax.xml.transform.TransformerFactory#newInstance()
>
>###### 建造模式(Builder)
>
>定义了一个新的类来构建另一个类的实例，以简化复杂对象的创建。建造模式通常也使用方法链接来实现。
>
>- - - java.lang.StringBuilder#append()
>   - java.lang.StringBuffer#append()
>   - java.sql.PreparedStatement
>   - javax.swing.GroupLayout.Group#addComponent()
>
>###### 工厂方法
>
>就是一个返回具体对象的方法。
>
>- - - java.lang.Proxy#newProxyInstance()
>   - java.lang.Object#toString()
>   - java.lang.Class#newInstance()
>   - java.lang.reflect.Array#newInstance()
>   - java.lang.reflect.Constructor#newInstance()
>   - java.lang.Boolean#valueOf(String)
>   - java.lang.Class#forName()
>
>###### 原型模式
>
>使得类的实例能够生成自身的拷贝。如果创建一个对象的实例非常复杂且耗时时，就可以使用这种模式，而不重新创建一个新的实例，你可以拷贝一个对象并直接修改它。
>
>- - - java.lang.Object#clone()
>   - java.lang.Cloneable
>
>###### 单例模式
>
>用来确保类只有一个实例。Joshua Bloch在Effetive Java中建议到，还有一种方法就是使用枚举。
>
>- - - java.lang.Runtime#getRuntime()
>   - java.awt.Toolkit#getDefaultToolkit()
>   - java.awt.GraphicsEnvironment#getLocalGraphicsEnvironment()
>   - java.awt.Desktop#getDesktop()
>   - java.lang.Math Random()方法



>##### 行为模式
>
>###### 责任链模式
>
>通过把请求从一个对象传递到链条中下一个对象的方式，直到请求被处理完毕，以实现对象间的解耦。
>
>- - - java.util.logging.Logger#log()
>   - javax.servlet.Filter#doFilter()
>
>###### 命令模式
>
>将操作封装到对象内，以便存储，传递和返回。
>
>- - - java.lang.Runnable
>   - javax.swing.Action
>
>###### 解释器模式
>
>这个模式通常定义了一个语言的语法，然后解析相应语法的语句。
>
>- - - java.util.Pattern
>   - java.text.Normalizer
>   - java.text.Format
>
>###### 迭代器模式
>
>提供一个一致的方法来顺序访问集合中的对象，这个方法与底层的集合的具体实现无关。
>
>- - - java.util.Iterator
>   - java.util.Enumeration
>
>###### 中介者模式
>
>通过使用一个中间对象来进行消息分发以及减少类之间的直接依赖。
>
>- - - java.util.Timer
>   - java.util.concurrent.Executor#execute()
>   - java.util.concurrent.ExecutorService#submit()
>   - java.lang.reflect.Method#invoke()
>
>###### 备忘录模式
>
>生成对象状态的一个快照，以便对象可以恢复原始状态而不用暴露自身的内容。Date对象通过自身内部的一个long值来实现备忘录模式。
>
>- - - java.util.Date
>   - java.io.Serializable
>
>###### 空对象模式
>
>这个模式通过一个无意义的对象来代替没有对象这个状态。它使得你不用额外对空对象进行处理。
>
>- - - java.util.Collections#emptyList()
>   - java.util.Collections#emptyMap()
>   - java.util.Collections#emptySet()
>
>###### 观察者模式
>
>它使得一个对象可以灵活的将消息发送给感兴趣的对象。
>
>- - - java.util.EventListener
>   - javax.servlet.http.HttpSessionBindingListener
>   - javax.servlet.http.HttpSessionAttributeListener
>   - javax.faces.event.PhaseListener
>
>###### 状态模式
>
>通过改变对象内部的状态，使得你可以在运行时动态改变一个对象的行为。
>
>- - - java.util.Iterator
>   - javax.faces.lifecycle.LifeCycle#execute()
>
>###### 策略模式
>
>使用这个模式来将一组算法封装成一系列对象。通过传递这些对象可以灵活的改变程序的功能。
>
>- - - java.util.Comparator#compare()
>   - javax.servlet.http.HttpServlet
>   - javax.servlet.Filter#doFilter()
>
>###### 模板方法模式
>
>让子类可以重写方法的一部分，而不是整个重写，你可以控制子类需要重写那些操作。
>
>- - - java.util.Collections#sort()
>   - java.io.InputStream#skip()
>   - java.io.InputStream#read()
>   - java.util.AbstractList#indexOf()
>
>###### 访问者模式
>
>提供一个方便的可维护的方式来操作一组对象。它使得你在不改变操作的对象前提下，可以修改或者扩展对象的行为。
>
>- - - javax.lang.model.element.Element and javax.lang.model.element.ElementVisitor
>   - javax.lang.model.type.TypeMirror and javax.lang.model.type.TypeVisitor



## spring设计模式

>- 1.简单工厂(非23种设计模式中的一种)
>- 2.工厂方法
>- 3.单例模式
>- 4.适配器模式
>- 5.装饰器模式
>- 6.代理模式
>- 7.观察者模式
>- 8.策略模式
>- 9.模版方法模式
>
>## 1.简单工厂(非23种设计模式中的一种)
>
>## 实现方式：
>
>BeanFactory。Spring中的BeanFactory就是简单工厂模式的体现，根据传入一个唯一的标识来获得Bean对象，但是否是在传入参数后创建还是传入参数前创建这个要根据具体情况来定。
>
>## 实质：
>
>由一个工厂类根据传入的参数，动态决定应该创建哪一个产品类。
>
>## 实现原理：
>
>**bean容器的启动阶段：**
>
>- 读取bean的xml配置文件,将bean元素分别转换成一个BeanDefinition对象。
>- 然后通过BeanDefinitionRegistry将这些bean注册到beanFactory中，保存在它的一个ConcurrentHashMap中。
>- 将BeanDefinition注册到了beanFactory之后，在这里Spring为我们提供了一个扩展的切口，允许我们通过实现接口BeanFactoryPostProcessor 在此处来插入我们定义的代码。典型的例子就是：PropertyPlaceholderConfigurer，我们一般在配置数据库的dataSource时使用到的占位符的值，就是它注入进去的。
>
>**容器中bean的实例化阶段：**
>
>实例化阶段主要是通过反射或者CGLIB对bean进行实例化，在这个阶段Spring又给我们暴露了很多的扩展点：
>
>- **各种的Aware接口** ，比如 BeanFactoryAware，对于实现了这些Aware接口的bean，在实例化bean时Spring会帮我们注入对应的BeanFactory的实例。
>- **BeanPostProcessor接口** ，实现了BeanPostProcessor接口的bean，在实例化bean时Spring会帮我们调用接口中的方法。
>- **InitializingBean接口** ，实现了InitializingBean接口的bean，在实例化bean时Spring会帮我们调用接口中的方法。
>- **DisposableBean接口** ，实现了BeanPostProcessor接口的bean，在该bean死亡时Spring会帮我们调用接口中的方法。
>
>## 设计意义：
>
>**松耦合。** 可以将原来硬编码的依赖，通过Spring这个beanFactory这个工厂来注入依赖，也就是说原来只有依赖方和被依赖方，现在我们引入了第三方——spring这个beanFactory，由它来解决bean之间的依赖问题，达到了松耦合的效果.
>
>**bean的额外处理。** 通过Spring接口的暴露，在实例化bean的阶段我们可以进行一些额外的处理，这些额外的处理只需要让bean实现对应的接口即可，那么spring就会在bean的生命周期调用我们实现的接口来处理该bean。[非常重要]
>
>## 2.工厂方法
>
>## 实现方式：
>
>FactoryBean接口。
>
>## 实现原理：
>
>实现了FactoryBean接口的bean是一类叫做factory的bean。其特点是，spring会在使用getBean()调用获得该bean时，会自动调用该bean的getObject()方法，所以返回的不是factory这个bean，而是这个bean.getOjbect()方法的返回值。
>
>### 例子：
>
>典型的例子有spring与mybatis的结合。
>
>**代码示例：**
>
>
>
>![img](https://pic3.zhimg.com/80/v2-57952d80301d013e42197b368bb4f062_1440w.jpg)
>
>
>
>**说明：**
>
>我们看上面该bean，因为实现了FactoryBean接口，所以返回的不是 SqlSessionFactoryBean 的实例，而是它的 SqlSessionFactoryBean.getObject() 的返回值。
>
>## 3.单例模式
>
>Spring依赖注入Bean实例默认是单例的。
>
>Spring的依赖注入（包括lazy-init方式）都是发生在AbstractBeanFactory的getBean里。getBean的doGetBean方法调用getSingleton进行bean的创建。
>
>分析getSingleton()方法
>
>```text
>public Object getSingleton(String beanName){
>   //参数true设置标识允许早期依赖
>   return getSingleton(beanName,true);
>}
>protected Object getSingleton(String beanName, boolean allowEarlyReference) {
>   //检查缓存中是否存在实例
>   Object singletonObject = this.singletonObjects.get(beanName);
>   if (singletonObject == null && isSingletonCurrentlyInCreation(beanName)) {
>       //如果为空，则锁定全局变量并进行处理。
>       synchronized (this.singletonObjects) {
>           //如果此bean正在加载，则不处理
>           singletonObject = this.earlySingletonObjects.get(beanName);
>           if (singletonObject == null && allowEarlyReference) {
>               //当某些方法需要提前初始化的时候则会调用addSingleFactory 方法将对应的ObjectFactory初始化策略存储在singletonFactories
>               ObjectFactory<?> singletonFactory = this.singletonFactories.get(beanName);
>               if (singletonFactory != null) {
>                   //调用预先设定的getObject方法
>                   singletonObject = singletonFactory.getObject();
>                   //记录在缓存中，earlysingletonObjects和singletonFactories互斥
>                   this.earlySingletonObjects.put(beanName, singletonObject);
>                   this.singletonFactories.remove(beanName);
>               }
>           }
>       }
>   }
>   return (singletonObject != NULL_OBJECT ? singletonObject : null);
>}
>```
>
>**getSingleton()过程图**
>
>ps：spring依赖注入时，使用了 双重判断加锁 的单例模式
>
>
>
>![img](https://pic2.zhimg.com/80/v2-6b4832167212c80bcde58e9ee747165d_1440w.jpg)
>
>
>
>**总结**
>
>**单例模式定义：** 保证一个类仅有一个实例，并提供一个访问它的全局访问点。
>
>**spring对单例的实现：** spring中的单例模式完成了后半句话，即提供了全局的访问点BeanFactory。但没有从构造器级别去控制单例，这是因为spring管理的是任意的java对象。
>
>## 4.适配器模式
>
>## 实现方式：
>
>SpringMVC中的适配器HandlerAdatper。
>
>## 实现原理：
>
>HandlerAdatper根据Handler规则执行不同的Handler。
>
>## 实现过程：
>
>DispatcherServlet根据HandlerMapping返回的handler，向HandlerAdatper发起请求，处理Handler。
>
>HandlerAdapter根据规则找到对应的Handler并让其执行，执行完毕后Handler会向HandlerAdapter返回一个ModelAndView，最后由HandlerAdapter向DispatchServelet返回一个ModelAndView。
>
>## 实现意义：
>
>HandlerAdatper使得Handler的扩展变得容易，只需要增加一个新的Handler和一个对应的HandlerAdapter即可。
>
>因此Spring定义了一个适配接口，使得每一种Controller有一种对应的适配器实现类，让适配器代替controller执行相应的方法。这样在扩展Controller时，只需要增加一个适配器类就完成了SpringMVC的扩展了。
>
>## 5.装饰器模式
>
>## 实现方式：
>
>Spring中用到的包装器模式在类名上有两种表现：一种是类名中含有Wrapper，另一种是类名中含有Decorator。
>
>## 实质：
>
>动态地给一个对象添加一些额外的职责。
>
>就增加功能来说，Decorator模式相比生成子类更为灵活。
>
>## 6.代理模式
>
>## 实现方式：
>
>AOP底层，就是动态代理模式的实现。
>
>## 动态代理：
>
>在内存中构建的，不需要手动编写代理类
>
>## 静态代理：
>
>需要手工编写代理类，代理类引用被代理对象。
>
>## 实现原理：
>
>切面在应用运行的时刻被织入。一般情况下，在织入切面时，AOP容器会为目标对象创建动态的创建一个代理对象。SpringAOP就是以这种方式织入切面的。
>
>织入：把切面应用到目标对象并创建新的代理对象的过程。
>
>## 7.观察者模式
>
>## 实现方式：
>
>spring的事件驱动模型使用的是 观察者模式 ，Spring中Observer模式常用的地方是listener的实现。
>
>## 具体实现：
>
>事件机制的实现需要三个部分,事件源,事件,事件监听器
>
>ApplicationEvent抽象类[事件]
>
>继承自jdk的EventObject,所有的事件都需要继承ApplicationEvent,并且通过构造器参数source得到事件源.
>
>该类的实现类ApplicationContextEvent表示ApplicaitonContext的容器事件.
>
>代码：
>
>```text
>publicabstractclass ApplicationEvent extends EventObject {
>   privatestaticfinallong serialVersionUID = 7099057708183571937L;
>   privatefinallong timestamp;
>   public ApplicationEvent(Object source) {
>   super(source);
>   this.timestamp = System.currentTimeMillis();
>   }
>   public final long getTimestamp() {
>       returnthis.timestamp;
>   }
>}
>```
>
>ApplicationListener接口[事件监听器]
>
>继承自jdk的EventListener,所有的监听器都要实现这个接口。
>
>这个接口只有一个onApplicationEvent()方法,该方法接受一个ApplicationEvent或其子类对象作为参数,在方法体中,可以通过不同对Event类的判断来进行相应的处理。
>
>当事件触发时所有的监听器都会收到消息。
>
>代码：
>
>```text
>publicinterface ApplicationListener<E extends ApplicationEvent> extends EventListener {
>    void onApplicationEvent(E event);
>}
>```
>
>ApplicationContext接口[事件源]
>
>ApplicationContext是spring中的全局容器，翻译过来是”应用上下文”。
>
>实现了ApplicationEventPublisher接口。
>
>## 职责：
>
>负责读取bean的配置文档,管理bean的加载,维护bean之间的依赖关系,可以说是负责bean的整个生命周期,再通俗一点就是我们平时所说的IOC容器。
>
>代码：
>
>```text
>publicinterface ApplicationEventPublisher {
>       void publishEvent(ApplicationEvent event);
>}
>
>public void publishEvent(ApplicationEvent event) {
>   Assert.notNull(event, "Event must not be null");
>   if (logger.isTraceEnabled()) {
>        logger.trace("Publishing event in " + getDisplayName() + ": " + event);
>   }
>   getApplicationEventMulticaster().multicastEvent(event);
>   if (this.parent != null) {
>   this.parent.publishEvent(event);
>   }
>}
>```
>
>ApplicationEventMulticaster抽象类[事件源中publishEvent方法需要调用其方法getApplicationEventMulticaster]
>
>属于事件广播器,它的作用是把Applicationcontext发布的Event广播给所有的监听器.
>
>代码：
>
>```text
>publicabstractclass AbstractApplicationContext extends DefaultResourceLoader
>   implements ConfigurableApplicationContext, DisposableBean {
>   private ApplicationEventMulticaster applicationEventMulticaster;
>   protected void registerListeners() {
>   // Register statically specified listeners first.
>   for (ApplicationListener<?> listener : getApplicationListeners()) {
>   getApplicationEventMulticaster().addApplicationListener(listener);
>   }
>   // Do not initialize FactoryBeans here: We need to leave all regular beans
>   // uninitialized to let post-processors apply to them!
>   String[] listenerBeanNames = getBeanNamesForType(ApplicationListener.class, true, false);
>   for (String lisName : listenerBeanNames) {
>   getApplicationEventMulticaster().addApplicationListenerBean(lisName);
>   }
> }
>}
>```
>
>## 8.策略模式
>
>## 实现方式：
>
>Spring框架的资源访问Resource接口。该接口提供了更强的资源访问能力，Spring 框架本身大量使用了 Resource 接口来访问底层资源。
>
>## Resource 接口介绍
>
>source 接口是具体资源访问策略的抽象，也是所有资源访问类所实现的接口。
>
>Resource 接口主要提供了如下几个方法:
>
>- **getInputStream()：** 定位并打开资源，返回资源对应的输入流。每次调用都返回新的输入流。调用者必须负责关闭输入流。
>- **exists()：** 返回 Resource 所指向的资源是否存在。
>- **isOpen()：** 返回资源文件是否打开，如果资源文件不能多次读取，每次读取结束应该显式关闭，以防止资源泄漏。
>- **getDescription()：** 返回资源的描述信息，通常用于资源处理出错时输出该信息，通常是全限定文件名或实际 URL。
>- **getFile：** 返回资源对应的 File 对象。
>- **getURL：** 返回资源对应的 URL 对象。
>
>最后两个方法通常无须使用，仅在通过简单方式访问无法实现时，Resource 提供传统的资源访问的功能。
>
>Resource 接口本身没有提供访问任何底层资源的实现逻辑，**针对不同的底层资源，Spring 将会提供不同的 Resource 实现类，不同的实现类负责不同的资源访问逻辑。**
>
>Spring 为 Resource 接口提供了如下实现类：
>
>- **UrlResource：** 访问网络资源的实现类。
>- **ClassPathResource：** 访问类加载路径里资源的实现类。
>- **FileSystemResource：** 访问文件系统里资源的实现类。
>- **ServletContextResource：** 访问相对于 ServletContext 路径里的资源的实现类.
>- **InputStreamResource：** 访问输入流资源的实现类。
>- **ByteArrayResource：** 访问字节数组资源的实现类。
>
>这些 Resource 实现类，针对不同的的底层资源，提供了相应的资源访问逻辑，并提供便捷的包装，以利于客户端程序的资源访问。
>
>## 9.模版方法模式
>
>## 经典模板方法定义：
>
>父类定义了骨架（调用哪些方法及顺序），某些特定方法由子类实现。
>
>最大的好处：代码复用，减少重复代码。除了子类要实现的特定方法，其他方法及方法调用顺序都在父类中预先写好了。
>
>**所以父类模板方法中有两类方法：**
>
>**共同的方法：** 所有子类都会用到的代码
>
>**不同的方法：** 子类要覆盖的方法，分为两种：
>
>- 抽象方法：父类中的是抽象方法，子类必须覆盖
>- 钩子方法：父类中是一个空方法，子类继承了默认也是空的
>
>注：为什么叫钩子，子类可以通过这个钩子（方法），控制父类，因为这个钩子实际是父类的方法（空方法）！
>
>## Spring模板方法模式实质：
>
>是模板方法模式和回调模式的结合，是Template Method不需要继承的另一种实现方式。Spring几乎所有的外接扩展都采用这种模式。
>
>## 具体实现：
>
>JDBC的抽象和对Hibernate的集成，都采用了一种理念或者处理方式，那就是模板方法模式与相应的Callback接口相结合。
>
>采用模板方法模式是为了以一种统一而集中的方式来处理资源的获取和释放，以JdbcTempalte为例:
>
>```text
>publicabstractclass JdbcTemplate {
>    publicfinal Object execute（String sql）{
>       Connection con=null;
>       Statement stmt=null;
>       try{
>           con=getConnection（）;
>           stmt=con.createStatement（）;
>           Object retValue=executeWithStatement（stmt,sql）;
>           return retValue;
>       }catch（SQLException e）{
>            ...
>       }finally{
>           closeStatement（stmt）;
>           releaseConnection（con）;
>       }
>   }
>   protectedabstract Object executeWithStatement（Statement   stmt, String sql）;
>}
>```
>
>## 引入回调原因：
>
>JdbcTemplate是抽象类，不能够独立使用，我们每次进行数据访问的时候都要给出一个相应的子类实现,这样肯定不方便，所以就引入了回调。
>
>回调代码
>
>```text
>publicinterface StatementCallback{
>   Object doWithStatement（Statement stmt）;
>}
>```
>
>利用回调方法重写JdbcTemplate方法
>
>```text
>publicclass JdbcTemplate {
>   publicfinal Object execute（StatementCallback callback）{
>       Connection con=null;
>       Statement stmt=null;
>       try{
>           con=getConnection（）;
>           stmt=con.createStatement（）;
>           Object retValue=callback.doWithStatement（stmt）;
>           return retValue;
>       }catch（SQLException e）{
>           ...
>       }finally{
>           closeStatement（stmt）;
>           releaseConnection（con）;
>       }
>   }
>
>   ...//其它方法定义
>}
>```
>
>Jdbc使用方法如下：
>
>```text
>JdbcTemplate jdbcTemplate=...;
>   final String sql=...;
>   StatementCallback callback=new StatementCallback(){
>   public Object=doWithStatement(Statement stmt){
>       return ...;
>   }
>}
>jdbcTemplate.execute(callback);
>```



## 单例模式

>- 饿汉模式
>
>```java
>public final class HungrySingleton implements Serializable {
>  /**
>   * 1.为什么加final                                        防止被继承 子类覆盖父类方法
>   * 2.如果实现了序列化接口 怎样防止反序列化来创建对象          加一个特殊方法 readSolve()防止反序列化 返回你方法里返回的对象
>   *
>   * 饿汉式单例  ： 饿汉式单例类: 在类初始化时，已经自行实例化。
>   * 但问题是无法做到延迟创建对象，事实上如果该单例类涉及资源较多，创建比较耗时间时，我们更希望它可以尽可能地延迟加载，从而减小初始化的负载
>   */
>
>  //3.为什么设置为私有，能否反射来创建新实例                    设置为私有就是防止被创建   反射功能强大能创建新实例
>  private HungrySingleton(){}
>
>  //4.这样类初始化时 是否能保证线程安全                        类加载解析时期就创建了对象，不会有线程安全  jvm在来保证线程安全
>  private static final HungrySingleton Instance=new HungrySingleton();
>
>  //5.为什么提供静态方法 而不是直接将字段设置为public           1.封装 2.创建单例对象有更多的控制  3.支持泛型的控制
>  public static HungrySingleton getInstance(){
>      return Instance;
>  }
>
>  public Object readSolve(){
>      return Instance;
>  }
>}
>```
>
>- 懒汉式单例
>
>```java
>public class LazySingleton {
>
>  /**
>   * 懒汉式单例  ：懒汉式单例模式在第一次调用的时候进行实例化。
>   */
>
>  private LazySingleton() {
>  }
>
>  private static volatile LazySingleton Instance = null;
>
>  /**
>   * 第一种 多线程创建方式 1.每一次调用方法都会synchronized重量锁 性能低
>   * 2. synchronized 加载了方法上 作用域太大
>   */
>  public static synchronized LazySingleton getInstance() {
>      if (Instance == null)
>          Instance = new LazySingleton();
>
>      return Instance;
>  }
>
>  /**
>   * 多线程 优化 二次检查机制
>   * 问题：1.解释为什么加volatile                synchronized不能防止指令重排  Instance=new LazySingleton()这里可能发生指令重排 加入												 volatile就不会了
>   * <p>
>   * 2.相比于第一种 第二种优化在哪            防止每次调用都加synchronized关键字 性能高 不用每次都进行加锁
>   * 3.为什么还需要加第二次判断==null        为了多线程情况下最开始创建对象的情况  假设第一个进入同步代码块 第二个线程在排队
>   * 第一个线程创建完之后 如果没加判断 第二个线程也会创建
>   */
>
>  public static LazySingleton getInstance_Opt() {
>      if (Instance == null) {
>          synchronized (LazySingleton.class) {
>              if (Instance == null) {
>                  Instance = new LazySingleton();		//如果不加入volatile可能会造成 Instance初始化不完全
>              }
>          }
>      }
>      return Instance;
>  }
>}
>```
>
>- 静态内部类
>
>```java
>public class Singleton {
>     /**
>  * 静态内部类方式（推荐）：
>  * 加载一个类时，其内部类不会同时被加载。一个类被加载，当且仅当其某个静态成员（静态域、构造器、静态方法等）被调用时发生。 由于在调用 			 StaticSingleton.getInstance() 的时候， 才会对单例进行初始化，而且通过反射，是不能从外部类获取内部类的属性的；
>  
>     由于静态内部类的特性，只有在其被第一次引用的时候才会被加载，所以可以保证其线程安全性。
>
>   * 总结：
>   * 优势：兼顾了懒汉模式的内存优化（使用时才初始化）以及饿汉模式的安全性（不会被反射入侵）。
>   * 劣势：需要两个类去做到这一点，虽然不会创建静态内部类的对象，但是其 Class 对象还是会被创建，而且是属于永久带的对象。
>      */
>  private static class InnerClass {
>      private static Singleton Instance = new Singleton();
>  }
>  private static final  Singleton getInstance() {
>      return InnerClass.Instance;
>  }
>}
>```
>
>- 枚举方式
>
>```java
>public class Singleton {
> private Singleton(){
> }   
> public static enum SingletonEnum {     //重点 枚举类型没有办法满足懒加载  在程序启动的时候就已经吧这个单例构建好了
>     SINGLETON;													//JVM无法获取枚举类 无参 构造器 发射会爆出异常
>   																			//protect Enum(String name, int val)
>      private Singleton instance = null;
>      private SingletonEnum(){
>          instance = new Singleton();
>      }
>      public Singleton getInstance(){
>          return instance;
>      }
>  }
>}
>```
>
>使用`SingletonEnum.INSTANCE`进行访问，这样也就避免调用`getInstance`方法，更重要的是使用枚举单例的写法，我们完全不用考虑序列化和反射的问题。枚举序列化是由`jvm`保证的，**每一个枚举类型和定义的枚举变量在JVM中都是唯一的**，在枚举类型的序列化和反序列化上，Java做了特殊的规定：在序列化时Java仅仅是将枚举对象的name属性输出到结果中，反序列化的时候则是通过java.lang.Enum的valueOf方法来根据名字查找枚举对象。同时，编译器是不允许任何对这种序列化机制的定制的并禁用了writeObject、readObject、readObjectNoData、writeReplace和readResolve等方法



## ==单例-双重检查机制==

>**什么是单例模式：**
>
>在整个运行时域，一个类只有一个实例对象。
>
>**为什么需要单例模式：**
>
>因为有的类创建和销毁消耗的资源并不是很大，例如String. 有的类比较庞大和复杂，如果频繁的创建和销毁对象，并且这些对象是完全可以复用的，那么将造成一些不必要的性能浪费。例如创建数据库连接`conn` 这个就是比较耗能，所以我们可以复用这个连接对象。
>
>1. 是否是线程安全
>2. 是否是懒加载      懒加载的好处就是项目比较大，需要调用的时候在创建，如果重来没有使用的话就创建比较浪费性能。
>3. 是否是反射可以创建单例
>4. `heppen-before`原则 八条

>```java
>public class Singleton {
>private volatile static Singleton Instacne; 
>
>private Singleton() {
>}
>public static  Singleton getInstance() {
>   if (Instacne == null) {
>       synchronized (Singleton.class) {
>           if ( Instacne == null) {
>               Instacne = new Singleton();
>           }
>       }
>   }
>   return Instacne;
>}
>}
>```
>
>**为什么要双重检查：为什么要加两个`if`判断**
>
>1. 毕竟在单例中`new`的情况非常少，绝大多数都是可以并行的读操作，因此在加锁前多进行一次null检查就可以减少绝大多数的加锁操作，也就提高了执行效率。避免了重复加锁、释放锁的性能消耗。 `synchronized`关键字是重量级关键字
>2. 第二次`if null`判断 是为了防止多个线程同时进入第一个判断、当时当有一个线程获取锁创建完对象，如果不加第二次检查，后续线程也会获取锁创建对象。
>
>**为什么要加入 volatile 关键字？**
>
>1. 虽然`synchronized`保证原子有序性、可见性、原子性。但是并不能保证指令重拍。`volatile`可以保证禁止指令重排。`volatile`修饰的变量时，JMM会把本地内存中值刷新到主内存。
>2. **`single = new Single()`这段代码并不具备原子性**。new 对象的时候在 JVM当中需要三个指令 
>
>       ```xml
>       memory = allocate();   //1：分配对象的内存空间
>       ctorInstance(memory);  //2：初始化对象
>       instance = memory;     //3：设置instance指向刚分配的内存地址
>       虚拟机为了指令效率可能会进行指令重排
>       ```
>
>假设有A、B两个线程去调用该单例方法，当A线程执行到`single = new Single()`时，如果编译器和处理器对指令重新排序，指令重排后：
>
>```xml
>memory = allocate();   //1：分配对象的内存空间
>instance = memory;     //3：设置instance指向刚分配的内存地址，此时对象还没被初始化
>ctorInstance(memory);  //2：初始化对象
>```
>
>设置`instance`指向刚分配的内存地址，此时对象还没被初始化,变量`single`指向内存地址之后就不为`null`了，此时`B`线程进入第一个`if`，由于`single`已经不为`null`了，那么就不会执行到同步代码块，而是直接返回未初始化对象的变量`single`，从而导致后续代码报错。所以这里边变量要加入`volatile`修饰符



## ==接口回调 观察者模式 快手面试题==

>```java
>  // 1、创建一个回调接口
>public interface CallBack
>{
>    public void doEvent();
>} 
>  
> // 2、创建回调接口的实现类，此例中，员工干完活后还要干什么事情是老板说了算的。
>public class Boss implements CallBack
>{
>    public void doEvent()
>    {
>        System.out.println("打电话给老板，告知已经完成工作了");
>    }
>}
>
>
>//创建控制类，也就是本例中的员工对象，他要持有老板的地址(即回调接口)
>public class Employee
>{
>    CallBack callBack;
>    public Employee(CallBack callBack)
>    {
>        this.callBack=callBack;
>    }
>    public void doWork()
>    {
>        System.out.println("玩命干活中....");
>        callBack.doEvent();
>    }
>}
>```





## 生产者消费者模式

https://segmentfault.com/a/1190000024444906

>1. 生产者队列长度      
>2. 创建几个生产者和几个消费者
>
>-----
>
><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gippgxspy8j310k0sagqn.jpg" alt="preview" style="zoom:25%;" />
>
>为什么需要`while` 在这里就是进行解释 ： 被通知之后不一定就是拿到锁 而是进入到等待队列当中了。期间可能就是有其他线程拿到了锁。
>
>```java
>// 这里边就是作为缓冲区大小呗  队列
>class Buffer {
>
>   private Queue<Integer> queue = new LinkedList<>();
>   private int size;
>   public Buffer(Queue<Integer> queue, int size) {
>       this.queue = queue;
>       this.size = size;
>   }
>
>   public synchronized void add(int val) throws InterruptedException {
>       while (queue.size() > size) {   //这里边是while 防止多线程 A线程进入被唤醒不一定立即拿到锁 在等待队列中 可能别的线程已经																				  生产了  所以在这里就是一定要在while里边调用wait呢 
>           wait();
>       }
>       queue.offer(val);
>       notifyAll();                   //通知消费者去消费
>   }
>
>   public synchronized int get() throws InterruptedException {
>       while (queue.size() == 0) {
>           wait();
>       }
>       int val = queue.poll();
>       notifyAll();  //通知生产者去生产
>       return val;
>   }
>}
>
>//生产者和消费者 主要就是上边两个方法  add get 方法
>
>class Produce implements Runnable {
>   private Buffer buffer;
>
>   public Produce(Buffer buffer) {
>       this.buffer = buffer;
>   }
>
>   @Override
>   public void run() {
>       for (int i = 0; i < 10; i++) {
>           try {
>               buffer.add(i);
>               Thread.sleep(1000);
>           } catch (InterruptedException e) {
>               e.printStackTrace();
>           }
>           System.out.println("生产者 生产：" + i);
>       }
>   }
>}
>
>class Consume implements Runnable {
>
>   private Buffer buffer;
>
>   public Consume(Buffer buffer) {
>       this.buffer = buffer;
>   }
>
>   @Override
>   public void run() {
>       for (int i = 0; i < 10; i++) {
>           int val = 0;
>           try {
>               val = buffer.get();
>               Thread.sleep(1000);
>           } catch (InterruptedException e) {
>               e.printStackTrace();
>           }
>           System.out.println("消费者消费:" + val);
>       }
>   }
>}
>
>public class Produce_Consume {
>   public static void main(String[] args) {
>       Buffer buffer = new Buffer(new LinkedList<>(), 5);
>       for (int i = 0; i < 5; i++) {
>           new Thread(new Produce(buffer)).start();
>       }
>       for (int i = 0; i < 5; i++) {
>           new Thread(new Consume(buffer)).start();
>       }
>   }
>}
>```
>
>------
>
>方法2： 阻塞队列实现
>
>当队列满了的时候进行入队列操作,当队列空了的时候进行出队列操作 这两种情况的时候。
>因此，当一个线程对已经满了的阻塞队列进行入队操作时会阻塞，除非有另外一个线程进行了出队操作，当一个线程对一个空的阻塞队列进行出队操作时也会阻塞，除非有另外一个线程进行了入队操作。
>
>```java
>public class Test3 {
>  private static Integer count = 0;
>  //创建一个阻塞队列
>  final BlockingQueue blockingQueue = new ArrayBlockingQueue<>(10);
>  public static void main(String[] args) {
>      Test3 test3 = new Test3();
>      new Thread(test3.new Producer()).start();
>      new Thread(test3.new Consumer()).start();
>      new Thread(test3.new Producer()).start();
>      new Thread(test3.new Consumer()).start();
>      new Thread(test3.new Producer()).start();
>      new Thread(test3.new Consumer()).start();
>      new Thread(test3.new Producer()).start();
>      new Thread(test3.new Consumer()).start();
>  }
>  class Producer implements Runnable {
>      @Override
>      public void run() {
>          for (int i = 0; i < 10; i++) {
>              try {
>                  Thread.sleep(3000);
>              } catch (Exception e) {
>                  e.printStackTrace();
>              }
>              try {
>                  blockingQueue.put(1);
>                  count++;
>                  System.out.println(Thread.currentThread().getName()
>                          + "生产者生产，目前总共有" + count);
>              } catch (InterruptedException e) {
>                  e.printStackTrace();
>              }
>          }
>      }
>  }
>  class Consumer implements Runnable {
>      @Override
>      public void run() {
>          for (int i = 0; i < 10; i++) {
>              try {
>                  Thread.sleep(3000);
>              } catch (InterruptedException e1) {
>                  e1.printStackTrace();
>              }
>              try {
>                  blockingQueue.take();
>                  count--;
>                  System.out.println(Thread.currentThread().getName()
>                          + "消费者消费，目前总共有" + count);
>              } catch (InterruptedException e) {
>                  e.printStackTrace();
>              }
>          }
>      }
>  }
>}
>```
>
>------
>
>方案三：可重入锁 `reentlock`
>
>```java
>java.util.concurrent.lock 中的 Lock 框架是锁定的一个抽象，通过对lock的lock()方法和unlock()方法实现了对锁的显示控制，而synchronize()则是对锁的隐性控制。可重入锁，也叫做递归锁，指的是同一线程 外层函数获得锁之后 ，内层递归函数仍然有获取该锁的代码，但不受影响，简单来说，该锁维护这一个与获取锁相关的计数器，如果拥有锁的某个线程再次得到锁，那么获取计数器就加1，函数调用结束计数器就减1，然后锁需要被释放两次才能获得真正释放。已经获取锁的线程进入其他需要相同锁的同步代码块不会被阻塞
>```
>
>```java
>public class Test2 {
>  private static Integer count = 0;
>  private static final Integer FULL = 10;
>  //创建一个锁对象
>  private Lock lock = new ReentrantLock();
>  //创建两个条件变量，一个为缓冲区非满，一个为缓冲区非空
>  private final Condition notFull = lock.newCondition();
>  private final Condition notEmpty = lock.newCondition();
>  public static void main(String[] args) {
>      Test2 test2 = new Test2();
>      new Thread(test2.new Producer()).start();
>      new Thread(test2.new Consumer()).start();
>      new Thread(test2.new Producer()).start();
>      new Thread(test2.new Consumer()).start();
>      new Thread(test2.new Producer()).start();
>      new Thread(test2.new Consumer()).start();
>      new Thread(test2.new Producer()).start();
>      new Thread(test2.new Consumer()).start();
>  }
>  class Producer implements Runnable {
>      @Override
>      public void run() {
>          for (int i = 0; i < 10; i++) {
>              try {
>                  Thread.sleep(3000);
>              } catch (Exception e) {
>                  e.printStackTrace();
>              }
>              //获取锁
>              lock.lock();
>              try {
>                  while (count == FULL) {
>                      try {
>                          notFull.await();
>                      } catch (InterruptedException e) {
>                          e.printStackTrace();
>                      }
>                  }
>                  count++;
>                  System.out.println(Thread.currentThread().getName()
>                          + "生产者生产，目前总共有" + count);
>                  //唤醒消费者
>                  notEmpty.signal();
>              } finally {
>                  //释放锁
>                  lock.unlock();
>              }
>          }
>      }
>  }
>  class Consumer implements Runnable {
>      @Override
>      public void run() {
>          for (int i = 0; i < 10; i++) {
>              try {
>                  Thread.sleep(3000);
>              } catch (InterruptedException e1) {
>                  e1.printStackTrace();
>              }
>              lock.lock();
>              try {
>                  while (count == 0) {
>                      try {
>                          notEmpty.await();
>                      } catch (Exception e) {
>                          e.printStackTrace();
>                      }
>                  }
>                  count--;
>                  System.out.println(Thread.currentThread().getName()
>                          + "消费者消费，目前总共有" + count);
>                  notFull.signal();
>              } finally {
>                  lock.unlock();
>              }
>          }
>      }
>  }
>}
>```



# 场景提



## 遍历二维数组，按行遍历和按列遍历效率是否不同

>1. 二维数组的内存地址是连续的，当前行的尾与下一行的头相邻*
>
>2. 现代计算机，在CPU与内存之间还有一种存储机制，那就是CPU缓存（cache）。CPU缓存的容量比内存小的多但是交换速度却比内存要快得多。缓存的出现主要是为了解决CPU运算速度与内存读写速度不匹配的矛盾，因为CPU运算速度要比内存读写速度快很多，这样会使CPU花费很长时间等待数据到来或把数据写入内存。
>
>3. 访问数组元素时，CPU不会每次只从内存中读取一个元素，而是读取一个区域的元素。假设二维数组的大小为（10 x 10），访问第一个元素时，CPU也会读取它的相邻元素，因为这个数组比较小，CPU一次就可以把所有元素缓存，因此无论是按行访问数组还是按列访问数组，CPU访问主存的数量都相同。随着数组元素越来越多，CPU缓存一次只能读取数组不到一行的数据，因此按列访问元素时每访问一个元素都要访问内存，因此速度就会慢很多。





## 突然断网 排查手段

>**如果是自身原因问题：**
>
>(1)首先是排除接触故障，即确保你的网线是可以正常使用的。然后禁用网卡后再启用，排除偶然故障。打开网络和共享中心窗口，单击窗口左上侧“更改适配器设置”右击其中的“本地连接“或”无线网络连接”，单击快捷菜单中的“禁用”命令，即可禁用所选网络。接下来重启网络，只需右击后单击启用即可。
>
>(2)使用ipconfig查看计算机的上网参数
>
>1、单击“开始|所有程序|附件|命令提示符“，打开命令提示符窗口
>
>2、输入ipconfig，按Enter确认，可以看到机器的配置信息，输入ipconfig/all,可以看到IP地址和网卡物理地址等相关网络详细信息。
>
>(3)使用ping命令测试网络的连通性，定位故障范围
>
>在命令提示符窗口中输入”ping 127.0.0.1“，数据显示本机分别发送和接受了4个数据包，丢包率为零，可以判断本机网络协议工作正常，如显示”请求超时“，则表明本机网卡的安装或TCP/IP协议有问题，接下来就应该检查网卡和TCP/IP协议，卸载后重装即可。
>
>(4)ping本机IP
>
>在确认127.0.0.1地址能被ping通的情况下，继续使用ping命令测试本机的IP地址能否被ping通，如不能，说明本机的网卡驱动程序不正确，或者网卡与网线之间连接有故障，也有可能是本地的路由表面收到了破坏，此时应检查本机网卡的状态是否为已连接，网络参数是否设置正确，如果正确可是不能ping通，就应该重新安装网卡驱动程序。丢失率为零，可以判断网卡安装配置没有问题，工作正常。
>
>(5)ping网关
>
>网关地址能被ping通的话，表明本机网络连接以及正常，如果命令不成功，可能是网关设备自身存在问题，也可能是本机上网参数设置有误，检查网络参数。
>
>---
>
>**先判断是不是所有用户在这里都是受影响的呢？**
>
>**Internet连接断**
>这里的网络断，不是个别用户无法上网，而是所有的用户都受影响，很显然应该检查网络出口，快速登录出口设备，检查链路状态，如果down掉了，再排查什么原因（分析日志log）造成的，同时电话联系对端运营商，让他们一起排查，如果链路状态UP，则ping 一下对端IP，如果不通，这时最好的方法是重启设备，如果重启还不能解决，问题很可能是对端设备、或链路出了问题（单通），非常小概率是本地的问题。
>
>如果可以ping 通对端，但无法ping 更远的IP（如8.8.8.8等更多知名IP），那就是运营商的问题了。
>
>**WAN断**
>而如果使用的加密隧道连接公司各个点，这里网络断是指这些隧道断，那么首先要Ping 隧道对端的IP，如果无法Ping通，再排查对端的IP连通性，如果本地端、对端都可以Ping 直连对端，则问题出在运营商。
>
>如果可以Ping通隧道对端，则最好的办法就是重启本地网关设备，重启可以解决很多由于软件Bug而造成的网络故障。
>
>最后提到的方法，因为前几天才遇到，Hub可以转发spoke-spoke之间的流量，但无法发送本地hub ->spoke 流量，接口上有很多receive error，最后重启解决问题。
>
>------



## tomact和 nginx区别

>Tomcat运行在JVM之上，它和HTTP服务器一样，绑定IP地址并监听TCP端口，同时还包含以下指责：
>
>- 管理Servlet程序的生命周期
>- 将URL映射到指定的Servlet进行处理
>- 与Servlet程序合作处理HTTP请求——根据HTTP请求生成HttpServletResponse对象并传递给Servlet进行处理，将Servlet中的HttpServletResponse对象生成的内容返回给浏览器
>
>
>虽然Tomcat也可以认为是HTTP服务器，但通常它仍然会和Nginx配合在一起使用：
>
>- 动静态资源分离——运用Nginx的反向代理功能分发请求：所有动态资源的请求交给Tomcat，而静态资源的请求（例如图片、视频、CSS、JavaScript文件等）则直接由Nginx返回到浏览器，这样能大大减轻Tomcat的压力。
>- 负载均衡，当业务压力增大时，可能一个Tomcat的实例不足以处理，那么这时可以启动多个Tomcat实例进行水平扩展，而Nginx的负载均衡功能可以把请求通过算法分发到各个不同的实例进行处理



## 设计一个登录功能

https://blog.csdn.net/shadow_zed/article/details/82425793

>1. Https 协议
>
>2. 密码复杂 大小写8位以上
>
>3. 加密 密码：可以使用md5散列算法+salt盐来增加密码的复杂性  
>
>4. 禁止sql注入的字符
>
>5. 保存每次的登录信息日志，如果登录的IP与以往有很大差别（必要时可使用异地登录告警），要引导用户重置密码方可登录。
>
>6. 不要在cookie中保留用户密码，如果一定要使用cookie实现自动登录，切记不要使用简单的用户名＋密码MD5保存到cookie，要把用户ID、用户名、过期时间、IP、不固定的salt等一起考虑进去，这个当然要可逆，服务端要进行解密才能验证用户自动登录有效。另外，cookie要设置为http only,这样就不能通过脚本访问cookie，保证cookie的安全性
>
>7. 一段时间类的尝试登录失败次数达到某个值，要锁定用户登录，如失败5次锁定24小时。或者间隔性锁定，如失败3次后锁定半小时，再失败1次锁定1小时，再失败1次锁定24小时。
>
>   设置会话有效期，比如登录后10分钟不操作就失效，要重新登录。
>
>   验证码使用，加上干扰线，防止计算机能够轻易识别，这样也可以防止黑客以程序的方式来尝试登录。
>
>   手机登录的一般使用短信验证码的，控制验证码的时效性，即验证码一次有效，一分钟内只能发送一次。



## 如何应对大流量、高并发？？

>##### **从服务端视角看高并发**
>
>服务端处理请求需要耗费服务端的资源，比如能同时开启的进程数、能同时运行的线程数、网络连接数、cpu、I/O、内存等等，由于服务端资源是有限的，那么服务端能同时处理的请求也是有限的。高并发问题的本质就是：资源的有限性
>
>##### **高并发带来的问题**
>
>服务端的处理和响应会越来越慢，甚至会丢弃部分请求不予处理，更严重的会导致服务端崩溃。
>
>### **高并发处理的基本思路**
>
>###### **1）从客户端看**
>
>- 尽量减少请求数量，比如：依靠客户端自身的缓存或处理能力
>- 尽量减少对服务端资源的不必要耗费，比如：重复使用某些资源，如连接池客户端处理的基本原则就是：能不访问服务端就不要访问
>
>##### **2）从服务端看**
>
>- 增加资源供给，比如：更大的网络带宽，使用更高配置的服务器，使用高性能的Web服务器，使用高性能的[数据库](https://cloud.tencent.com/solution/database?from=10680)
>- 请求分流，比如：使用集群,分布式的系统架构
>- 应用优化，比如：使用更高效的编程语言,优化处理业务逻辑的算法,优化访问数据库的SQL
>
>基本原则：分而治之，并提高单个请求的处理速度
>
>### **高并发处理的基本手段**
>
>##### **1）客户端发出请求层面，常见的手段有：**
>
>- 尽量利用浏览器的缓存功能，减少访问服务端，比如：js、css、图片等
>- 可以考虑使用压缩传输的功能，减少网络流量，也会提高传输速度
>- 考虑使用异步请求，分批获取数据
>
>###### **2）前端接收客户端请求层面，常见的手段有：**
>
>- 动静分离，部分静态资源可以直接从Nginx返回
>- 按请求的不同，分发到不同的后端进行处理，比如：[负载均衡](https://cloud.tencent.com/product/clb?from=10680)、业务拆分访问等
>- 前面再加上一层来做多个Nginx的负载均衡，比如：LVS、F5等
>- 还可以在更前面使用[CDN](https://cloud.tencent.com/product/cdn?from=10680)服务
>- 还可以对动态内容进行缓存，尽量减少访问后端服务
>
>###### **3）Web服务器层面，常见的手段有：**
>
>- 使用最新的JVM，并进行配置优化
>- 对Web服务器进行配置优化，比如：调整内存数量、线程数量等
>- 提供多个能提供相同服务的Web服务器，以实现负载均衡
>- 仔细规划Web服务器上部署的应用规模
>- 对Web服务器进行集群
>
>###### **4）Web应用层面，常见的手段有：**
>
>- 动态内容静态化
>- Java开发优化
>- 优化处理业务逻辑的算法
>- 合理高效的利用缓存
>- 优化访问数据库的Sql，可以考虑利用存储过程等数据库的能力
>- 合理使用多线程，加快业务处理
>- 部分业务可以考虑内存数据库，或者是进行纯内存处理
>- 尽量避免远程调用、大量I/O等耗时的操作
>- 合理规划事务等较为耗资源的操作
>- 合理使用异步处理
>- 对部分业务考虑采用预处理或者预计算的方式，减少实时计算量
>- 内部系统间的业务尽量直接调用、直接处理，减少WebService、工作流等
>
>##### **5）数据库层面，常见的手段有：**
>
>- 合理选择数据库的引擎，比如Mysql的InnoDB与MyISAM引擎
>- 进行配置优化
>- 可以考虑使用存储过程来处理复杂的数据逻辑
>- 数据库集群，进行读写分离
>- 合理设计数据库的表结构、索引等
>- 分库、分表，降低单库、单表的数据量













